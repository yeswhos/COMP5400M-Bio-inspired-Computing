{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Backpropagation on the Iris data set.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeswhos/COMP5400M-Bio-inspired-Computing/blob/master/CW2/Backpropagation%20on%20the%20Iris%20data%20set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbQztCaXT1i1",
        "colab_type": "text"
      },
      "source": [
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">COMP5400 - Tensorflow Demo</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Marc de Kamps, University of Leeds</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j6YIxblT1i2",
        "colab_type": "text"
      },
      "source": [
        "This notebook demonstrates the use of keras. We will first use it to create a multi-layer perceptron that can classify the iris data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVPYDVOeT1i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first check if all the prerequisites are there.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKKuJqRDT1i6",
        "colab_type": "text"
      },
      "source": [
        "If the previous cells came through, then all the important stuff has been installed on your machine. Now let's process the iris data set and create a 1-of-3 coding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOaCLmssVOGy",
        "colab_type": "text"
      },
      "source": [
        "Load data file from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n-EZkkhUthI",
        "colab_type": "code",
        "outputId": "274c3b0d-29dd-441f-f81b-fe742c650806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = \"drive/My Drive/Bio/iris.data\""
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QV3rb9BET1i6",
        "colab_type": "code",
        "outputId": "fae565bc-602e-40a2-de79-3fc403bc1e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs  = []\n",
        "outputs = []\n",
        "\n",
        "d = {}\n",
        "d['Iris-setosa\\n']     = [1., 0., 0.]\n",
        "d['Iris-versicolor\\n'] = [0., 1., 0.]\n",
        "d['Iris-virginica\\n']  = [0., 0., 1.]\n",
        "\n",
        "# with open('iris.data') as f:\n",
        "with open(filepath) as f:\n",
        "    lines=f.readlines()\n",
        "    for line in lines:\n",
        "        items=line.split(',')\n",
        "        if len(items) == 5:\n",
        "            inp =  [float(x) for x in items[0:4] ]\n",
        "            inputs.append(inp)\n",
        "            out = d[items[4]]\n",
        "            outputs.append(out)\n",
        "            \n",
        "print( len(inputs), 'input patterns', len(outputs), 'output patterns')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150 input patterns 150 output patterns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgE80GzwFS_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9370b85b-11ab-41c6-d545-8071772596e3"
      },
      "source": [
        "inputs  = []\n",
        "outputs = []\n",
        "\n",
        "d = {}\n",
        "d['Iris-setosa\\n']  = [1., 0., 0.]\n",
        "d['Iris-versicolor\\n'] = [0., 0., 1.]\n",
        "d['Iris-virginica\\n']  = [0., 0., 1.]\n",
        "\n",
        "# with open('iris.data') as f:\n",
        "with open(filepath) as f:\n",
        "    lines=f.readlines()\n",
        "    for line in lines:\n",
        "        items=line.split(',')\n",
        "        if len(items) == 5:\n",
        "            inp =  [float(x) for x in items[0:4] ]\n",
        "            inputs.append(inp)\n",
        "            out = d[items[4]]\n",
        "            outputs.append(out)\n",
        "            \n",
        "print( len(inputs), 'input patterns', len(outputs), 'output patterns')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150 input patterns 150 output patterns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hzseelEYpIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "total = np.array(inputs)\n",
        "# print(total)\n",
        "set_sepal_len = total[:50:,0]\n",
        "set_sepal_wid = total[:50:,1]\n",
        "set_petal_len = total[:50:,2]\n",
        "set_petal_wid = total[:50:,3]\n",
        "\n",
        "versi_sepal_len = total[50:100:,0]\n",
        "versi_sepal_wid = total[50:100:,1]\n",
        "versi_petal_len = total[50:100:,2]\n",
        "versi_petal_wid = total[50:100:,3]\n",
        "\n",
        "virgin_sepal_len = total[100:150:,0]\n",
        "virgin_sepal_wid = total[100:150:,1]\n",
        "virgin_petal_len = total[100:150:,2]\n",
        "virgin_petal_wid = total[100:150:,3]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybGPQjDqczD2",
        "colab_type": "code",
        "outputId": "0e2437b7-b299-4c8f-f09c-1d90a4612bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "from pylab import *\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.title(\"Sepal width & length\")\n",
        "plt.xlabel(\"sepal width\")\n",
        "plt.ylabel(\"sepal length\")\n",
        "p1 = plt.scatter(versi_sepal_wid, versi_sepal_len, c = 'g', marker = \"o\")\n",
        "p2 = plt.scatter(virgin_sepal_wid, virgin_sepal_len, c = 'b', marker = \"o\")\n",
        "p3 = plt.scatter(set_sepal_wid, set_sepal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.title(\"Petal width & length\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"petal length\")\n",
        "p4 = plt.scatter(versi_petal_wid, versi_petal_len, c = 'g', marker = \"o\")\n",
        "p5 = plt.scatter(virgin_petal_wid, virgin_petal_len, c = 'b', marker = \"o\")\n",
        "p6 = plt.scatter(set_petal_wid, set_petal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "#plt.legend([p4, p5, p6], ['versicolor', 'virginica', 'setosa'], loc = 'lower right')\n",
        "\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.title(\"Petal length & sepal length\")\n",
        "plt.xlabel(\"petal length\")\n",
        "plt.ylabel(\"sepal length\")\n",
        "p7 = plt.scatter(versi_petal_len, versi_sepal_len, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_len, virgin_sepal_len, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_len, set_sepal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.title(\"Petal length & sepal width\")\n",
        "plt.xlabel(\"petal length\")\n",
        "plt.ylabel(\"sepal width\")\n",
        "p7 = plt.scatter(versi_petal_len, versi_sepal_wid, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_len, virgin_sepal_wid, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_len, set_sepal_wid, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.title(\"Petal width & sepal length\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"sepal length\")\n",
        "p7 = plt.scatter(versi_petal_wid, versi_sepal_len, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_wid, virgin_sepal_len, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_wid, set_sepal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.title(\"Petal width & sepal width\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"sepal width\")\n",
        "p7 = plt.scatter(versi_petal_wid, versi_sepal_wid, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_wid, virgin_sepal_wid, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_wid, set_sepal_wid, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x1152 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1H2Os1a1uRA",
        "colab_type": "code",
        "outputId": "f45c4e7e-ca43-490f-b927-a576949c668a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.title(\"Petal length & width\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"petal length\")\n",
        "p1 = plt.scatter(versi_petal_wid, versi_petal_len, c = 'g', marker = \"o\")\n",
        "p2 = plt.scatter(virgin_petal_wid, virgin_petal_len, c = 'g', marker = \"o\")\n",
        "p3 = plt.scatter(set_petal_wid, set_petal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p2, p3], ['non-setosa', 'setosa'], loc = 'lower right')\n",
        "x = [0, 3.5]\n",
        "y = [1.25, 0]\n",
        "plt.plot(y, x, 'r')\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBe3xiS_T1i9",
        "colab_type": "text"
      },
      "source": [
        "Now we build a network. A stack of layers is captured by the tf.keras.Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE7mEeFPT1i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "import random\n",
        "ids=random.sample(range(0,len(inputs)), 100) # generate 100 random ids\n",
        "train_in = []\n",
        "train_out=[]\n",
        "for id in ids:\n",
        "    train_in.append(inputs[id])\n",
        "    train_out.append(outputs[id])\n",
        "train_inputs  = np.array(train_in)\n",
        "train_outputs = np.array(train_out)\n",
        "\n",
        "val_input =[]\n",
        "val_output=[]\n",
        "validation_ids = list(set(range(0,len(inputs))) - set(ids))\n",
        "for val_id in validation_ids:\n",
        "    val_input.append(inputs[val_id])\n",
        "    val_output.append(outputs[val_id])\n",
        "val_inputs  = np.array(val_input)\n",
        "val_outputs = np.array(val_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAeR8U6JBcAJ",
        "colab_type": "code",
        "outputId": "21adddfb-cb24-41f3-a972-7479c83b8ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(train_outputs[10:15])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsABpVVDT1i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "model = tf.keras.Sequential()\n",
        "# an mlp with a given number of input nodes. Four input nodes, three output nodes \n",
        "nr_hidden = 5\n",
        "nr_in     = 4\n",
        "nr_out    = 3 \n",
        "model.add(layers.Dense(nr_in,activation='relu'))\n",
        "model.add(layers.Dense(nr_hidden, activation = 'sigmoid'))\n",
        "model.add(layers.Dense(nr_out,activation='sigmoid'))\n",
        "model.compile(optimizer=tf.train.GradientDescentOptimizer(0.09),loss='mse',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN5Q7sv-T1jC",
        "colab_type": "text"
      },
      "source": [
        "Create training set and bring them into a numpy array form. Let's use a 100 patterns for training. Also, build a validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-m5FXGET1jC",
        "colab_type": "text"
      },
      "source": [
        "Now train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtfHXnap9St8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0ac8fd2-f8bf-4376-8916-4558f5e20d03"
      },
      "source": [
        "earlystop=tf.keras.callbacks.EarlyStopping(monitor='val_acc',min_delta=-0.01,patience=800,verbose=True,restore_best_weights=True)\n",
        "callbacks=[earlystop]\n",
        "history_model = model.fit(train_inputs,train_outputs,epochs=1000,batch_size=30,validation_data=(val_inputs,val_outputs),callbacks=callbacks)\n",
        "#model.fit(train_inputs,train_outputs,epochs=500,batch_size=30, validation_data=(val_inputs, val_outputs))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/1000\n",
            "100/100 [==============================] - 0s 1ms/sample - loss: 0.2138 - acc: 0.7200 - val_loss: 0.2517 - val_acc: 0.5600\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2081 - acc: 0.7200 - val_loss: 0.2468 - val_acc: 0.5600\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.2027 - acc: 0.7200 - val_loss: 0.2423 - val_acc: 0.5600\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1978 - acc: 0.7200 - val_loss: 0.2382 - val_acc: 0.5600\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1934 - acc: 0.7200 - val_loss: 0.2342 - val_acc: 0.5600\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1894 - acc: 0.7200 - val_loss: 0.2307 - val_acc: 0.5600\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1857 - acc: 0.7200 - val_loss: 0.2275 - val_acc: 0.5600\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1822 - acc: 0.7200 - val_loss: 0.2247 - val_acc: 0.5600\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1790 - acc: 0.7200 - val_loss: 0.2219 - val_acc: 0.5600\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1761 - acc: 0.7200 - val_loss: 0.2195 - val_acc: 0.5600\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1733 - acc: 0.7200 - val_loss: 0.2174 - val_acc: 0.5600\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1708 - acc: 0.7200 - val_loss: 0.2153 - val_acc: 0.5600\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1685 - acc: 0.7200 - val_loss: 0.2135 - val_acc: 0.5600\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1663 - acc: 0.7200 - val_loss: 0.2118 - val_acc: 0.5600\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1643 - acc: 0.7200 - val_loss: 0.2103 - val_acc: 0.5600\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1624 - acc: 0.7200 - val_loss: 0.2089 - val_acc: 0.5600\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1608 - acc: 0.7200 - val_loss: 0.2075 - val_acc: 0.5600\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1592 - acc: 0.7200 - val_loss: 0.2063 - val_acc: 0.5600\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1577 - acc: 0.7200 - val_loss: 0.2051 - val_acc: 0.5600\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1564 - acc: 0.7200 - val_loss: 0.2039 - val_acc: 0.5600\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1551 - acc: 0.7200 - val_loss: 0.2029 - val_acc: 0.5600\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1539 - acc: 0.7200 - val_loss: 0.2020 - val_acc: 0.5600\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1528 - acc: 0.7200 - val_loss: 0.2012 - val_acc: 0.5600\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1518 - acc: 0.7200 - val_loss: 0.2002 - val_acc: 0.5600\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.1508 - acc: 0.7200 - val_loss: 0.1992 - val_acc: 0.5600\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1500 - acc: 0.7200 - val_loss: 0.1986 - val_acc: 0.5600\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1491 - acc: 0.7200 - val_loss: 0.1978 - val_acc: 0.5600\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1483 - acc: 0.7200 - val_loss: 0.1971 - val_acc: 0.5600\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1476 - acc: 0.7200 - val_loss: 0.1965 - val_acc: 0.5600\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1469 - acc: 0.7200 - val_loss: 0.1958 - val_acc: 0.5600\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1463 - acc: 0.7200 - val_loss: 0.1952 - val_acc: 0.5600\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 0s 149us/sample - loss: 0.1456 - acc: 0.7200 - val_loss: 0.1947 - val_acc: 0.5600\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1450 - acc: 0.7200 - val_loss: 0.1940 - val_acc: 0.5600\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1445 - acc: 0.7200 - val_loss: 0.1936 - val_acc: 0.5600\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1439 - acc: 0.7200 - val_loss: 0.1930 - val_acc: 0.5600\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1435 - acc: 0.7200 - val_loss: 0.1925 - val_acc: 0.5600\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1430 - acc: 0.7200 - val_loss: 0.1920 - val_acc: 0.5600\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1425 - acc: 0.7200 - val_loss: 0.1915 - val_acc: 0.5600\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1421 - acc: 0.7200 - val_loss: 0.1912 - val_acc: 0.5600\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1417 - acc: 0.7200 - val_loss: 0.1907 - val_acc: 0.5600\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1413 - acc: 0.7200 - val_loss: 0.1902 - val_acc: 0.5600\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1410 - acc: 0.7200 - val_loss: 0.1899 - val_acc: 0.5600\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1406 - acc: 0.7200 - val_loss: 0.1896 - val_acc: 0.5600\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1402 - acc: 0.7200 - val_loss: 0.1892 - val_acc: 0.5600\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1399 - acc: 0.7200 - val_loss: 0.1890 - val_acc: 0.5600\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1396 - acc: 0.7200 - val_loss: 0.1887 - val_acc: 0.5600\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1393 - acc: 0.7200 - val_loss: 0.1882 - val_acc: 0.5600\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1390 - acc: 0.7200 - val_loss: 0.1881 - val_acc: 0.5600\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1387 - acc: 0.7200 - val_loss: 0.1878 - val_acc: 0.5600\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1385 - acc: 0.7200 - val_loss: 0.1877 - val_acc: 0.5600\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1382 - acc: 0.7200 - val_loss: 0.1876 - val_acc: 0.5600\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1380 - acc: 0.7200 - val_loss: 0.1874 - val_acc: 0.5600\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1377 - acc: 0.7200 - val_loss: 0.1873 - val_acc: 0.5600\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1375 - acc: 0.7200 - val_loss: 0.1869 - val_acc: 0.5600\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.1373 - acc: 0.7200 - val_loss: 0.1861 - val_acc: 0.5600\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1371 - acc: 0.7200 - val_loss: 0.1859 - val_acc: 0.5600\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1369 - acc: 0.7200 - val_loss: 0.1859 - val_acc: 0.5600\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1367 - acc: 0.7200 - val_loss: 0.1855 - val_acc: 0.5600\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1364 - acc: 0.7200 - val_loss: 0.1851 - val_acc: 0.5600\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1363 - acc: 0.7200 - val_loss: 0.1851 - val_acc: 0.5600\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1361 - acc: 0.7200 - val_loss: 0.1850 - val_acc: 0.5600\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1359 - acc: 0.7200 - val_loss: 0.1846 - val_acc: 0.5600\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1357 - acc: 0.7200 - val_loss: 0.1843 - val_acc: 0.5600\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1355 - acc: 0.7200 - val_loss: 0.1842 - val_acc: 0.5600\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1354 - acc: 0.7200 - val_loss: 0.1842 - val_acc: 0.5600\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1352 - acc: 0.7200 - val_loss: 0.1840 - val_acc: 0.5600\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1350 - acc: 0.7200 - val_loss: 0.1838 - val_acc: 0.5600\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1349 - acc: 0.7200 - val_loss: 0.1836 - val_acc: 0.5600\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1347 - acc: 0.7200 - val_loss: 0.1834 - val_acc: 0.5600\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1346 - acc: 0.7200 - val_loss: 0.1833 - val_acc: 0.5600\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1344 - acc: 0.7200 - val_loss: 0.1832 - val_acc: 0.5600\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1343 - acc: 0.7200 - val_loss: 0.1828 - val_acc: 0.5600\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 0s 223us/sample - loss: 0.1341 - acc: 0.7200 - val_loss: 0.1825 - val_acc: 0.5600\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1340 - acc: 0.7200 - val_loss: 0.1825 - val_acc: 0.5600\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1338 - acc: 0.7200 - val_loss: 0.1823 - val_acc: 0.5600\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1338 - acc: 0.7200 - val_loss: 0.1824 - val_acc: 0.5600\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1336 - acc: 0.7200 - val_loss: 0.1824 - val_acc: 0.5600\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1335 - acc: 0.7200 - val_loss: 0.1823 - val_acc: 0.5600\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1334 - acc: 0.7200 - val_loss: 0.1824 - val_acc: 0.5600\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1333 - acc: 0.7200 - val_loss: 0.1823 - val_acc: 0.5600\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1332 - acc: 0.7200 - val_loss: 0.1824 - val_acc: 0.5600\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1330 - acc: 0.7200 - val_loss: 0.1824 - val_acc: 0.5600\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1329 - acc: 0.7200 - val_loss: 0.1823 - val_acc: 0.5600\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.1328 - acc: 0.7200 - val_loss: 0.1820 - val_acc: 0.5600\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1327 - acc: 0.7200 - val_loss: 0.1818 - val_acc: 0.5600\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1325 - acc: 0.7200 - val_loss: 0.1815 - val_acc: 0.5600\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1324 - acc: 0.7200 - val_loss: 0.1814 - val_acc: 0.5600\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1323 - acc: 0.7200 - val_loss: 0.1810 - val_acc: 0.5600\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1322 - acc: 0.7200 - val_loss: 0.1807 - val_acc: 0.5600\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1320 - acc: 0.7200 - val_loss: 0.1802 - val_acc: 0.5600\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1319 - acc: 0.7200 - val_loss: 0.1798 - val_acc: 0.5600\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1318 - acc: 0.7200 - val_loss: 0.1798 - val_acc: 0.5600\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1317 - acc: 0.7200 - val_loss: 0.1797 - val_acc: 0.5600\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1316 - acc: 0.7200 - val_loss: 0.1794 - val_acc: 0.5600\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1315 - acc: 0.7200 - val_loss: 0.1791 - val_acc: 0.5600\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1314 - acc: 0.7200 - val_loss: 0.1790 - val_acc: 0.5600\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1313 - acc: 0.7200 - val_loss: 0.1784 - val_acc: 0.5600\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1311 - acc: 0.7200 - val_loss: 0.1785 - val_acc: 0.5600\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1310 - acc: 0.7200 - val_loss: 0.1782 - val_acc: 0.5600\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1309 - acc: 0.7200 - val_loss: 0.1781 - val_acc: 0.5600\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1308 - acc: 0.7200 - val_loss: 0.1780 - val_acc: 0.5600\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1307 - acc: 0.7200 - val_loss: 0.1780 - val_acc: 0.5600\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1306 - acc: 0.7200 - val_loss: 0.1780 - val_acc: 0.5600\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1305 - acc: 0.7200 - val_loss: 0.1777 - val_acc: 0.5600\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1304 - acc: 0.7200 - val_loss: 0.1775 - val_acc: 0.5600\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1303 - acc: 0.7200 - val_loss: 0.1775 - val_acc: 0.5600\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1302 - acc: 0.7200 - val_loss: 0.1774 - val_acc: 0.5600\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1301 - acc: 0.7200 - val_loss: 0.1771 - val_acc: 0.5600\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1300 - acc: 0.7200 - val_loss: 0.1770 - val_acc: 0.5600\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1299 - acc: 0.7200 - val_loss: 0.1768 - val_acc: 0.5600\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1298 - acc: 0.7200 - val_loss: 0.1768 - val_acc: 0.5600\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1297 - acc: 0.7200 - val_loss: 0.1766 - val_acc: 0.5600\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1296 - acc: 0.7200 - val_loss: 0.1767 - val_acc: 0.5600\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1295 - acc: 0.7200 - val_loss: 0.1764 - val_acc: 0.5600\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1294 - acc: 0.7200 - val_loss: 0.1763 - val_acc: 0.5600\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1293 - acc: 0.7200 - val_loss: 0.1762 - val_acc: 0.5600\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.1292 - acc: 0.7200 - val_loss: 0.1763 - val_acc: 0.5600\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1291 - acc: 0.7200 - val_loss: 0.1760 - val_acc: 0.5600\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1290 - acc: 0.7200 - val_loss: 0.1757 - val_acc: 0.5600\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1289 - acc: 0.7200 - val_loss: 0.1757 - val_acc: 0.5600\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1288 - acc: 0.7200 - val_loss: 0.1759 - val_acc: 0.5600\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1287 - acc: 0.7200 - val_loss: 0.1756 - val_acc: 0.5600\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1286 - acc: 0.7200 - val_loss: 0.1753 - val_acc: 0.5600\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1285 - acc: 0.7200 - val_loss: 0.1751 - val_acc: 0.5600\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1284 - acc: 0.7200 - val_loss: 0.1752 - val_acc: 0.5600\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1283 - acc: 0.7200 - val_loss: 0.1749 - val_acc: 0.5600\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1282 - acc: 0.7200 - val_loss: 0.1748 - val_acc: 0.5600\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1281 - acc: 0.7200 - val_loss: 0.1747 - val_acc: 0.5600\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1280 - acc: 0.7200 - val_loss: 0.1746 - val_acc: 0.5600\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1279 - acc: 0.7200 - val_loss: 0.1743 - val_acc: 0.5600\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1278 - acc: 0.7200 - val_loss: 0.1739 - val_acc: 0.5600\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1278 - acc: 0.7200 - val_loss: 0.1733 - val_acc: 0.5600\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1276 - acc: 0.7200 - val_loss: 0.1727 - val_acc: 0.5600\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1275 - acc: 0.7200 - val_loss: 0.1725 - val_acc: 0.5600\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1274 - acc: 0.7200 - val_loss: 0.1722 - val_acc: 0.5600\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1273 - acc: 0.7200 - val_loss: 0.1722 - val_acc: 0.5600\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1272 - acc: 0.7200 - val_loss: 0.1721 - val_acc: 0.5600\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1270 - acc: 0.7200 - val_loss: 0.1719 - val_acc: 0.5600\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1270 - acc: 0.7200 - val_loss: 0.1716 - val_acc: 0.5600\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1269 - acc: 0.7200 - val_loss: 0.1715 - val_acc: 0.5600\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1268 - acc: 0.7200 - val_loss: 0.1709 - val_acc: 0.5600\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1266 - acc: 0.7200 - val_loss: 0.1708 - val_acc: 0.5600\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1265 - acc: 0.7200 - val_loss: 0.1704 - val_acc: 0.5600\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1264 - acc: 0.7200 - val_loss: 0.1704 - val_acc: 0.5600\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1263 - acc: 0.7200 - val_loss: 0.1703 - val_acc: 0.5600\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1262 - acc: 0.7200 - val_loss: 0.1704 - val_acc: 0.5600\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1261 - acc: 0.7200 - val_loss: 0.1702 - val_acc: 0.5600\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1259 - acc: 0.7200 - val_loss: 0.1703 - val_acc: 0.5600\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1258 - acc: 0.7200 - val_loss: 0.1704 - val_acc: 0.5600\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1257 - acc: 0.7200 - val_loss: 0.1703 - val_acc: 0.5600\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1256 - acc: 0.7200 - val_loss: 0.1702 - val_acc: 0.5600\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1255 - acc: 0.7200 - val_loss: 0.1698 - val_acc: 0.5600\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1254 - acc: 0.7200 - val_loss: 0.1695 - val_acc: 0.5600\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1253 - acc: 0.7200 - val_loss: 0.1694 - val_acc: 0.5600\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1251 - acc: 0.7200 - val_loss: 0.1693 - val_acc: 0.5600\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.1250 - acc: 0.7200 - val_loss: 0.1692 - val_acc: 0.5600\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1249 - acc: 0.7200 - val_loss: 0.1692 - val_acc: 0.5600\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 0s 149us/sample - loss: 0.1248 - acc: 0.7200 - val_loss: 0.1690 - val_acc: 0.5600\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1246 - acc: 0.7200 - val_loss: 0.1690 - val_acc: 0.5600\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1245 - acc: 0.7200 - val_loss: 0.1689 - val_acc: 0.5600\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1244 - acc: 0.7200 - val_loss: 0.1688 - val_acc: 0.5600\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1243 - acc: 0.7200 - val_loss: 0.1687 - val_acc: 0.5600\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1241 - acc: 0.7200 - val_loss: 0.1684 - val_acc: 0.5600\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1240 - acc: 0.7200 - val_loss: 0.1681 - val_acc: 0.5600\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1239 - acc: 0.7200 - val_loss: 0.1679 - val_acc: 0.5600\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1238 - acc: 0.7200 - val_loss: 0.1678 - val_acc: 0.5600\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1236 - acc: 0.7200 - val_loss: 0.1679 - val_acc: 0.5600\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.1235 - acc: 0.7200 - val_loss: 0.1677 - val_acc: 0.5600\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1234 - acc: 0.7200 - val_loss: 0.1676 - val_acc: 0.5600\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.1232 - acc: 0.7200 - val_loss: 0.1673 - val_acc: 0.5600\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1231 - acc: 0.7200 - val_loss: 0.1670 - val_acc: 0.5600\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1229 - acc: 0.7200 - val_loss: 0.1669 - val_acc: 0.5600\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1228 - acc: 0.7200 - val_loss: 0.1666 - val_acc: 0.5600\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1226 - acc: 0.7200 - val_loss: 0.1667 - val_acc: 0.5600\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1225 - acc: 0.7200 - val_loss: 0.1664 - val_acc: 0.5600\n",
            "Epoch 176/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1223 - acc: 0.7200 - val_loss: 0.1663 - val_acc: 0.5600\n",
            "Epoch 177/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1222 - acc: 0.7200 - val_loss: 0.1662 - val_acc: 0.5600\n",
            "Epoch 178/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1220 - acc: 0.7200 - val_loss: 0.1660 - val_acc: 0.5600\n",
            "Epoch 179/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1219 - acc: 0.7200 - val_loss: 0.1657 - val_acc: 0.5600\n",
            "Epoch 180/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1217 - acc: 0.7200 - val_loss: 0.1654 - val_acc: 0.5600\n",
            "Epoch 181/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1215 - acc: 0.7200 - val_loss: 0.1653 - val_acc: 0.5600\n",
            "Epoch 182/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1214 - acc: 0.7200 - val_loss: 0.1649 - val_acc: 0.5600\n",
            "Epoch 183/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1212 - acc: 0.7200 - val_loss: 0.1648 - val_acc: 0.5600\n",
            "Epoch 184/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1211 - acc: 0.7200 - val_loss: 0.1646 - val_acc: 0.5600\n",
            "Epoch 185/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1209 - acc: 0.7200 - val_loss: 0.1645 - val_acc: 0.5600\n",
            "Epoch 186/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1208 - acc: 0.7200 - val_loss: 0.1643 - val_acc: 0.5600\n",
            "Epoch 187/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1205 - acc: 0.7200 - val_loss: 0.1641 - val_acc: 0.5600\n",
            "Epoch 188/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1203 - acc: 0.7200 - val_loss: 0.1639 - val_acc: 0.5600\n",
            "Epoch 189/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1202 - acc: 0.7200 - val_loss: 0.1637 - val_acc: 0.5600\n",
            "Epoch 190/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1200 - acc: 0.7200 - val_loss: 0.1632 - val_acc: 0.5600\n",
            "Epoch 191/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1198 - acc: 0.7200 - val_loss: 0.1630 - val_acc: 0.5600\n",
            "Epoch 192/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1196 - acc: 0.7200 - val_loss: 0.1625 - val_acc: 0.5600\n",
            "Epoch 193/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1193 - acc: 0.7200 - val_loss: 0.1622 - val_acc: 0.5600\n",
            "Epoch 194/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1191 - acc: 0.7200 - val_loss: 0.1620 - val_acc: 0.5600\n",
            "Epoch 195/1000\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.1189 - acc: 0.7200 - val_loss: 0.1616 - val_acc: 0.5600\n",
            "Epoch 196/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1187 - acc: 0.7200 - val_loss: 0.1609 - val_acc: 0.5600\n",
            "Epoch 197/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1185 - acc: 0.7200 - val_loss: 0.1609 - val_acc: 0.5600\n",
            "Epoch 198/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1182 - acc: 0.7200 - val_loss: 0.1607 - val_acc: 0.5600\n",
            "Epoch 199/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1180 - acc: 0.7200 - val_loss: 0.1605 - val_acc: 0.5600\n",
            "Epoch 200/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1178 - acc: 0.7200 - val_loss: 0.1602 - val_acc: 0.5600\n",
            "Epoch 201/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1176 - acc: 0.7200 - val_loss: 0.1597 - val_acc: 0.5600\n",
            "Epoch 202/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1173 - acc: 0.7200 - val_loss: 0.1591 - val_acc: 0.5600\n",
            "Epoch 203/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1170 - acc: 0.7200 - val_loss: 0.1588 - val_acc: 0.5600\n",
            "Epoch 204/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1168 - acc: 0.7200 - val_loss: 0.1583 - val_acc: 0.5600\n",
            "Epoch 205/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1165 - acc: 0.7200 - val_loss: 0.1580 - val_acc: 0.5600\n",
            "Epoch 206/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1162 - acc: 0.7200 - val_loss: 0.1575 - val_acc: 0.5600\n",
            "Epoch 207/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1159 - acc: 0.7200 - val_loss: 0.1569 - val_acc: 0.5600\n",
            "Epoch 208/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1155 - acc: 0.7200 - val_loss: 0.1565 - val_acc: 0.5600\n",
            "Epoch 209/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1153 - acc: 0.7200 - val_loss: 0.1562 - val_acc: 0.5600\n",
            "Epoch 210/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1150 - acc: 0.7200 - val_loss: 0.1555 - val_acc: 0.5600\n",
            "Epoch 211/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1146 - acc: 0.7200 - val_loss: 0.1546 - val_acc: 0.5600\n",
            "Epoch 212/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1142 - acc: 0.7200 - val_loss: 0.1541 - val_acc: 0.5600\n",
            "Epoch 213/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1138 - acc: 0.7200 - val_loss: 0.1535 - val_acc: 0.5600\n",
            "Epoch 214/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1135 - acc: 0.7200 - val_loss: 0.1532 - val_acc: 0.5600\n",
            "Epoch 215/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1131 - acc: 0.7200 - val_loss: 0.1525 - val_acc: 0.5600\n",
            "Epoch 216/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1127 - acc: 0.7200 - val_loss: 0.1522 - val_acc: 0.5600\n",
            "Epoch 217/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1123 - acc: 0.7200 - val_loss: 0.1519 - val_acc: 0.5600\n",
            "Epoch 218/1000\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.1119 - acc: 0.7200 - val_loss: 0.1511 - val_acc: 0.5600\n",
            "Epoch 219/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1115 - acc: 0.7200 - val_loss: 0.1506 - val_acc: 0.5600\n",
            "Epoch 220/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1110 - acc: 0.7200 - val_loss: 0.1498 - val_acc: 0.5600\n",
            "Epoch 221/1000\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1105 - acc: 0.7200 - val_loss: 0.1491 - val_acc: 0.5600\n",
            "Epoch 222/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1101 - acc: 0.7200 - val_loss: 0.1483 - val_acc: 0.5600\n",
            "Epoch 223/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1095 - acc: 0.7200 - val_loss: 0.1477 - val_acc: 0.5600\n",
            "Epoch 224/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1090 - acc: 0.7200 - val_loss: 0.1469 - val_acc: 0.5600\n",
            "Epoch 225/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1085 - acc: 0.7200 - val_loss: 0.1462 - val_acc: 0.5600\n",
            "Epoch 226/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1080 - acc: 0.7200 - val_loss: 0.1455 - val_acc: 0.5600\n",
            "Epoch 227/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1075 - acc: 0.7200 - val_loss: 0.1448 - val_acc: 0.5600\n",
            "Epoch 228/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1070 - acc: 0.7200 - val_loss: 0.1442 - val_acc: 0.5600\n",
            "Epoch 229/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1065 - acc: 0.7200 - val_loss: 0.1435 - val_acc: 0.5600\n",
            "Epoch 230/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1060 - acc: 0.7200 - val_loss: 0.1431 - val_acc: 0.5600\n",
            "Epoch 231/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1055 - acc: 0.7200 - val_loss: 0.1425 - val_acc: 0.5600\n",
            "Epoch 232/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1050 - acc: 0.7200 - val_loss: 0.1420 - val_acc: 0.5600\n",
            "Epoch 233/1000\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1045 - acc: 0.7200 - val_loss: 0.1414 - val_acc: 0.5600\n",
            "Epoch 234/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1041 - acc: 0.7200 - val_loss: 0.1406 - val_acc: 0.5600\n",
            "Epoch 235/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1035 - acc: 0.7200 - val_loss: 0.1402 - val_acc: 0.5600\n",
            "Epoch 236/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1030 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 237/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1025 - acc: 0.7200 - val_loss: 0.1386 - val_acc: 0.5600\n",
            "Epoch 238/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1021 - acc: 0.7200 - val_loss: 0.1379 - val_acc: 0.5600\n",
            "Epoch 239/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1016 - acc: 0.7200 - val_loss: 0.1373 - val_acc: 0.5600\n",
            "Epoch 240/1000\n",
            "100/100 [==============================] - 0s 164us/sample - loss: 0.1011 - acc: 0.7200 - val_loss: 0.1369 - val_acc: 0.5600\n",
            "Epoch 241/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1006 - acc: 0.7200 - val_loss: 0.1365 - val_acc: 0.5600\n",
            "Epoch 242/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1002 - acc: 0.7200 - val_loss: 0.1358 - val_acc: 0.5600\n",
            "Epoch 243/1000\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.0997 - acc: 0.7200 - val_loss: 0.1350 - val_acc: 0.5600\n",
            "Epoch 244/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0993 - acc: 0.7200 - val_loss: 0.1342 - val_acc: 0.5600\n",
            "Epoch 245/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0988 - acc: 0.7200 - val_loss: 0.1336 - val_acc: 0.5600\n",
            "Epoch 246/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0983 - acc: 0.7200 - val_loss: 0.1330 - val_acc: 0.5600\n",
            "Epoch 247/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0979 - acc: 0.7200 - val_loss: 0.1324 - val_acc: 0.5600\n",
            "Epoch 248/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0974 - acc: 0.7200 - val_loss: 0.1317 - val_acc: 0.5600\n",
            "Epoch 249/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0969 - acc: 0.7200 - val_loss: 0.1313 - val_acc: 0.5600\n",
            "Epoch 250/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0965 - acc: 0.7200 - val_loss: 0.1307 - val_acc: 0.5600\n",
            "Epoch 251/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0960 - acc: 0.7200 - val_loss: 0.1302 - val_acc: 0.5600\n",
            "Epoch 252/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0955 - acc: 0.7200 - val_loss: 0.1294 - val_acc: 0.5600\n",
            "Epoch 253/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0950 - acc: 0.7200 - val_loss: 0.1289 - val_acc: 0.5600\n",
            "Epoch 254/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0946 - acc: 0.7200 - val_loss: 0.1284 - val_acc: 0.5600\n",
            "Epoch 255/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0941 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 256/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0937 - acc: 0.7200 - val_loss: 0.1272 - val_acc: 0.5600\n",
            "Epoch 257/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0932 - acc: 0.7200 - val_loss: 0.1265 - val_acc: 0.5600\n",
            "Epoch 258/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0928 - acc: 0.7200 - val_loss: 0.1259 - val_acc: 0.5600\n",
            "Epoch 259/1000\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0923 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 260/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0919 - acc: 0.7200 - val_loss: 0.1248 - val_acc: 0.5600\n",
            "Epoch 261/1000\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0915 - acc: 0.7200 - val_loss: 0.1243 - val_acc: 0.5600\n",
            "Epoch 262/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0910 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 263/1000\n",
            "100/100 [==============================] - 0s 148us/sample - loss: 0.0906 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 264/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0902 - acc: 0.7200 - val_loss: 0.1227 - val_acc: 0.5600\n",
            "Epoch 265/1000\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.0897 - acc: 0.7200 - val_loss: 0.1221 - val_acc: 0.5600\n",
            "Epoch 266/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0893 - acc: 0.7200 - val_loss: 0.1215 - val_acc: 0.5600\n",
            "Epoch 267/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0889 - acc: 0.7200 - val_loss: 0.1209 - val_acc: 0.5600\n",
            "Epoch 268/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0884 - acc: 0.7200 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 269/1000\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0880 - acc: 0.7200 - val_loss: 0.1198 - val_acc: 0.5600\n",
            "Epoch 270/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0876 - acc: 0.7200 - val_loss: 0.1193 - val_acc: 0.5600\n",
            "Epoch 271/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0871 - acc: 0.7200 - val_loss: 0.1188 - val_acc: 0.5600\n",
            "Epoch 272/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0867 - acc: 0.7200 - val_loss: 0.1182 - val_acc: 0.5600\n",
            "Epoch 273/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0863 - acc: 0.7200 - val_loss: 0.1176 - val_acc: 0.5600\n",
            "Epoch 274/1000\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.0859 - acc: 0.7200 - val_loss: 0.1169 - val_acc: 0.5600\n",
            "Epoch 275/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0855 - acc: 0.7200 - val_loss: 0.1164 - val_acc: 0.5600\n",
            "Epoch 276/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0851 - acc: 0.7200 - val_loss: 0.1157 - val_acc: 0.5600\n",
            "Epoch 277/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0846 - acc: 0.7200 - val_loss: 0.1151 - val_acc: 0.5600\n",
            "Epoch 278/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0842 - acc: 0.7200 - val_loss: 0.1144 - val_acc: 0.5600\n",
            "Epoch 279/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0838 - acc: 0.7200 - val_loss: 0.1139 - val_acc: 0.5600\n",
            "Epoch 280/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0834 - acc: 0.7200 - val_loss: 0.1134 - val_acc: 0.5600\n",
            "Epoch 281/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0830 - acc: 0.7200 - val_loss: 0.1130 - val_acc: 0.5600\n",
            "Epoch 282/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0826 - acc: 0.7200 - val_loss: 0.1123 - val_acc: 0.5600\n",
            "Epoch 283/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0821 - acc: 0.7200 - val_loss: 0.1117 - val_acc: 0.5600\n",
            "Epoch 284/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0818 - acc: 0.7200 - val_loss: 0.1111 - val_acc: 0.5600\n",
            "Epoch 285/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0813 - acc: 0.7200 - val_loss: 0.1106 - val_acc: 0.5600\n",
            "Epoch 286/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0809 - acc: 0.7200 - val_loss: 0.1101 - val_acc: 0.5600\n",
            "Epoch 287/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0805 - acc: 0.7200 - val_loss: 0.1096 - val_acc: 0.5600\n",
            "Epoch 288/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0802 - acc: 0.7200 - val_loss: 0.1090 - val_acc: 0.5600\n",
            "Epoch 289/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0798 - acc: 0.7200 - val_loss: 0.1086 - val_acc: 0.5600\n",
            "Epoch 290/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0794 - acc: 0.7200 - val_loss: 0.1081 - val_acc: 0.5600\n",
            "Epoch 291/1000\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.0790 - acc: 0.7200 - val_loss: 0.1074 - val_acc: 0.5600\n",
            "Epoch 292/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0786 - acc: 0.7200 - val_loss: 0.1070 - val_acc: 0.5600\n",
            "Epoch 293/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0782 - acc: 0.7200 - val_loss: 0.1065 - val_acc: 0.5600\n",
            "Epoch 294/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0779 - acc: 0.7200 - val_loss: 0.1060 - val_acc: 0.5600\n",
            "Epoch 295/1000\n",
            "100/100 [==============================] - 0s 134us/sample - loss: 0.0775 - acc: 0.7200 - val_loss: 0.1054 - val_acc: 0.5600\n",
            "Epoch 296/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0771 - acc: 0.7200 - val_loss: 0.1048 - val_acc: 0.5600\n",
            "Epoch 297/1000\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0767 - acc: 0.7200 - val_loss: 0.1043 - val_acc: 0.5600\n",
            "Epoch 298/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0763 - acc: 0.7200 - val_loss: 0.1036 - val_acc: 0.5600\n",
            "Epoch 299/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0759 - acc: 0.7200 - val_loss: 0.1031 - val_acc: 0.5600\n",
            "Epoch 300/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0755 - acc: 0.7200 - val_loss: 0.1025 - val_acc: 0.5600\n",
            "Epoch 301/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0751 - acc: 0.7200 - val_loss: 0.1020 - val_acc: 0.5600\n",
            "Epoch 302/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0747 - acc: 0.7200 - val_loss: 0.1015 - val_acc: 0.5600\n",
            "Epoch 303/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0744 - acc: 0.7200 - val_loss: 0.1009 - val_acc: 0.5600\n",
            "Epoch 304/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0740 - acc: 0.7200 - val_loss: 0.1004 - val_acc: 0.5600\n",
            "Epoch 305/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0737 - acc: 0.7200 - val_loss: 0.1000 - val_acc: 0.5600\n",
            "Epoch 306/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0733 - acc: 0.7200 - val_loss: 0.0994 - val_acc: 0.5600\n",
            "Epoch 307/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0729 - acc: 0.7200 - val_loss: 0.0989 - val_acc: 0.5600\n",
            "Epoch 308/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0725 - acc: 0.7200 - val_loss: 0.0982 - val_acc: 0.5600\n",
            "Epoch 309/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0721 - acc: 0.7200 - val_loss: 0.0976 - val_acc: 0.5600\n",
            "Epoch 310/1000\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0717 - acc: 0.7200 - val_loss: 0.0971 - val_acc: 0.5600\n",
            "Epoch 311/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0713 - acc: 0.7200 - val_loss: 0.0966 - val_acc: 0.5600\n",
            "Epoch 312/1000\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0710 - acc: 0.7200 - val_loss: 0.0960 - val_acc: 0.5600\n",
            "Epoch 313/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0706 - acc: 0.7200 - val_loss: 0.0955 - val_acc: 0.5600\n",
            "Epoch 314/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0702 - acc: 0.7200 - val_loss: 0.0949 - val_acc: 0.5600\n",
            "Epoch 315/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0698 - acc: 0.7200 - val_loss: 0.0943 - val_acc: 0.5600\n",
            "Epoch 316/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0694 - acc: 0.7200 - val_loss: 0.0938 - val_acc: 0.5600\n",
            "Epoch 317/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0691 - acc: 0.7200 - val_loss: 0.0933 - val_acc: 0.5600\n",
            "Epoch 318/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0687 - acc: 0.7200 - val_loss: 0.0927 - val_acc: 0.5600\n",
            "Epoch 319/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0683 - acc: 0.7200 - val_loss: 0.0921 - val_acc: 0.5600\n",
            "Epoch 320/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0680 - acc: 0.7200 - val_loss: 0.0917 - val_acc: 0.5600\n",
            "Epoch 321/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0676 - acc: 0.7500 - val_loss: 0.0911 - val_acc: 0.9600\n",
            "Epoch 322/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0673 - acc: 0.9500 - val_loss: 0.0904 - val_acc: 0.9600\n",
            "Epoch 323/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0669 - acc: 0.9700 - val_loss: 0.0898 - val_acc: 1.0000\n",
            "Epoch 324/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0665 - acc: 0.9700 - val_loss: 0.0891 - val_acc: 1.0000\n",
            "Epoch 325/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0661 - acc: 0.9800 - val_loss: 0.0886 - val_acc: 1.0000\n",
            "Epoch 326/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0657 - acc: 0.9800 - val_loss: 0.0881 - val_acc: 1.0000\n",
            "Epoch 327/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0654 - acc: 0.9800 - val_loss: 0.0875 - val_acc: 1.0000\n",
            "Epoch 328/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0651 - acc: 0.9800 - val_loss: 0.0871 - val_acc: 1.0000\n",
            "Epoch 329/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0646 - acc: 0.9800 - val_loss: 0.0865 - val_acc: 1.0000\n",
            "Epoch 330/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0643 - acc: 0.9800 - val_loss: 0.0861 - val_acc: 1.0000\n",
            "Epoch 331/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0640 - acc: 0.9800 - val_loss: 0.0856 - val_acc: 1.0000\n",
            "Epoch 332/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0636 - acc: 0.9800 - val_loss: 0.0851 - val_acc: 1.0000\n",
            "Epoch 333/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0633 - acc: 0.9800 - val_loss: 0.0846 - val_acc: 1.0000\n",
            "Epoch 334/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0629 - acc: 0.9800 - val_loss: 0.0841 - val_acc: 1.0000\n",
            "Epoch 335/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0626 - acc: 0.9800 - val_loss: 0.0834 - val_acc: 1.0000\n",
            "Epoch 336/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0622 - acc: 0.9800 - val_loss: 0.0829 - val_acc: 1.0000\n",
            "Epoch 337/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0618 - acc: 0.9800 - val_loss: 0.0824 - val_acc: 1.0000\n",
            "Epoch 338/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0615 - acc: 0.9800 - val_loss: 0.0821 - val_acc: 1.0000\n",
            "Epoch 339/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0612 - acc: 0.9800 - val_loss: 0.0816 - val_acc: 1.0000\n",
            "Epoch 340/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0608 - acc: 0.9800 - val_loss: 0.0812 - val_acc: 1.0000\n",
            "Epoch 341/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0605 - acc: 0.9800 - val_loss: 0.0807 - val_acc: 1.0000\n",
            "Epoch 342/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0602 - acc: 0.9900 - val_loss: 0.0801 - val_acc: 1.0000\n",
            "Epoch 343/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0598 - acc: 0.9900 - val_loss: 0.0796 - val_acc: 1.0000\n",
            "Epoch 344/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0595 - acc: 0.9900 - val_loss: 0.0792 - val_acc: 1.0000\n",
            "Epoch 345/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0592 - acc: 0.9900 - val_loss: 0.0788 - val_acc: 1.0000\n",
            "Epoch 346/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0589 - acc: 0.9900 - val_loss: 0.0783 - val_acc: 1.0000\n",
            "Epoch 347/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0585 - acc: 0.9900 - val_loss: 0.0779 - val_acc: 1.0000\n",
            "Epoch 348/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0582 - acc: 0.9900 - val_loss: 0.0774 - val_acc: 1.0000\n",
            "Epoch 349/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0579 - acc: 0.9900 - val_loss: 0.0770 - val_acc: 1.0000\n",
            "Epoch 350/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0576 - acc: 0.9900 - val_loss: 0.0766 - val_acc: 1.0000\n",
            "Epoch 351/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0572 - acc: 0.9900 - val_loss: 0.0761 - val_acc: 1.0000\n",
            "Epoch 352/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0569 - acc: 0.9900 - val_loss: 0.0757 - val_acc: 1.0000\n",
            "Epoch 353/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0566 - acc: 0.9900 - val_loss: 0.0752 - val_acc: 1.0000\n",
            "Epoch 354/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0564 - acc: 0.9900 - val_loss: 0.0748 - val_acc: 1.0000\n",
            "Epoch 355/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0560 - acc: 0.9900 - val_loss: 0.0744 - val_acc: 1.0000\n",
            "Epoch 356/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0557 - acc: 0.9900 - val_loss: 0.0739 - val_acc: 1.0000\n",
            "Epoch 357/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0553 - acc: 0.9900 - val_loss: 0.0735 - val_acc: 1.0000\n",
            "Epoch 358/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0551 - acc: 0.9900 - val_loss: 0.0731 - val_acc: 1.0000\n",
            "Epoch 359/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0547 - acc: 0.9900 - val_loss: 0.0726 - val_acc: 1.0000\n",
            "Epoch 360/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0544 - acc: 0.9900 - val_loss: 0.0721 - val_acc: 1.0000\n",
            "Epoch 361/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 1.0000\n",
            "Epoch 362/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 1.0000\n",
            "Epoch 363/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 0.0708 - val_acc: 1.0000\n",
            "Epoch 364/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.0704 - val_acc: 1.0000\n",
            "Epoch 365/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0529 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 1.0000\n",
            "Epoch 366/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 1.0000\n",
            "Epoch 367/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.0692 - val_acc: 1.0000\n",
            "Epoch 368/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 1.0000\n",
            "Epoch 369/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0517 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 1.0000\n",
            "Epoch 370/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 1.0000\n",
            "Epoch 371/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 1.0000\n",
            "Epoch 372/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 1.0000\n",
            "Epoch 373/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0505 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 1.0000\n",
            "Epoch 374/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0502 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 1.0000\n",
            "Epoch 375/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 1.0000\n",
            "Epoch 376/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0496 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 1.0000\n",
            "Epoch 377/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0493 - acc: 1.0000 - val_loss: 0.0652 - val_acc: 1.0000\n",
            "Epoch 378/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 1.0000\n",
            "Epoch 379/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 1.0000\n",
            "Epoch 380/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 0.0640 - val_acc: 1.0000\n",
            "Epoch 381/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 1.0000\n",
            "Epoch 382/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 1.0000\n",
            "Epoch 383/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 1.0000\n",
            "Epoch 384/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.0623 - val_acc: 1.0000\n",
            "Epoch 385/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0471 - acc: 1.0000 - val_loss: 0.0619 - val_acc: 1.0000\n",
            "Epoch 386/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0468 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 1.0000\n",
            "Epoch 387/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 1.0000\n",
            "Epoch 388/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 1.0000\n",
            "Epoch 389/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0459 - acc: 1.0000 - val_loss: 0.0603 - val_acc: 1.0000\n",
            "Epoch 390/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0457 - acc: 1.0000 - val_loss: 0.0600 - val_acc: 1.0000\n",
            "Epoch 391/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 1.0000\n",
            "Epoch 392/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 1.0000\n",
            "Epoch 393/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0449 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 1.0000\n",
            "Epoch 394/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 1.0000\n",
            "Epoch 395/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0444 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 1.0000\n",
            "Epoch 396/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 1.0000\n",
            "Epoch 397/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0439 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 1.0000\n",
            "Epoch 398/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
            "Epoch 399/1000\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 1.0000\n",
            "Epoch 400/1000\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0432 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 1.0000\n",
            "Epoch 401/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0430 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 1.0000\n",
            "Epoch 402/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0427 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 1.0000\n",
            "Epoch 403/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 1.0000\n",
            "Epoch 404/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
            "Epoch 405/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 1.0000\n",
            "Epoch 406/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 1.0000\n",
            "Epoch 407/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 1.0000\n",
            "Epoch 408/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 1.0000\n",
            "Epoch 409/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 1.0000\n",
            "Epoch 410/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0408 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 411/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 1.0000\n",
            "Epoch 412/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.0529 - val_acc: 1.0000\n",
            "Epoch 413/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 1.0000\n",
            "Epoch 414/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0399 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 1.0000\n",
            "Epoch 415/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 1.0000\n",
            "Epoch 416/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.0518 - val_acc: 1.0000\n",
            "Epoch 417/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 1.0000\n",
            "Epoch 418/1000\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0391 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
            "Epoch 419/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 1.0000\n",
            "Epoch 420/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0386 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
            "Epoch 421/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
            "Epoch 422/1000\n",
            "100/100 [==============================] - 0s 152us/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 1.0000\n",
            "Epoch 423/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
            "Epoch 424/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 1.0000\n",
            "Epoch 425/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0376 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
            "Epoch 426/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 1.0000\n",
            "Epoch 427/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 1.0000\n",
            "Epoch 428/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0369 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 1.0000\n",
            "Epoch 429/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0481 - val_acc: 1.0000\n",
            "Epoch 430/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0365 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 1.0000\n",
            "Epoch 431/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 1.0000\n",
            "Epoch 432/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 1.0000\n",
            "Epoch 433/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 1.0000\n",
            "Epoch 434/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0357 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 1.0000\n",
            "Epoch 435/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 1.0000\n",
            "Epoch 436/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 1.0000\n",
            "Epoch 437/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 1.0000\n",
            "Epoch 438/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0349 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 1.0000\n",
            "Epoch 439/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0347 - acc: 1.0000 - val_loss: 0.0454 - val_acc: 1.0000\n",
            "Epoch 440/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 1.0000\n",
            "Epoch 441/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 1.0000\n",
            "Epoch 442/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
            "Epoch 443/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 1.0000\n",
            "Epoch 444/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 1.0000\n",
            "Epoch 445/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 1.0000\n",
            "Epoch 446/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 1.0000\n",
            "Epoch 447/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 1.0000\n",
            "Epoch 448/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 1.0000\n",
            "Epoch 449/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 1.0000\n",
            "Epoch 450/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.0426 - val_acc: 1.0000\n",
            "Epoch 451/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 1.0000\n",
            "Epoch 452/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 1.0000\n",
            "Epoch 453/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0321 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
            "Epoch 454/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 1.0000\n",
            "Epoch 455/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 1.0000\n",
            "Epoch 456/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0315 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 1.0000\n",
            "Epoch 457/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0409 - val_acc: 1.0000\n",
            "Epoch 458/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 0.0407 - val_acc: 1.0000\n",
            "Epoch 459/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
            "Epoch 460/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 1.0000\n",
            "Epoch 461/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 1.0000\n",
            "Epoch 462/1000\n",
            "100/100 [==============================] - 0s 133us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
            "Epoch 463/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 1.0000\n",
            "Epoch 464/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 1.0000\n",
            "Epoch 465/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 1.0000\n",
            "Epoch 466/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0391 - val_acc: 1.0000\n",
            "Epoch 467/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 1.0000\n",
            "Epoch 468/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 1.0000\n",
            "Epoch 469/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0294 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 1.0000\n",
            "Epoch 470/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.0382 - val_acc: 1.0000\n",
            "Epoch 471/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 1.0000\n",
            "Epoch 472/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 1.0000\n",
            "Epoch 473/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
            "Epoch 474/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 1.0000\n",
            "Epoch 475/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
            "Epoch 476/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
            "Epoch 477/1000\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.0368 - val_acc: 1.0000\n",
            "Epoch 478/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 1.0000\n",
            "Epoch 479/1000\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 1.0000\n",
            "Epoch 480/1000\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
            "Epoch 481/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 1.0000\n",
            "Epoch 482/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 1.0000\n",
            "Epoch 483/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 1.0000\n",
            "Epoch 484/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 1.0000\n",
            "Epoch 485/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0352 - val_acc: 1.0000\n",
            "Epoch 486/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 1.0000\n",
            "Epoch 487/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 488/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 489/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 1.0000\n",
            "Epoch 490/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
            "Epoch 491/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
            "Epoch 492/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
            "Epoch 493/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 1.0000\n",
            "Epoch 494/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
            "Epoch 495/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\n",
            "Epoch 496/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 1.0000\n",
            "Epoch 497/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n",
            "Epoch 498/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 1.0000\n",
            "Epoch 499/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
            "Epoch 500/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
            "Epoch 501/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
            "Epoch 502/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
            "Epoch 503/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 1.0000\n",
            "Epoch 504/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
            "Epoch 505/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 1.0000\n",
            "Epoch 506/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 1.0000\n",
            "Epoch 507/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 1.0000\n",
            "Epoch 508/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 1.0000\n",
            "Epoch 509/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 1.0000\n",
            "Epoch 510/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
            "Epoch 511/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000\n",
            "Epoch 512/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 1.0000\n",
            "Epoch 513/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 1.0000\n",
            "Epoch 514/1000\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 1.0000\n",
            "Epoch 515/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
            "Epoch 516/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 1.0000\n",
            "Epoch 517/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 1.0000\n",
            "Epoch 518/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 1.0000\n",
            "Epoch 519/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
            "Epoch 520/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 1.0000\n",
            "Epoch 521/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 1.0000\n",
            "Epoch 522/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 1.0000\n",
            "Epoch 523/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
            "Epoch 524/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
            "Epoch 525/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
            "Epoch 526/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.0285 - val_acc: 1.0000\n",
            "Epoch 527/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
            "Epoch 528/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
            "Epoch 529/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
            "Epoch 530/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
            "Epoch 531/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 532/1000\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000\n",
            "Epoch 533/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 1.0000\n",
            "Epoch 534/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 1.0000\n",
            "Epoch 535/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 1.0000\n",
            "Epoch 536/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000\n",
            "Epoch 537/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 1.0000\n",
            "Epoch 538/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 539/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 1.0000\n",
            "Epoch 540/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 1.0000\n",
            "Epoch 541/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\n",
            "Epoch 542/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
            "Epoch 543/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
            "Epoch 544/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
            "Epoch 545/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
            "Epoch 546/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 1.0000\n",
            "Epoch 547/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
            "Epoch 548/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
            "Epoch 549/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\n",
            "Epoch 550/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
            "Epoch 551/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
            "Epoch 552/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
            "Epoch 553/1000\n",
            "100/100 [==============================] - 0s 136us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
            "Epoch 554/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 555/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 1.0000\n",
            "Epoch 556/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
            "Epoch 557/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
            "Epoch 558/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
            "Epoch 559/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
            "Epoch 560/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
            "Epoch 561/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
            "Epoch 562/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
            "Epoch 563/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
            "Epoch 564/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
            "Epoch 565/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
            "Epoch 566/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\n",
            "Epoch 567/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
            "Epoch 568/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
            "Epoch 569/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 570/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
            "Epoch 571/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
            "Epoch 572/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
            "Epoch 573/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
            "Epoch 574/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
            "Epoch 575/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
            "Epoch 576/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
            "Epoch 577/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
            "Epoch 578/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n",
            "Epoch 579/1000\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
            "Epoch 580/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
            "Epoch 581/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 582/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
            "Epoch 583/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
            "Epoch 584/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
            "Epoch 585/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
            "Epoch 586/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
            "Epoch 587/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
            "Epoch 588/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
            "Epoch 589/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
            "Epoch 590/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
            "Epoch 591/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 1.0000\n",
            "Epoch 592/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 593/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
            "Epoch 594/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
            "Epoch 595/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
            "Epoch 596/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
            "Epoch 597/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
            "Epoch 598/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
            "Epoch 599/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 600/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
            "Epoch 601/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 1.0000\n",
            "Epoch 602/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
            "Epoch 603/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
            "Epoch 604/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
            "Epoch 605/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
            "Epoch 606/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
            "Epoch 607/1000\n",
            "100/100 [==============================] - 0s 149us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 608/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
            "Epoch 609/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
            "Epoch 610/1000\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
            "Epoch 611/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
            "Epoch 612/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 613/1000\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 614/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
            "Epoch 615/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
            "Epoch 616/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
            "Epoch 617/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
            "Epoch 618/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
            "Epoch 619/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
            "Epoch 620/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
            "Epoch 621/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
            "Epoch 622/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
            "Epoch 623/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 624/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 625/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 626/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 627/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
            "Epoch 628/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
            "Epoch 629/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 630/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 631/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
            "Epoch 632/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
            "Epoch 633/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
            "Epoch 634/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
            "Epoch 635/1000\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
            "Epoch 636/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
            "Epoch 637/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 638/1000\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 639/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
            "Epoch 640/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
            "Epoch 641/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
            "Epoch 642/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 643/1000\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 644/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 645/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
            "Epoch 646/1000\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
            "Epoch 647/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
            "Epoch 648/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
            "Epoch 649/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
            "Epoch 650/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
            "Epoch 651/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
            "Epoch 652/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
            "Epoch 653/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
            "Epoch 654/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
            "Epoch 655/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n",
            "Epoch 656/1000\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
            "Epoch 657/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
            "Epoch 658/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 659/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 660/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 661/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 662/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 663/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 664/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
            "Epoch 665/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
            "Epoch 666/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
            "Epoch 667/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
            "Epoch 668/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
            "Epoch 669/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
            "Epoch 670/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
            "Epoch 671/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
            "Epoch 672/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
            "Epoch 673/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
            "Epoch 674/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
            "Epoch 675/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 676/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 677/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 678/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 679/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 680/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
            "Epoch 681/1000\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
            "Epoch 682/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
            "Epoch 683/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
            "Epoch 684/1000\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
            "Epoch 685/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
            "Epoch 686/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
            "Epoch 687/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
            "Epoch 688/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
            "Epoch 689/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
            "Epoch 690/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
            "Epoch 691/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
            "Epoch 692/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
            "Epoch 693/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
            "Epoch 694/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
            "Epoch 695/1000\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
            "Epoch 696/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
            "Epoch 697/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
            "Epoch 698/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
            "Epoch 699/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
            "Epoch 700/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
            "Epoch 701/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
            "Epoch 702/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
            "Epoch 703/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
            "Epoch 704/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
            "Epoch 705/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
            "Epoch 706/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
            "Epoch 707/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 708/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 709/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
            "Epoch 710/1000\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
            "Epoch 711/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
            "Epoch 712/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
            "Epoch 713/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
            "Epoch 714/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
            "Epoch 715/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
            "Epoch 716/1000\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
            "Epoch 717/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
            "Epoch 718/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
            "Epoch 719/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
            "Epoch 720/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
            "Epoch 721/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
            "Epoch 722/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
            "Epoch 723/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
            "Epoch 724/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
            "Epoch 725/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 726/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 727/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 728/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
            "Epoch 729/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
            "Epoch 730/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 731/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 732/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 733/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 734/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 735/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
            "Epoch 736/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
            "Epoch 737/1000\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
            "Epoch 738/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 739/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 740/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 741/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
            "Epoch 742/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
            "Epoch 743/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 744/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 745/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 746/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
            "Epoch 747/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
            "Epoch 748/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
            "Epoch 749/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 750/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 751/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
            "Epoch 752/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
            "Epoch 753/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
            "Epoch 754/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
            "Epoch 755/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
            "Epoch 756/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
            "Epoch 757/1000\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
            "Epoch 758/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
            "Epoch 759/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
            "Epoch 760/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 761/1000\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 762/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 763/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 764/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
            "Epoch 765/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
            "Epoch 766/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
            "Epoch 767/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 768/1000\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 769/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 770/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 771/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 772/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 773/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 774/1000\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 775/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 776/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 777/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 778/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 779/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 780/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 781/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 782/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 783/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 784/1000\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 785/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 786/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 787/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 788/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 789/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 790/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 791/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 792/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 793/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 794/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 795/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 796/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 797/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 798/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 799/1000\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 800/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 801/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 802/1000\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 803/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 804/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 805/1000\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 806/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 807/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 808/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 809/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 810/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 811/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 812/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 813/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 814/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 815/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 816/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 817/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 818/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 819/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 820/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 821/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 822/1000\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 823/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 824/1000\n",
            "100/100 [==============================] - 0s 145us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 825/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 826/1000\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 827/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 828/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 829/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 830/1000\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 831/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 832/1000\n",
            "100/100 [==============================] - 0s 217us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 833/1000\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 834/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 835/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 836/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 837/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 838/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 839/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 840/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 841/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 842/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 843/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 844/1000\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 845/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 846/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 847/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 848/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 849/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 850/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 851/1000\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 852/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 853/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 854/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 855/1000\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 856/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 857/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 858/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 859/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 860/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 861/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 862/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 863/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 864/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 865/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 866/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 867/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 868/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 869/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 870/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 871/1000\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 872/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 873/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 874/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 875/1000\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 876/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 877/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 878/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 879/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 880/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 881/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 882/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 883/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 884/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 885/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 886/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 887/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 888/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 889/1000\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 890/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 891/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 892/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 893/1000\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 894/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 895/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 896/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 897/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 898/1000\n",
            "100/100 [==============================] - 0s 144us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 899/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 900/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 901/1000\n",
            "100/100 [==============================] - 0s 164us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 902/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 903/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 904/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 905/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 906/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 907/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 908/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 909/1000\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 910/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 911/1000\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 912/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 913/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 914/1000\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 915/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 916/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 917/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 918/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 919/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 920/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 921/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 922/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 923/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 924/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 925/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 926/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 927/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 928/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 929/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 930/1000\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 931/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 932/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 933/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 934/1000\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 935/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 936/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 937/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 938/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 939/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 940/1000\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 941/1000\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 942/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 943/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 944/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 945/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 946/1000\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 947/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 948/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 949/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 950/1000\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 951/1000\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 952/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 953/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 954/1000\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 955/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 956/1000\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 957/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 958/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 959/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 960/1000\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 961/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 962/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 963/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 964/1000\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 965/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 966/1000\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 967/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 968/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 969/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 970/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 971/1000\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 972/1000\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 973/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 974/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 975/1000\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 976/1000\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 977/1000\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 978/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 979/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 980/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 981/1000\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 982/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 983/1000\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 984/1000\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 985/1000\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 986/1000\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 987/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 988/1000\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 989/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 990/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 991/1000\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 992/1000\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 993/1000\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 994/1000\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 995/1000\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 996/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 997/1000\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 998/1000\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 999/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 1000/1000\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky-VIVrfbM0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b0d9da41-5a4c-4abb-8240-9bf1a0f44a58"
      },
      "source": [
        "vla_accu=[]\n",
        "vla_accu=history_model.history['val_acc']\n",
        "vla_loss=[]\n",
        "val_loss=history_model.history['val_loss']\n",
        "\n",
        "Epochs=[]\n",
        "i=0\n",
        "for i in range(0,len(vla_accu)):\n",
        "  Epochs.append(i)\n",
        "  i += 1\n",
        "# Sepal length with Petal length\n",
        "plt.plot(Epochs,vla_accu,c='r',label=\"vlidation acc\")\n",
        "plt.ylabel('vlidation acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "piccGRyMT1jD",
        "colab_type": "code",
        "outputId": "e989f90c-8a97-473e-c68c-8f3eef9a60c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_model = model.fit(train_inputs,train_outputs,epochs=500,batch_size=30, validation_data=(val_inputs, val_outputs))\n",
        "# print(history)\n",
        "# keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/500\n",
            "100/100 [==============================] - 0s 336us/sample - loss: 0.2627 - acc: 0.0000e+00 - val_loss: 0.2495 - val_acc: 0.0000e+00\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.2412 - acc: 0.0100 - val_loss: 0.2337 - val_acc: 0.3200\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2206 - acc: 0.6200 - val_loss: 0.2211 - val_acc: 0.5400\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.2042 - acc: 0.7300 - val_loss: 0.2109 - val_acc: 0.5400\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.1900 - acc: 0.7300 - val_loss: 0.2032 - val_acc: 0.5400\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1794 - acc: 0.7300 - val_loss: 0.1974 - val_acc: 0.5400\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1710 - acc: 0.7300 - val_loss: 0.1930 - val_acc: 0.5400\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1637 - acc: 0.7300 - val_loss: 0.1895 - val_acc: 0.5400\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 0s 75us/sample - loss: 0.1583 - acc: 0.7300 - val_loss: 0.1867 - val_acc: 0.5400\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1541 - acc: 0.7300 - val_loss: 0.1845 - val_acc: 0.5400\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1505 - acc: 0.7300 - val_loss: 0.1829 - val_acc: 0.5400\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1471 - acc: 0.7300 - val_loss: 0.1815 - val_acc: 0.5400\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1443 - acc: 0.7300 - val_loss: 0.1804 - val_acc: 0.5400\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1421 - acc: 0.7300 - val_loss: 0.1797 - val_acc: 0.5400\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.1398 - acc: 0.7300 - val_loss: 0.1786 - val_acc: 0.5400\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.1381 - acc: 0.7300 - val_loss: 0.1778 - val_acc: 0.5400\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.1365 - acc: 0.7300 - val_loss: 0.1774 - val_acc: 0.5400\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.1350 - acc: 0.7300 - val_loss: 0.1773 - val_acc: 0.5400\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1335 - acc: 0.7300 - val_loss: 0.1770 - val_acc: 0.5400\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1323 - acc: 0.7300 - val_loss: 0.1766 - val_acc: 0.5400\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1312 - acc: 0.7300 - val_loss: 0.1762 - val_acc: 0.5400\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1302 - acc: 0.7300 - val_loss: 0.1758 - val_acc: 0.5400\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1293 - acc: 0.7300 - val_loss: 0.1756 - val_acc: 0.5400\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1284 - acc: 0.7300 - val_loss: 0.1752 - val_acc: 0.5400\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1275 - acc: 0.7300 - val_loss: 0.1745 - val_acc: 0.5400\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1268 - acc: 0.7300 - val_loss: 0.1734 - val_acc: 0.5400\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1261 - acc: 0.7300 - val_loss: 0.1728 - val_acc: 0.5400\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1254 - acc: 0.7300 - val_loss: 0.1722 - val_acc: 0.5400\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1247 - acc: 0.7300 - val_loss: 0.1718 - val_acc: 0.5400\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1240 - acc: 0.7300 - val_loss: 0.1717 - val_acc: 0.5400\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1234 - acc: 0.7300 - val_loss: 0.1714 - val_acc: 0.5400\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.1228 - acc: 0.7300 - val_loss: 0.1705 - val_acc: 0.5400\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1222 - acc: 0.7300 - val_loss: 0.1698 - val_acc: 0.5400\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1216 - acc: 0.7300 - val_loss: 0.1692 - val_acc: 0.5400\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.1210 - acc: 0.7300 - val_loss: 0.1691 - val_acc: 0.5400\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1205 - acc: 0.7300 - val_loss: 0.1685 - val_acc: 0.5400\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1199 - acc: 0.7300 - val_loss: 0.1675 - val_acc: 0.5400\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1194 - acc: 0.7300 - val_loss: 0.1667 - val_acc: 0.5400\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1189 - acc: 0.7300 - val_loss: 0.1666 - val_acc: 0.5400\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1184 - acc: 0.7300 - val_loss: 0.1657 - val_acc: 0.5400\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1178 - acc: 0.7300 - val_loss: 0.1648 - val_acc: 0.5400\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1173 - acc: 0.7300 - val_loss: 0.1641 - val_acc: 0.5400\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1168 - acc: 0.7300 - val_loss: 0.1641 - val_acc: 0.5400\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1162 - acc: 0.7300 - val_loss: 0.1639 - val_acc: 0.5400\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1158 - acc: 0.7300 - val_loss: 0.1628 - val_acc: 0.5400\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1152 - acc: 0.7300 - val_loss: 0.1624 - val_acc: 0.5400\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1147 - acc: 0.7300 - val_loss: 0.1625 - val_acc: 0.5400\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1142 - acc: 0.7300 - val_loss: 0.1614 - val_acc: 0.5400\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1137 - acc: 0.7300 - val_loss: 0.1609 - val_acc: 0.5400\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1132 - acc: 0.7300 - val_loss: 0.1601 - val_acc: 0.5400\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1126 - acc: 0.7300 - val_loss: 0.1597 - val_acc: 0.5400\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 0s 77us/sample - loss: 0.1122 - acc: 0.7300 - val_loss: 0.1585 - val_acc: 0.5400\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.1116 - acc: 0.7300 - val_loss: 0.1571 - val_acc: 0.5400\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1111 - acc: 0.7300 - val_loss: 0.1555 - val_acc: 0.5400\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1104 - acc: 0.7300 - val_loss: 0.1553 - val_acc: 0.5400\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1099 - acc: 0.7300 - val_loss: 0.1543 - val_acc: 0.5400\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1092 - acc: 0.7300 - val_loss: 0.1531 - val_acc: 0.5400\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.1086 - acc: 0.7300 - val_loss: 0.1527 - val_acc: 0.5400\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1080 - acc: 0.7300 - val_loss: 0.1521 - val_acc: 0.5400\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1074 - acc: 0.7300 - val_loss: 0.1513 - val_acc: 0.5400\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.1068 - acc: 0.7300 - val_loss: 0.1503 - val_acc: 0.5400\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1061 - acc: 0.7300 - val_loss: 0.1492 - val_acc: 0.5400\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1055 - acc: 0.7300 - val_loss: 0.1485 - val_acc: 0.5400\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1048 - acc: 0.7300 - val_loss: 0.1473 - val_acc: 0.5400\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1041 - acc: 0.7300 - val_loss: 0.1461 - val_acc: 0.5400\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1034 - acc: 0.7300 - val_loss: 0.1456 - val_acc: 0.5400\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1027 - acc: 0.7300 - val_loss: 0.1446 - val_acc: 0.5400\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1020 - acc: 0.7300 - val_loss: 0.1436 - val_acc: 0.5400\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.1013 - acc: 0.7300 - val_loss: 0.1423 - val_acc: 0.5400\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1005 - acc: 0.7300 - val_loss: 0.1406 - val_acc: 0.5400\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0996 - acc: 0.7300 - val_loss: 0.1392 - val_acc: 0.5400\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0990 - acc: 0.7300 - val_loss: 0.1385 - val_acc: 0.5400\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0981 - acc: 0.7300 - val_loss: 0.1374 - val_acc: 0.5400\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0973 - acc: 0.7300 - val_loss: 0.1363 - val_acc: 0.5400\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0965 - acc: 0.7300 - val_loss: 0.1349 - val_acc: 0.5400\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0956 - acc: 0.7300 - val_loss: 0.1337 - val_acc: 0.5400\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0948 - acc: 0.7300 - val_loss: 0.1325 - val_acc: 0.5400\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0939 - acc: 0.7300 - val_loss: 0.1310 - val_acc: 0.5400\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0931 - acc: 0.7300 - val_loss: 0.1292 - val_acc: 0.5400\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0923 - acc: 0.7300 - val_loss: 0.1287 - val_acc: 0.5400\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0914 - acc: 0.7300 - val_loss: 0.1275 - val_acc: 0.5400\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0906 - acc: 0.7300 - val_loss: 0.1263 - val_acc: 0.5400\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0897 - acc: 0.7300 - val_loss: 0.1247 - val_acc: 0.5400\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0889 - acc: 0.7300 - val_loss: 0.1240 - val_acc: 0.5400\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0881 - acc: 0.7300 - val_loss: 0.1221 - val_acc: 0.5400\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0873 - acc: 0.7300 - val_loss: 0.1205 - val_acc: 0.5400\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0863 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5400\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0856 - acc: 0.7300 - val_loss: 0.1191 - val_acc: 0.5400\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0847 - acc: 0.7300 - val_loss: 0.1180 - val_acc: 0.5400\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0839 - acc: 0.7300 - val_loss: 0.1167 - val_acc: 0.5400\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0831 - acc: 0.7300 - val_loss: 0.1151 - val_acc: 0.5400\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0822 - acc: 0.7300 - val_loss: 0.1141 - val_acc: 0.5400\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0815 - acc: 0.7300 - val_loss: 0.1125 - val_acc: 0.5400\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0806 - acc: 0.7300 - val_loss: 0.1117 - val_acc: 0.5400\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0799 - acc: 0.7300 - val_loss: 0.1100 - val_acc: 0.5400\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0789 - acc: 0.7300 - val_loss: 0.1088 - val_acc: 0.5600\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0782 - acc: 0.7300 - val_loss: 0.1074 - val_acc: 0.5600\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0773 - acc: 0.7400 - val_loss: 0.1062 - val_acc: 0.5600\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0765 - acc: 0.7400 - val_loss: 0.1051 - val_acc: 0.5600\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0757 - acc: 0.7400 - val_loss: 0.1043 - val_acc: 0.5800\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0749 - acc: 0.7400 - val_loss: 0.1034 - val_acc: 0.5800\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0741 - acc: 0.7400 - val_loss: 0.1020 - val_acc: 0.6200\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0734 - acc: 0.7600 - val_loss: 0.1012 - val_acc: 0.6200\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0725 - acc: 0.7800 - val_loss: 0.1004 - val_acc: 0.6400\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0719 - acc: 0.8100 - val_loss: 0.0994 - val_acc: 0.7000\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0711 - acc: 0.8700 - val_loss: 0.0987 - val_acc: 0.7000\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0703 - acc: 0.8400 - val_loss: 0.0972 - val_acc: 0.7800\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0696 - acc: 0.9000 - val_loss: 0.0965 - val_acc: 0.8000\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0689 - acc: 0.8900 - val_loss: 0.0944 - val_acc: 0.8400\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0680 - acc: 0.9300 - val_loss: 0.0934 - val_acc: 0.9000\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0672 - acc: 0.9300 - val_loss: 0.0920 - val_acc: 0.9200\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0665 - acc: 0.9500 - val_loss: 0.0905 - val_acc: 0.9600\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0657 - acc: 0.9900 - val_loss: 0.0893 - val_acc: 0.9600\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0651 - acc: 0.9900 - val_loss: 0.0888 - val_acc: 0.9600\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0642 - acc: 0.9900 - val_loss: 0.0879 - val_acc: 0.9600\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0635 - acc: 0.9900 - val_loss: 0.0868 - val_acc: 0.9800\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.0628 - acc: 0.9900 - val_loss: 0.0856 - val_acc: 0.9800\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0620 - acc: 0.9900 - val_loss: 0.0849 - val_acc: 0.9800\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0613 - acc: 0.9900 - val_loss: 0.0835 - val_acc: 0.9800\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0606 - acc: 0.9900 - val_loss: 0.0827 - val_acc: 1.0000\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0600 - acc: 0.9900 - val_loss: 0.0821 - val_acc: 1.0000\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0593 - acc: 0.9900 - val_loss: 0.0809 - val_acc: 1.0000\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0586 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 1.0000\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 1.0000\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 1.0000\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0566 - acc: 1.0000 - val_loss: 0.0778 - val_acc: 1.0000\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 1.0000\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 1.0000\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 1.0000\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 1.0000\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 1.0000\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0528 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 1.0000\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0522 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 1.0000\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0516 - acc: 1.0000 - val_loss: 0.0704 - val_acc: 1.0000\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 0s 152us/sample - loss: 0.0511 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 1.0000\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0504 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 1.0000\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0498 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 1.0000\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0493 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 1.0000\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 1.0000\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0481 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 1.0000\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.0476 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 1.0000\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 1.0000\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 1.0000\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0459 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 1.0000\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.0624 - val_acc: 1.0000\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0450 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 1.0000\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0445 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 1.0000\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 0.0602 - val_acc: 1.0000\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.0589 - val_acc: 1.0000\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 1.0000\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 1.0000\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 1.0000\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 1.0000\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0410 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 1.0000\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0405 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 1.0000\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 1.0000\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0392 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 1.0000\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 1.0000\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.0517 - val_acc: 1.0000\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0379 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0375 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 1.0000\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 1.0000\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 1.0000\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 1.0000\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 1.0000\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 1.0000\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 1.0000\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 1.0000\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0338 - acc: 1.0000 - val_loss: 0.0458 - val_acc: 1.0000\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 1.0000\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0327 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 1.0000\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0317 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 1.0000\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 1.0000\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 1.0000\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 1.0000\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 1.0000\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0295 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 1.0000\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 1.0000\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 1.0000\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 1.0000\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 1.0000\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.0375 - val_acc: 1.0000\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 1.0000\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 1.0000\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.0359 - val_acc: 1.0000\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 1.0000\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 1.0000\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 1.0000\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.0345 - val_acc: 1.0000\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 1.0000\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.0322 - val_acc: 1.0000\n",
            "Epoch 208/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
            "Epoch 209/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 1.0000\n",
            "Epoch 210/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 1.0000\n",
            "Epoch 211/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
            "Epoch 212/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 1.0000\n",
            "Epoch 213/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
            "Epoch 214/500\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
            "Epoch 215/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 1.0000\n",
            "Epoch 216/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\n",
            "Epoch 217/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 1.0000\n",
            "Epoch 218/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 0.0291 - val_acc: 1.0000\n",
            "Epoch 219/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
            "Epoch 220/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
            "Epoch 221/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 1.0000\n",
            "Epoch 222/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
            "Epoch 223/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
            "Epoch 224/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
            "Epoch 225/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000\n",
            "Epoch 226/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 1.0000\n",
            "Epoch 227/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0271 - val_acc: 1.0000\n",
            "Epoch 228/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 229/500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 1.0000\n",
            "Epoch 230/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
            "Epoch 231/500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
            "Epoch 232/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 1.0000\n",
            "Epoch 233/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
            "Epoch 234/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 1.0000\n",
            "Epoch 235/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
            "Epoch 236/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
            "Epoch 237/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 238/500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 1.0000\n",
            "Epoch 239/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
            "Epoch 240/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
            "Epoch 241/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 1.0000\n",
            "Epoch 242/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
            "Epoch 243/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
            "Epoch 244/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
            "Epoch 245/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
            "Epoch 246/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 247/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
            "Epoch 248/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
            "Epoch 249/500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
            "Epoch 250/500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
            "Epoch 251/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
            "Epoch 252/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
            "Epoch 253/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n",
            "Epoch 254/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 255/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
            "Epoch 256/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
            "Epoch 257/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
            "Epoch 258/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
            "Epoch 259/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
            "Epoch 260/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000\n",
            "Epoch 261/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 262/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
            "Epoch 263/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
            "Epoch 264/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 1.0000\n",
            "Epoch 265/500\n",
            "100/100 [==============================] - 0s 77us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
            "Epoch 266/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 267/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 1.0000\n",
            "Epoch 268/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
            "Epoch 269/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
            "Epoch 270/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
            "Epoch 271/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 272/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
            "Epoch 273/500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
            "Epoch 274/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 275/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
            "Epoch 276/500\n",
            "100/100 [==============================] - 0s 137us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
            "Epoch 277/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
            "Epoch 278/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
            "Epoch 279/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
            "Epoch 280/500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
            "Epoch 281/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 282/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 283/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 284/500\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
            "Epoch 285/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
            "Epoch 286/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
            "Epoch 287/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
            "Epoch 288/500\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
            "Epoch 289/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
            "Epoch 290/500\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
            "Epoch 291/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 292/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 293/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
            "Epoch 294/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 295/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 296/500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
            "Epoch 297/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 1.0000\n",
            "Epoch 298/500\n",
            "100/100 [==============================] - 0s 76us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
            "Epoch 299/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n",
            "Epoch 300/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
            "Epoch 301/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 1.0000\n",
            "Epoch 302/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n",
            "Epoch 303/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
            "Epoch 304/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 305/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 306/500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 307/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 308/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
            "Epoch 309/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
            "Epoch 310/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
            "Epoch 311/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 1.0000\n",
            "Epoch 312/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
            "Epoch 313/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
            "Epoch 314/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
            "Epoch 315/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 316/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 317/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 318/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 319/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
            "Epoch 320/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
            "Epoch 321/500\n",
            "100/100 [==============================] - 0s 76us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
            "Epoch 322/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
            "Epoch 323/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
            "Epoch 324/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
            "Epoch 325/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
            "Epoch 326/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 1.0000\n",
            "Epoch 327/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
            "Epoch 328/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
            "Epoch 329/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
            "Epoch 330/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
            "Epoch 331/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
            "Epoch 332/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
            "Epoch 333/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 1.0000\n",
            "Epoch 334/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
            "Epoch 335/500\n",
            "100/100 [==============================] - 0s 76us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
            "Epoch 336/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 337/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 338/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
            "Epoch 339/500\n",
            "100/100 [==============================] - 0s 75us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
            "Epoch 340/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
            "Epoch 341/500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
            "Epoch 342/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
            "Epoch 343/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
            "Epoch 344/500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
            "Epoch 345/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
            "Epoch 346/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
            "Epoch 347/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
            "Epoch 348/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
            "Epoch 349/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 350/500\n",
            "100/100 [==============================] - 0s 76us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 351/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
            "Epoch 352/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 353/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 354/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 355/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 356/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
            "Epoch 357/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
            "Epoch 358/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 359/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 360/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 1.0000\n",
            "Epoch 361/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 362/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 363/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
            "Epoch 364/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
            "Epoch 365/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 366/500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 367/500\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 1.0000\n",
            "Epoch 368/500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
            "Epoch 369/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
            "Epoch 370/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
            "Epoch 371/500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
            "Epoch 372/500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 373/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 374/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 375/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
            "Epoch 376/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 377/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 378/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 379/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 380/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 381/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 382/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 383/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 384/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 385/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 386/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 387/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 388/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 389/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 390/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 391/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 392/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 393/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 394/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 395/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 396/500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 397/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 398/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 399/500\n",
            "100/100 [==============================] - 0s 76us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 400/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 401/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 402/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 403/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 404/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 405/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 406/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 407/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 408/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 409/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 410/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 411/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 412/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 413/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 414/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 415/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 416/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 417/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 418/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 419/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 420/500\n",
            "100/100 [==============================] - 0s 77us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
            "Epoch 421/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 422/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 423/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 424/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 425/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 426/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 427/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 428/500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 429/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 430/500\n",
            "100/100 [==============================] - 0s 75us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 431/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 432/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 433/500\n",
            "100/100 [==============================] - 0s 72us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 434/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 435/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 436/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 437/500\n",
            "100/100 [==============================] - 0s 79us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 438/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 439/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 440/500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 441/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 442/500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 443/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 444/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 445/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 446/500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 447/500\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 448/500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 449/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 450/500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 451/500\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 452/500\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 453/500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 454/500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 455/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 456/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 457/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 458/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 459/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 460/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 461/500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 462/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 463/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 464/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 465/500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 466/500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 467/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 468/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 469/500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 470/500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 471/500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 472/500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 473/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 474/500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 475/500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 476/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 477/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 478/500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 479/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 480/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 481/500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 482/500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 483/500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 484/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 485/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 486/500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 487/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
            "Epoch 488/500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 489/500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 490/500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 491/500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 492/500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 493/500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 494/500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 495/500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 496/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 497/500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 498/500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 499/500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 500/500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwQdE1_g8RWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vla_loss = []\n",
        "val_loss = history_model.history['val_loss']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utEcCDTCT1jF",
        "colab_type": "code",
        "outputId": "5e90347f-2c5e-40cc-9f42-9967e3f4cd08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.predict(val_inputs[10:15])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09187338, 0.03235349, 0.90492916],\n",
              "       [0.85573435, 0.04135624, 0.1491934 ],\n",
              "       [0.09159645, 0.03237534, 0.90543145],\n",
              "       [0.8497749 , 0.04128527, 0.1548797 ],\n",
              "       [0.85541886, 0.04134289, 0.14951499]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6RVcnZYASUQ",
        "colab_type": "code",
        "outputId": "32263714-4d51-4ad7-e884-c2e55bb36d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_out[10:15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwlx7WypT1jI",
        "colab_type": "code",
        "outputId": "5edbc424-24c7-4103-8261-ac7b1c50c20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(val_outputs[10:15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IP02_1T1jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}