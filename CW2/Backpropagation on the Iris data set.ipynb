{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Backpropagation on the Iris data set.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeswhos/COMP5400M-Bio-inspired-Computing/blob/master/CW2/Backpropagation%20on%20the%20Iris%20data%20set.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbQztCaXT1i1",
        "colab_type": "text"
      },
      "source": [
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">COMP5400 - Tensorflow Demo</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Marc de Kamps, University of Leeds</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j6YIxblT1i2",
        "colab_type": "text"
      },
      "source": [
        "This notebook demonstrates the use of keras. We will first use it to create a multi-layer perceptron that can classify the iris data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVPYDVOeT1i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first check if all the prerequisites are there.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKKuJqRDT1i6",
        "colab_type": "text"
      },
      "source": [
        "If the previous cells came through, then all the important stuff has been installed on your machine. Now let's process the iris data set and create a 1-of-3 coding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOaCLmssVOGy",
        "colab_type": "text"
      },
      "source": [
        "Load data file from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n-EZkkhUthI",
        "colab_type": "code",
        "outputId": "602b22d0-9bf8-4d04-ce03-e8f5f01b688a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath = \"drive/My Drive/Bio/iris.data\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QV3rb9BET1i6",
        "colab_type": "code",
        "outputId": "3b395adf-5503-46a8-ba47-0333decb13d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs  = []\n",
        "outputs = []\n",
        "iris = []\n",
        "\n",
        "d = {}\n",
        "d['Iris-setosa\\n']     = [1., 0., 0.]\n",
        "d['Iris-versicolor\\n'] = [0., 1., 0.]\n",
        "d['Iris-virginica\\n']  = [0., 0., 1.]\n",
        "\n",
        "# with open('iris.data') as f:\n",
        "with open(filepath) as f:\n",
        "    lines=f.readlines()\n",
        "    for line in lines:\n",
        "        items=line.split(',')\n",
        "        iris.append(items)\n",
        "        if len(items) == 5:\n",
        "            inp =  [float(x) for x in items[0:4] ]\n",
        "            inputs.append(inp)\n",
        "            out = d[items[4]]\n",
        "            outputs.append(out)\n",
        "            \n",
        "print( len(inputs), 'input patterns', len(outputs), 'output patterns')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "150 input patterns 150 output patterns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX2Av7IOYW9I",
        "colab_type": "code",
        "outputId": "3c5458ac-1062-43ed-9736-79fcf6d4f2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(iris)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['5.1', '3.5', '1.4', '0.2', 'Iris-setosa\\n'], ['4.9', '3.0', '1.4', '0.2', 'Iris-setosa\\n'], ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa\\n'], ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa\\n'], ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa\\n'], ['5.4', '3.9', '1.7', '0.4', 'Iris-setosa\\n'], ['4.6', '3.4', '1.4', '0.3', 'Iris-setosa\\n'], ['5.0', '3.4', '1.5', '0.2', 'Iris-setosa\\n'], ['4.4', '2.9', '1.4', '0.2', 'Iris-setosa\\n'], ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa\\n'], ['5.4', '3.7', '1.5', '0.2', 'Iris-setosa\\n'], ['4.8', '3.4', '1.6', '0.2', 'Iris-setosa\\n'], ['4.8', '3.0', '1.4', '0.1', 'Iris-setosa\\n'], ['4.3', '3.0', '1.1', '0.1', 'Iris-setosa\\n'], ['5.8', '4.0', '1.2', '0.2', 'Iris-setosa\\n'], ['5.7', '4.4', '1.5', '0.4', 'Iris-setosa\\n'], ['5.4', '3.9', '1.3', '0.4', 'Iris-setosa\\n'], ['5.1', '3.5', '1.4', '0.3', 'Iris-setosa\\n'], ['5.7', '3.8', '1.7', '0.3', 'Iris-setosa\\n'], ['5.1', '3.8', '1.5', '0.3', 'Iris-setosa\\n'], ['5.4', '3.4', '1.7', '0.2', 'Iris-setosa\\n'], ['5.1', '3.7', '1.5', '0.4', 'Iris-setosa\\n'], ['4.6', '3.6', '1.0', '0.2', 'Iris-setosa\\n'], ['5.1', '3.3', '1.7', '0.5', 'Iris-setosa\\n'], ['4.8', '3.4', '1.9', '0.2', 'Iris-setosa\\n'], ['5.0', '3.0', '1.6', '0.2', 'Iris-setosa\\n'], ['5.0', '3.4', '1.6', '0.4', 'Iris-setosa\\n'], ['5.2', '3.5', '1.5', '0.2', 'Iris-setosa\\n'], ['5.2', '3.4', '1.4', '0.2', 'Iris-setosa\\n'], ['4.7', '3.2', '1.6', '0.2', 'Iris-setosa\\n'], ['4.8', '3.1', '1.6', '0.2', 'Iris-setosa\\n'], ['5.4', '3.4', '1.5', '0.4', 'Iris-setosa\\n'], ['5.2', '4.1', '1.5', '0.1', 'Iris-setosa\\n'], ['5.5', '4.2', '1.4', '0.2', 'Iris-setosa\\n'], ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa\\n'], ['5.0', '3.2', '1.2', '0.2', 'Iris-setosa\\n'], ['5.5', '3.5', '1.3', '0.2', 'Iris-setosa\\n'], ['4.9', '3.1', '1.5', '0.1', 'Iris-setosa\\n'], ['4.4', '3.0', '1.3', '0.2', 'Iris-setosa\\n'], ['5.1', '3.4', '1.5', '0.2', 'Iris-setosa\\n'], ['5.0', '3.5', '1.3', '0.3', 'Iris-setosa\\n'], ['4.5', '2.3', '1.3', '0.3', 'Iris-setosa\\n'], ['4.4', '3.2', '1.3', '0.2', 'Iris-setosa\\n'], ['5.0', '3.5', '1.6', '0.6', 'Iris-setosa\\n'], ['5.1', '3.8', '1.9', '0.4', 'Iris-setosa\\n'], ['4.8', '3.0', '1.4', '0.3', 'Iris-setosa\\n'], ['5.1', '3.8', '1.6', '0.2', 'Iris-setosa\\n'], ['4.6', '3.2', '1.4', '0.2', 'Iris-setosa\\n'], ['5.3', '3.7', '1.5', '0.2', 'Iris-setosa\\n'], ['5.0', '3.3', '1.4', '0.2', 'Iris-setosa\\n'], ['7.0', '3.2', '4.7', '1.4', 'Iris-versicolor\\n'], ['6.4', '3.2', '4.5', '1.5', 'Iris-versicolor\\n'], ['6.9', '3.1', '4.9', '1.5', 'Iris-versicolor\\n'], ['5.5', '2.3', '4.0', '1.3', 'Iris-versicolor\\n'], ['6.5', '2.8', '4.6', '1.5', 'Iris-versicolor\\n'], ['5.7', '2.8', '4.5', '1.3', 'Iris-versicolor\\n'], ['6.3', '3.3', '4.7', '1.6', 'Iris-versicolor\\n'], ['4.9', '2.4', '3.3', '1.0', 'Iris-versicolor\\n'], ['6.6', '2.9', '4.6', '1.3', 'Iris-versicolor\\n'], ['5.2', '2.7', '3.9', '1.4', 'Iris-versicolor\\n'], ['5.0', '2.0', '3.5', '1.0', 'Iris-versicolor\\n'], ['5.9', '3.0', '4.2', '1.5', 'Iris-versicolor\\n'], ['6.0', '2.2', '4.0', '1.0', 'Iris-versicolor\\n'], ['6.1', '2.9', '4.7', '1.4', 'Iris-versicolor\\n'], ['5.6', '2.9', '3.6', '1.3', 'Iris-versicolor\\n'], ['6.7', '3.1', '4.4', '1.4', 'Iris-versicolor\\n'], ['5.6', '3.0', '4.5', '1.5', 'Iris-versicolor\\n'], ['5.8', '2.7', '4.1', '1.0', 'Iris-versicolor\\n'], ['6.2', '2.2', '4.5', '1.5', 'Iris-versicolor\\n'], ['5.6', '2.5', '3.9', '1.1', 'Iris-versicolor\\n'], ['5.9', '3.2', '4.8', '1.8', 'Iris-versicolor\\n'], ['6.1', '2.8', '4.0', '1.3', 'Iris-versicolor\\n'], ['6.3', '2.5', '4.9', '1.5', 'Iris-versicolor\\n'], ['6.1', '2.8', '4.7', '1.2', 'Iris-versicolor\\n'], ['6.4', '2.9', '4.3', '1.3', 'Iris-versicolor\\n'], ['6.6', '3.0', '4.4', '1.4', 'Iris-versicolor\\n'], ['6.8', '2.8', '4.8', '1.4', 'Iris-versicolor\\n'], ['6.7', '3.0', '5.0', '1.7', 'Iris-versicolor\\n'], ['6.0', '2.9', '4.5', '1.5', 'Iris-versicolor\\n'], ['5.7', '2.6', '3.5', '1.0', 'Iris-versicolor\\n'], ['5.5', '2.4', '3.8', '1.1', 'Iris-versicolor\\n'], ['5.5', '2.4', '3.7', '1.0', 'Iris-versicolor\\n'], ['5.8', '2.7', '3.9', '1.2', 'Iris-versicolor\\n'], ['6.0', '2.7', '5.1', '1.6', 'Iris-versicolor\\n'], ['5.4', '3.0', '4.5', '1.5', 'Iris-versicolor\\n'], ['6.0', '3.4', '4.5', '1.6', 'Iris-versicolor\\n'], ['6.7', '3.1', '4.7', '1.5', 'Iris-versicolor\\n'], ['6.3', '2.3', '4.4', '1.3', 'Iris-versicolor\\n'], ['5.6', '3.0', '4.1', '1.3', 'Iris-versicolor\\n'], ['5.5', '2.5', '4.0', '1.3', 'Iris-versicolor\\n'], ['5.5', '2.6', '4.4', '1.2', 'Iris-versicolor\\n'], ['6.1', '3.0', '4.6', '1.4', 'Iris-versicolor\\n'], ['5.8', '2.6', '4.0', '1.2', 'Iris-versicolor\\n'], ['5.0', '2.3', '3.3', '1.0', 'Iris-versicolor\\n'], ['5.6', '2.7', '4.2', '1.3', 'Iris-versicolor\\n'], ['5.7', '3.0', '4.2', '1.2', 'Iris-versicolor\\n'], ['5.7', '2.9', '4.2', '1.3', 'Iris-versicolor\\n'], ['6.2', '2.9', '4.3', '1.3', 'Iris-versicolor\\n'], ['5.1', '2.5', '3.0', '1.1', 'Iris-versicolor\\n'], ['5.7', '2.8', '4.1', '1.3', 'Iris-versicolor\\n'], ['6.3', '3.3', '6.0', '2.5', 'Iris-virginica\\n'], ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica\\n'], ['7.1', '3.0', '5.9', '2.1', 'Iris-virginica\\n'], ['6.3', '2.9', '5.6', '1.8', 'Iris-virginica\\n'], ['6.5', '3.0', '5.8', '2.2', 'Iris-virginica\\n'], ['7.6', '3.0', '6.6', '2.1', 'Iris-virginica\\n'], ['4.9', '2.5', '4.5', '1.7', 'Iris-virginica\\n'], ['7.3', '2.9', '6.3', '1.8', 'Iris-virginica\\n'], ['6.7', '2.5', '5.8', '1.8', 'Iris-virginica\\n'], ['7.2', '3.6', '6.1', '2.5', 'Iris-virginica\\n'], ['6.5', '3.2', '5.1', '2.0', 'Iris-virginica\\n'], ['6.4', '2.7', '5.3', '1.9', 'Iris-virginica\\n'], ['6.8', '3.0', '5.5', '2.1', 'Iris-virginica\\n'], ['5.7', '2.5', '5.0', '2.0', 'Iris-virginica\\n'], ['5.8', '2.8', '5.1', '2.4', 'Iris-virginica\\n'], ['6.4', '3.2', '5.3', '2.3', 'Iris-virginica\\n'], ['6.5', '3.0', '5.5', '1.8', 'Iris-virginica\\n'], ['7.7', '3.8', '6.7', '2.2', 'Iris-virginica\\n'], ['7.7', '2.6', '6.9', '2.3', 'Iris-virginica\\n'], ['6.0', '2.2', '5.0', '1.5', 'Iris-virginica\\n'], ['6.9', '3.2', '5.7', '2.3', 'Iris-virginica\\n'], ['5.6', '2.8', '4.9', '2.0', 'Iris-virginica\\n'], ['7.7', '2.8', '6.7', '2.0', 'Iris-virginica\\n'], ['6.3', '2.7', '4.9', '1.8', 'Iris-virginica\\n'], ['6.7', '3.3', '5.7', '2.1', 'Iris-virginica\\n'], ['7.2', '3.2', '6.0', '1.8', 'Iris-virginica\\n'], ['6.2', '2.8', '4.8', '1.8', 'Iris-virginica\\n'], ['6.1', '3.0', '4.9', '1.8', 'Iris-virginica\\n'], ['6.4', '2.8', '5.6', '2.1', 'Iris-virginica\\n'], ['7.2', '3.0', '5.8', '1.6', 'Iris-virginica\\n'], ['7.4', '2.8', '6.1', '1.9', 'Iris-virginica\\n'], ['7.9', '3.8', '6.4', '2.0', 'Iris-virginica\\n'], ['6.4', '2.8', '5.6', '2.2', 'Iris-virginica\\n'], ['6.3', '2.8', '5.1', '1.5', 'Iris-virginica\\n'], ['6.1', '2.6', '5.6', '1.4', 'Iris-virginica\\n'], ['7.7', '3.0', '6.1', '2.3', 'Iris-virginica\\n'], ['6.3', '3.4', '5.6', '2.4', 'Iris-virginica\\n'], ['6.4', '3.1', '5.5', '1.8', 'Iris-virginica\\n'], ['6.0', '3.0', '4.8', '1.8', 'Iris-virginica\\n'], ['6.9', '3.1', '5.4', '2.1', 'Iris-virginica\\n'], ['6.7', '3.1', '5.6', '2.4', 'Iris-virginica\\n'], ['6.9', '3.1', '5.1', '2.3', 'Iris-virginica\\n'], ['5.8', '2.7', '5.1', '1.9', 'Iris-virginica\\n'], ['6.8', '3.2', '5.9', '2.3', 'Iris-virginica\\n'], ['6.7', '3.3', '5.7', '2.5', 'Iris-virginica\\n'], ['6.7', '3.0', '5.2', '2.3', 'Iris-virginica\\n'], ['6.3', '2.5', '5.0', '1.9', 'Iris-virginica\\n'], ['6.5', '3.0', '5.2', '2.0', 'Iris-virginica\\n'], ['6.2', '3.4', '5.4', '2.3', 'Iris-virginica\\n'], ['5.9', '3.0', '5.1', '1.8', 'Iris-virginica\\n'], ['\\n']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgE80GzwFS_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hzseelEYpIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "total = np.array(inputs)\n",
        "# print(total)\n",
        "set_sepal_len = total[:50:,0]\n",
        "set_sepal_wid = total[:50:,1]\n",
        "set_petal_len = total[:50:,2]\n",
        "set_petal_wid = total[:50:,3]\n",
        "\n",
        "versi_sepal_len = total[50:100:,0]\n",
        "versi_sepal_wid = total[50:100:,1]\n",
        "versi_petal_len = total[50:100:,2]\n",
        "versi_petal_wid = total[50:100:,3]\n",
        "\n",
        "virgin_sepal_len = total[100:150:,0]\n",
        "virgin_sepal_wid = total[100:150:,1]\n",
        "virgin_petal_len = total[100:150:,2]\n",
        "virgin_petal_wid = total[100:150:,3]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybGPQjDqczD2",
        "colab_type": "code",
        "outputId": "a332bf5c-d07c-4154-fd4d-121b0649cc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "from pylab import *\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "plt.subplot(3, 3, 1)\n",
        "plt.title(\"Sepal width & length\")\n",
        "plt.xlabel(\"sepal width\")\n",
        "plt.ylabel(\"sepal length\")\n",
        "p1 = plt.scatter(versi_sepal_wid, versi_sepal_len, c = 'g', marker = \"o\")\n",
        "p2 = plt.scatter(virgin_sepal_wid, virgin_sepal_len, c = 'b', marker = \"o\")\n",
        "p3 = plt.scatter(set_sepal_wid, set_sepal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 2)\n",
        "plt.title(\"Petal width & length\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"petal length\")\n",
        "p4 = plt.scatter(versi_petal_wid, versi_petal_len, c = 'g', marker = \"o\")\n",
        "p5 = plt.scatter(virgin_petal_wid, virgin_petal_len, c = 'b', marker = \"o\")\n",
        "p6 = plt.scatter(set_petal_wid, set_petal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "#plt.legend([p4, p5, p6], ['versicolor', 'virginica', 'setosa'], loc = 'lower right')\n",
        "\n",
        "plt.subplot(3, 3, 3)\n",
        "plt.title(\"Petal length & sepal length\")\n",
        "plt.xlabel(\"petal length\")\n",
        "plt.ylabel(\"sepal length\")\n",
        "p7 = plt.scatter(versi_petal_len, versi_sepal_len, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_len, virgin_sepal_len, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_len, set_sepal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 4)\n",
        "plt.title(\"Petal length & sepal width\")\n",
        "plt.xlabel(\"petal length\")\n",
        "plt.ylabel(\"sepal width\")\n",
        "p7 = plt.scatter(versi_petal_len, versi_sepal_wid, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_len, virgin_sepal_wid, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_len, set_sepal_wid, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 5)\n",
        "plt.title(\"Petal width & sepal length\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"sepal length\")\n",
        "p7 = plt.scatter(versi_petal_wid, versi_sepal_len, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_wid, virgin_sepal_len, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_wid, set_sepal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "\n",
        "plt.subplot(3, 3, 6)\n",
        "plt.title(\"Petal width & sepal width\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"sepal width\")\n",
        "p7 = plt.scatter(versi_petal_wid, versi_sepal_wid, c = 'g', marker = \"o\")\n",
        "p8 = plt.scatter(virgin_petal_wid, virgin_sepal_wid, c = 'b', marker = \"o\")\n",
        "p9 = plt.scatter(set_petal_wid, set_sepal_wid, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p1, p2, p3], ['versicolor', 'virginica', 'setosa'], loc = 'lower right', prop = {'size':8})\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x1152 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1H2Os1a1uRA",
        "colab_type": "code",
        "outputId": "97f19532-7027-42d5-d19e-b4e6ce772108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.title(\"Petal length & width\")\n",
        "plt.xlabel(\"petal width\")\n",
        "plt.ylabel(\"petal length\")\n",
        "p1 = plt.scatter(versi_petal_wid, versi_petal_len, c = 'g', marker = \"o\")\n",
        "p2 = plt.scatter(virgin_petal_wid, virgin_petal_len, c = 'g', marker = \"o\")\n",
        "p3 = plt.scatter(set_petal_wid, set_petal_len, c = 'r', marker = \"o\")\n",
        "plt.tick_params(axis='both', which = 'major', labelsize=10)\n",
        "plt.legend([p2, p3], ['non-setosa', 'setosa'], loc = 'lower right')\n",
        "x = [0, 3.5]\n",
        "y = [1.25, 0]\n",
        "plt.plot(y, x, 'r')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1sBKV86W4S0",
        "colab_type": "code",
        "outputId": "77b1ec6e-61aa-4843-d65d-43d2b703d194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['label'] = iris.target\n",
        "df.head()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  label\n",
              "0                5.1               3.5  ...               0.2      0\n",
              "1                4.9               3.0  ...               0.2      0\n",
              "2                4.7               3.2  ...               0.2      0\n",
              "3                4.6               3.1  ...               0.2      0\n",
              "4                5.0               3.6  ...               0.2      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0hp7zU5WPOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(df.iloc[:100, [2, 3, -1]])\n",
        "X_setoa, y_setoa = data[:,:-1], data[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9FbOKAlju5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_1 = np.array(df.iloc[50:150, [2, 3, -1]])\n",
        "X_virginica, y_virginica = data_1[:,:-1], data_1[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fCS5jjzGPHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_total = np.array(df.iloc[:, [2, 3, -1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVIBMPT2jwKF",
        "colab_type": "code",
        "outputId": "698c60b3-dbca-47e5-8681-afb5d7de8a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(y_virginica))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRPtolZXTmLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from goto import with_goto\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "# import tensorflow as tf\n",
        "class Perceptron(object):\n",
        "    def __init__(self, input_feature_num, activation=None, b = 0.0):\n",
        "        self.activation = activation if activation else self.sign\n",
        "        self.w = [0.0] * input_feature_num\n",
        "        self.b = b\n",
        "\n",
        "    def sign(self, z):\n",
        "        return int(z>0)\n",
        "    def predict(self, x):\n",
        "        return self.activation(\n",
        "            np.dot(self.w, x) + self.b)\n",
        "    \n",
        "    def fit(self, x_train, y_train, iteration=10, learning_rate=0.1):\n",
        "        # 训练函数\n",
        "        for _ in range(iteration):\n",
        "            counter = 0\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                y_hat = self.predict(x)\n",
        "                # print(y)\n",
        "                # print(y_hat)\n",
        "                loss = tf.Variable((y - y_hat) ** 2, name = 'loss')\n",
        "                init = tf.global_variables_initializer()\n",
        "                with tf.Session() as session:\n",
        "                  session.run(init)\n",
        "                  a = session.run(loss)\n",
        "                  #print(\"loss\", session.run(loss))\n",
        "                if(a == 0.0):\n",
        "                  counter += 1  \n",
        "                self._update_weights(x, y, y_hat, learning_rate)\n",
        "            if(counter > 90):\n",
        "                # print(count)\n",
        "                # print(counter)\n",
        "                print(self.__str__())\n",
        "                return\n",
        "        print(self)\n",
        "    # def _loss_function(n_x, n_y):\n",
        "    #     loss = tf.Variable((n_x - n_y) ** 2, name = 'loss')\n",
        "    #     init = tf.global_variables_initializer()\n",
        "    #     with tf.Session() as session:\n",
        "    #       session.run(init)\n",
        "    #       # print(session.run(loss))\n",
        "    #       return session.run(loss)\n",
        "\n",
        "    \n",
        "    def _update_weights(self, x, y, y_hat, learning_rate):\n",
        "        delta = y - y_hat\n",
        "        self.w = np.add(self.w,np.multiply(learning_rate * delta, x))\n",
        "        self.b += learning_rate * delta\n",
        "    \n",
        "    def __str__(self):\n",
        "        return 'weights: {}\\tbias: {}'.format(self.w, self.b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kB4OvnLeONE",
        "colab_type": "code",
        "outputId": "2ce5d746-7f13-41b5-f8e9-2ee273012d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "perceptron_setoa = Perceptron(input_feature_num=X_setoa.shape[1])\n",
        "perceptron_setoa.fit(X_setoa, y_setoa, iteration=100, learning_rate=0.1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [0.47 0.14]\tbias: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c10JTTJTtNKU",
        "colab_type": "code",
        "outputId": "eb6ae33c-2aef-4a32-8431-61c7e6c048a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "perceptron_virginica = Perceptron(input_feature_num=X_virginica.shape[1], b = -200000.0)\n",
        "perceptron_virginica.fit(X_virginica, y_virginica, iteration=1000, learning_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights: [52478.2        18440.13999999]\tbias: -189729.29999940217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf3mJtznw6x5",
        "colab_type": "code",
        "outputId": "ca5c383f-1036-481d-a7b6-0c6f245019bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "x_points = np.linspace(0, 2)\n",
        "y_ = -(perceptron_setoa.w[0]*x_points + perceptron_setoa.b)/perceptron_setoa.w[1]\n",
        "z_ = -(perceptron_setoa.w[0]*x_points + perceptron_setoa.b)/perceptron_setoa.w[1]\n",
        "plt.plot(x_points, y_)\n",
        "\n",
        "# plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')\n",
        "# plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')\n",
        "plt.plot(data_total[:50, 1], data_total[:50, 0],'bo', color='blue', label='setoa')\n",
        "plt.plot(data_total[50:150, 1],data_total[50:150, 0], 'bo', color='orange', label='non-setoa')\n",
        "plt.xlabel('petal width')\n",
        "plt.ylabel('petal length')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f09aabe8400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCOiSU3Svftp",
        "colab_type": "code",
        "outputId": "55672bd5-0801-43ef-c2ad-81aa8ed991b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "x_points = np.linspace(0,3)\n",
        "# y_points = np.linspace(0,3)\n",
        "y_ = -(perceptron_virginica.w[0]*x_points + perceptron_virginica.b)/perceptron_virginica.w[1]\n",
        "# z_ = -(perceptron_setoa.w[0]*y_points + perceptron_setoa.b)/perceptron_setoa.w[1]\n",
        "plt.plot(x_points, y_)\n",
        "# plt.plot(y_points, z_)\n",
        "# plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')\n",
        "# plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')\n",
        "plt.plot(data_total[100:150, 1], data_total[100:150, 0],'bo', color='blue', label='virginica')\n",
        "plt.plot(data_total[50:100, 1], data_total[50:100, 0],'bo', color='orange', label='non-virginica')\n",
        "# plt.plot(data_total[50:100, 1],data_total[50:100, 0], 'bo', color='orange', label='versicolor')\n",
        "# plt.plot(data_total[:50, 1],data_total[:50, 0], 'bo', color='green', label='setosa')\n",
        "plt.xlabel('petal width')\n",
        "plt.ylabel('petal length')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f09aab59400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrfqNw6OZZMy",
        "colab_type": "code",
        "outputId": "9519aa67-035e-4b0f-b472-678d0d008cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "x_points = np.linspace(0,3)\n",
        "y_points = np.linspace(0,3)\n",
        "y_ = -(perceptron_virginica.w[0]*x_points + perceptron_virginica.b)/perceptron_virginica.w[1]\n",
        "z_ = -(perceptron_setoa.w[0]*y_points + perceptron_setoa.b)/perceptron_setoa.w[1]\n",
        "plt.plot(x_points, y_)\n",
        "plt.plot(y_points, z_)\n",
        "# plt.plot(data[:50, 0], data[:50, 1], 'bo', color='blue', label='0')\n",
        "# plt.plot(data[50:100, 0], data[50:100, 1], 'bo', color='orange', label='1')\n",
        "plt.plot(data_total[100:150, 1], data_total[100:150, 0],'bo', color='blue', label='virginica')\n",
        "# plt.plot(data_total[50:100, 1], data_total[50:100, 0],'bo', color='orange', label='non-virginica')\n",
        "plt.plot(data_total[50:100, 1],data_total[50:100, 0], 'bo', color='orange', label='versicolor')\n",
        "plt.plot(data_total[:50, 1],data_total[:50, 0], 'bo', color='green', label='setosa')\n",
        "plt.xlabel('petal width')\n",
        "plt.ylabel('petal length')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f09aaacd5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ3YY96Bq4ss",
        "colab_type": "code",
        "outputId": "b11a560c-70f5-4ef5-b1fa-f555f541374d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w = tf.Variable([[0.0, 0.0], [0.0, 0.0], [0.06, 52478.2], [0.08, 18440.13999999]])\n",
        "b = tf.Variable(-0.2, -189729.29999940217)\n",
        "print(b)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_109:0' shape=() dtype=float32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNw-1b1g9VLr",
        "colab_type": "code",
        "outputId": "4378db41-c670-426f-806c-6d56325d1dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.Variable(tf.random_normal([4, 2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable_68:0' shape=(4, 2) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2_wpMJB9bCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.compat.v1.disable_eager_execution() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZx4YmvSyguW",
        "colab_type": "code",
        "outputId": "f1e5e3a5-151f-4a2a-b3c5-1397fef521c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "\n",
        "train_X, train_Y = train_inputs, train_outputs\n",
        "\n",
        "#print(train_Y)\n",
        "\n",
        "n_input = 4\n",
        "n_hidden = 2\n",
        "# n_hidden_2 = 5\n",
        "n_output = 3\n",
        "\n",
        "X = tf.placeholder(\"float\",[None,n_input])\n",
        "Y = tf.placeholder(\"float\",[None,n_output])\n",
        "\n",
        "weights = {\n",
        "  \"hidden\": w,\n",
        "  # \"hidden_2\": tf.Variable(tf.random_normal([2,n_hidden_2])),\n",
        "\t\"output\": tf.Variable(tf.random_normal([n_hidden,n_output])),\n",
        "}\n",
        "\n",
        "bias = {\n",
        "\n",
        "  \"hidden\": b,\n",
        "  # \"hidden_2\": tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "\t\"output\": tf.Variable(tf.random_normal([n_output])),\n",
        "}\n",
        "\n",
        "def model(X, weights, bias):\n",
        "  layer1 = tf.add(tf.matmul(X, weights[\"hidden\"]),bias[\"hidden\"])\n",
        "  # layer2 = tf.add(tf.matmul(X, weights[\"hidden_2\"]),bias[\"hidden_2\"])\n",
        "  layer1 = tf.nn.relu(layer1)\n",
        "  output_layer = tf.matmul(layer1,weights[\"output\"]) + bias[\"output\"]\n",
        "  return output_layer\n",
        "\n",
        "test_X, test_Y = val_inputs, val_outputs\n",
        "pred = model(X,weights,bias)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
        "optimizador = tf.train.AdamOptimizer(0.01).minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\tsess.run(init)\n",
        "  \n",
        "\tfor epochs in range(1000):\n",
        "\t\t_, c= sess.run([optimizador,cost],feed_dict = {X: train_X, Y: train_Y})\n",
        "\t\tif(epochs + 1) % 100 == 0:\n",
        "\t\t\tprint(\"Epoch:\",epochs+1,\"Cost:\", c)\n",
        "\tprint(\"Optimization Finished\")\n",
        "\n",
        "\ttest_result = sess.run(pred,feed_dict = {X: train_X})\n",
        "\tcorrect_prediction = tf.equal(tf.argmax(test_result,1),tf.argmax(train_Y,1))\n",
        "\taccuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
        "\n",
        "\tprint(\"accuracy:\", accuracy.eval({X: test_X, Y: test_Y}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100 Cost: 773.0076\n",
            "Epoch: 200 Cost: 488.24527\n",
            "Epoch: 300 Cost: 287.04858\n",
            "Epoch: 400 Cost: 261.02972\n",
            "Epoch: 500 Cost: 183.53166\n",
            "Epoch: 600 Cost: 5.9706416\n",
            "Epoch: 700 Cost: 36.360783\n",
            "Epoch: 800 Cost: 245.6848\n",
            "Epoch: 900 Cost: 485.29282\n",
            "Epoch: 1000 Cost: 77.52723\n",
            "Optimization Finished\n",
            "accuracy: 0.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOmaMwFnmJ5V",
        "colab_type": "code",
        "outputId": "d76a83e3-1349-44a4-c9cd-b77d65061624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print(sess.run(weights))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hidden': array([[0.000000e+00, 0.000000e+00],\n",
            "       [0.000000e+00, 0.000000e+00],\n",
            "       [6.000000e-02, 5.247820e+04],\n",
            "       [8.000000e-02, 1.844014e+04]], dtype=float32), 'output': array([[ 1.3765048 ,  1.0485619 ,  0.3632738 ],\n",
            "       [ 0.704572  , -1.1088995 , -0.10013436]], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aohjAX-816TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBe3xiS_T1i9",
        "colab_type": "text"
      },
      "source": [
        "Now we build a network. A stack of layers is captured by the tf.keras.Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE7mEeFPT1i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "ids=random.sample(range(0,len(inputs)), 100) # generate 100 random ids\n",
        "train_in = []\n",
        "train_out=[]\n",
        "for id in ids:\n",
        "    train_in.append(inputs[id])\n",
        "    train_out.append(outputs[id])\n",
        "train_inputs  = np.array(train_in)\n",
        "train_outputs = np.array(train_out)\n",
        "\n",
        "val_input =[]\n",
        "val_output=[]\n",
        "validation_ids = list(set(range(0,len(inputs))) - set(ids))\n",
        "for val_id in validation_ids:\n",
        "    val_input.append(inputs[val_id])\n",
        "    val_output.append(outputs[val_id])\n",
        "val_inputs  = np.array(val_input)\n",
        "val_outputs = np.array(val_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAeR8U6JBcAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsABpVVDT1i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tf.disable_v2_behavior()\n",
        "model = tf.keras.Sequential()\n",
        "# an mlp with a given number of input nodes. Four input nodes, three output nodes \n",
        "nr_hidden = 5\n",
        "nr_in     = 4\n",
        "nr_out    = 3 \n",
        "model.add(layers.Dense(nr_in,activation='relu'))\n",
        "model.add(layers.Dense(nr_hidden, activation = 'sigmoid'))\n",
        "model.add(layers.Dense(nr_out,activation='sigmoid'))\n",
        "model.compile(optimizer=tf.train.GradientDescentOptimizer(0.05),loss='mse',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN5Q7sv-T1jC",
        "colab_type": "text"
      },
      "source": [
        "Create training set and bring them into a numpy array form. Let's use a 100 patterns for training. Also, build a validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-m5FXGET1jC",
        "colab_type": "text"
      },
      "source": [
        "Now train:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtfHXnap9St8",
        "colab_type": "code",
        "outputId": "9037e4c2-6d14-46af-e37e-e4531257ada8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# earlystop=tf.keras.callbacks.EarlyStopping(monitor='val_acc',min_delta=-0.01,patience=800,verbose=True,restore_best_weights=True)\n",
        "# callbacks=[earlystop]\n",
        "# history_model = model.fit(train_inputs,train_outputs,epochs=20000,batch_size=30,validation_data=(val_inputs,val_outputs),callbacks=callbacks)\n",
        "model.fit(train_inputs,train_outputs,epochs=1500,batch_size=30, validation_data=(val_inputs, val_outputs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples, validate on 50 samples\n",
            "Epoch 1/1500\n",
            "100/100 [==============================] - 0s 3ms/sample - loss: 0.3158 - acc: 0.3700 - val_loss: 0.3050 - val_acc: 0.2600\n",
            "Epoch 2/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.3125 - acc: 0.3700 - val_loss: 0.3019 - val_acc: 0.2600\n",
            "Epoch 3/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.3092 - acc: 0.3700 - val_loss: 0.2990 - val_acc: 0.2600\n",
            "Epoch 4/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.3060 - acc: 0.3700 - val_loss: 0.2963 - val_acc: 0.2600\n",
            "Epoch 5/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.3029 - acc: 0.3700 - val_loss: 0.2934 - val_acc: 0.2600\n",
            "Epoch 6/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2998 - acc: 0.3700 - val_loss: 0.2907 - val_acc: 0.2600\n",
            "Epoch 7/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2969 - acc: 0.3700 - val_loss: 0.2881 - val_acc: 0.2600\n",
            "Epoch 8/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2940 - acc: 0.3700 - val_loss: 0.2856 - val_acc: 0.2600\n",
            "Epoch 9/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.2912 - acc: 0.3700 - val_loss: 0.2832 - val_acc: 0.2600\n",
            "Epoch 10/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.2885 - acc: 0.3700 - val_loss: 0.2809 - val_acc: 0.2600\n",
            "Epoch 11/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2859 - acc: 0.3700 - val_loss: 0.2787 - val_acc: 0.2600\n",
            "Epoch 12/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2834 - acc: 0.3700 - val_loss: 0.2765 - val_acc: 0.2600\n",
            "Epoch 13/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2809 - acc: 0.3700 - val_loss: 0.2742 - val_acc: 0.2600\n",
            "Epoch 14/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2785 - acc: 0.3700 - val_loss: 0.2723 - val_acc: 0.2600\n",
            "Epoch 15/1500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.2762 - acc: 0.3700 - val_loss: 0.2703 - val_acc: 0.2600\n",
            "Epoch 16/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.2741 - acc: 0.3700 - val_loss: 0.2686 - val_acc: 0.2600\n",
            "Epoch 17/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.2719 - acc: 0.3700 - val_loss: 0.2668 - val_acc: 0.2600\n",
            "Epoch 18/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.2697 - acc: 0.3700 - val_loss: 0.2651 - val_acc: 0.2600\n",
            "Epoch 19/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2677 - acc: 0.3700 - val_loss: 0.2633 - val_acc: 0.2600\n",
            "Epoch 20/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.2657 - acc: 0.3700 - val_loss: 0.2618 - val_acc: 0.2600\n",
            "Epoch 21/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.2640 - acc: 0.3700 - val_loss: 0.2603 - val_acc: 0.2600\n",
            "Epoch 22/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.2622 - acc: 0.3700 - val_loss: 0.2590 - val_acc: 0.2600\n",
            "Epoch 23/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2606 - acc: 0.3700 - val_loss: 0.2575 - val_acc: 0.2600\n",
            "Epoch 24/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.2589 - acc: 0.3700 - val_loss: 0.2561 - val_acc: 0.2600\n",
            "Epoch 25/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2572 - acc: 0.3700 - val_loss: 0.2549 - val_acc: 0.2600\n",
            "Epoch 26/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.2557 - acc: 0.3700 - val_loss: 0.2535 - val_acc: 0.2600\n",
            "Epoch 27/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.2541 - acc: 0.3700 - val_loss: 0.2524 - val_acc: 0.2600\n",
            "Epoch 28/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2527 - acc: 0.3700 - val_loss: 0.2512 - val_acc: 0.2600\n",
            "Epoch 29/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.2513 - acc: 0.3700 - val_loss: 0.2499 - val_acc: 0.2600\n",
            "Epoch 30/1500\n",
            "100/100 [==============================] - 0s 147us/sample - loss: 0.2499 - acc: 0.3700 - val_loss: 0.2488 - val_acc: 0.2600\n",
            "Epoch 31/1500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.2486 - acc: 0.3700 - val_loss: 0.2478 - val_acc: 0.2600\n",
            "Epoch 32/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.2475 - acc: 0.3700 - val_loss: 0.2468 - val_acc: 0.2600\n",
            "Epoch 33/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.2462 - acc: 0.3700 - val_loss: 0.2458 - val_acc: 0.2600\n",
            "Epoch 34/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.2450 - acc: 0.3700 - val_loss: 0.2448 - val_acc: 0.2600\n",
            "Epoch 35/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.2439 - acc: 0.3700 - val_loss: 0.2439 - val_acc: 0.2600\n",
            "Epoch 36/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2428 - acc: 0.3700 - val_loss: 0.2430 - val_acc: 0.2600\n",
            "Epoch 37/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2417 - acc: 0.3700 - val_loss: 0.2422 - val_acc: 0.2600\n",
            "Epoch 38/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.2406 - acc: 0.3700 - val_loss: 0.2413 - val_acc: 0.2600\n",
            "Epoch 39/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2397 - acc: 0.3700 - val_loss: 0.2406 - val_acc: 0.2600\n",
            "Epoch 40/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2386 - acc: 0.3700 - val_loss: 0.2397 - val_acc: 0.2600\n",
            "Epoch 41/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2376 - acc: 0.3700 - val_loss: 0.2389 - val_acc: 0.2600\n",
            "Epoch 42/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.2367 - acc: 0.3700 - val_loss: 0.2384 - val_acc: 0.2600\n",
            "Epoch 43/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.2358 - acc: 0.3700 - val_loss: 0.2377 - val_acc: 0.2600\n",
            "Epoch 44/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.2350 - acc: 0.3700 - val_loss: 0.2371 - val_acc: 0.2600\n",
            "Epoch 45/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2342 - acc: 0.3700 - val_loss: 0.2365 - val_acc: 0.2600\n",
            "Epoch 46/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2334 - acc: 0.3700 - val_loss: 0.2359 - val_acc: 0.2600\n",
            "Epoch 47/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.2327 - acc: 0.3700 - val_loss: 0.2353 - val_acc: 0.2600\n",
            "Epoch 48/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.2319 - acc: 0.3700 - val_loss: 0.2349 - val_acc: 0.2600\n",
            "Epoch 49/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.2312 - acc: 0.3700 - val_loss: 0.2343 - val_acc: 0.2600\n",
            "Epoch 50/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2306 - acc: 0.3700 - val_loss: 0.2337 - val_acc: 0.2600\n",
            "Epoch 51/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.2299 - acc: 0.3700 - val_loss: 0.2332 - val_acc: 0.2600\n",
            "Epoch 52/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2293 - acc: 0.3700 - val_loss: 0.2328 - val_acc: 0.2600\n",
            "Epoch 53/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.2287 - acc: 0.3700 - val_loss: 0.2323 - val_acc: 0.2600\n",
            "Epoch 54/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2281 - acc: 0.3700 - val_loss: 0.2318 - val_acc: 0.2600\n",
            "Epoch 55/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2275 - acc: 0.3700 - val_loss: 0.2314 - val_acc: 0.2600\n",
            "Epoch 56/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.2270 - acc: 0.3700 - val_loss: 0.2311 - val_acc: 0.2600\n",
            "Epoch 57/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.2264 - acc: 0.3700 - val_loss: 0.2308 - val_acc: 0.2600\n",
            "Epoch 58/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.2259 - acc: 0.3700 - val_loss: 0.2304 - val_acc: 0.2600\n",
            "Epoch 59/1500\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.2254 - acc: 0.3700 - val_loss: 0.2300 - val_acc: 0.2600\n",
            "Epoch 60/1500\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.2249 - acc: 0.3700 - val_loss: 0.2297 - val_acc: 0.2600\n",
            "Epoch 61/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.2245 - acc: 0.3700 - val_loss: 0.2293 - val_acc: 0.2600\n",
            "Epoch 62/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.2241 - acc: 0.3700 - val_loss: 0.2290 - val_acc: 0.2600\n",
            "Epoch 63/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.2236 - acc: 0.3700 - val_loss: 0.2286 - val_acc: 0.2600\n",
            "Epoch 64/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.2232 - acc: 0.3700 - val_loss: 0.2282 - val_acc: 0.2600\n",
            "Epoch 65/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.2228 - acc: 0.3700 - val_loss: 0.2278 - val_acc: 0.2600\n",
            "Epoch 66/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.2224 - acc: 0.3700 - val_loss: 0.2275 - val_acc: 0.2600\n",
            "Epoch 67/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.2221 - acc: 0.3700 - val_loss: 0.2273 - val_acc: 0.2600\n",
            "Epoch 68/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.2216 - acc: 0.3700 - val_loss: 0.2269 - val_acc: 0.2600\n",
            "Epoch 69/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.2213 - acc: 0.3700 - val_loss: 0.2266 - val_acc: 0.2600\n",
            "Epoch 70/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.2209 - acc: 0.3700 - val_loss: 0.2262 - val_acc: 0.2600\n",
            "Epoch 71/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.2204 - acc: 0.3700 - val_loss: 0.2260 - val_acc: 0.2600\n",
            "Epoch 72/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.2201 - acc: 0.3700 - val_loss: 0.2260 - val_acc: 0.2600\n",
            "Epoch 73/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2197 - acc: 0.3700 - val_loss: 0.2258 - val_acc: 0.2600\n",
            "Epoch 74/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.2194 - acc: 0.3700 - val_loss: 0.2255 - val_acc: 0.2600\n",
            "Epoch 75/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2191 - acc: 0.3700 - val_loss: 0.2252 - val_acc: 0.2600\n",
            "Epoch 76/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2187 - acc: 0.3700 - val_loss: 0.2250 - val_acc: 0.2600\n",
            "Epoch 77/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.2184 - acc: 0.3700 - val_loss: 0.2249 - val_acc: 0.2600\n",
            "Epoch 78/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.2181 - acc: 0.3700 - val_loss: 0.2247 - val_acc: 0.2600\n",
            "Epoch 79/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.2177 - acc: 0.3700 - val_loss: 0.2244 - val_acc: 0.2600\n",
            "Epoch 80/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2174 - acc: 0.3700 - val_loss: 0.2242 - val_acc: 0.2600\n",
            "Epoch 81/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.2170 - acc: 0.3700 - val_loss: 0.2240 - val_acc: 0.2600\n",
            "Epoch 82/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2168 - acc: 0.3700 - val_loss: 0.2237 - val_acc: 0.2600\n",
            "Epoch 83/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.2165 - acc: 0.3700 - val_loss: 0.2235 - val_acc: 0.2600\n",
            "Epoch 84/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.2162 - acc: 0.3700 - val_loss: 0.2231 - val_acc: 0.2600\n",
            "Epoch 85/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.2159 - acc: 0.3700 - val_loss: 0.2230 - val_acc: 0.2600\n",
            "Epoch 86/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.2156 - acc: 0.3700 - val_loss: 0.2226 - val_acc: 0.2600\n",
            "Epoch 87/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.2153 - acc: 0.3800 - val_loss: 0.2224 - val_acc: 0.2600\n",
            "Epoch 88/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.2150 - acc: 0.3900 - val_loss: 0.2223 - val_acc: 0.2600\n",
            "Epoch 89/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.2148 - acc: 0.3900 - val_loss: 0.2221 - val_acc: 0.2600\n",
            "Epoch 90/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2144 - acc: 0.4000 - val_loss: 0.2220 - val_acc: 0.2600\n",
            "Epoch 91/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2141 - acc: 0.4000 - val_loss: 0.2218 - val_acc: 0.2800\n",
            "Epoch 92/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.2139 - acc: 0.4000 - val_loss: 0.2214 - val_acc: 0.3000\n",
            "Epoch 93/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.2136 - acc: 0.4000 - val_loss: 0.2210 - val_acc: 0.3400\n",
            "Epoch 94/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.2133 - acc: 0.5400 - val_loss: 0.2208 - val_acc: 0.3600\n",
            "Epoch 95/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2130 - acc: 0.5300 - val_loss: 0.2205 - val_acc: 0.4000\n",
            "Epoch 96/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.2128 - acc: 0.5700 - val_loss: 0.2204 - val_acc: 0.3800\n",
            "Epoch 97/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2125 - acc: 0.5700 - val_loss: 0.2203 - val_acc: 0.4200\n",
            "Epoch 98/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.2123 - acc: 0.5900 - val_loss: 0.2201 - val_acc: 0.4200\n",
            "Epoch 99/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.2120 - acc: 0.6100 - val_loss: 0.2197 - val_acc: 0.4600\n",
            "Epoch 100/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.2117 - acc: 0.6200 - val_loss: 0.2194 - val_acc: 0.5200\n",
            "Epoch 101/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.2114 - acc: 0.6900 - val_loss: 0.2192 - val_acc: 0.5200\n",
            "Epoch 102/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.2112 - acc: 0.7000 - val_loss: 0.2191 - val_acc: 0.5200\n",
            "Epoch 103/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.2109 - acc: 0.6900 - val_loss: 0.2188 - val_acc: 0.5600\n",
            "Epoch 104/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2107 - acc: 0.7000 - val_loss: 0.2184 - val_acc: 0.5600\n",
            "Epoch 105/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.2104 - acc: 0.7100 - val_loss: 0.2182 - val_acc: 0.5600\n",
            "Epoch 106/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2101 - acc: 0.7100 - val_loss: 0.2181 - val_acc: 0.5600\n",
            "Epoch 107/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.2099 - acc: 0.7100 - val_loss: 0.2179 - val_acc: 0.5600\n",
            "Epoch 108/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2096 - acc: 0.7100 - val_loss: 0.2178 - val_acc: 0.5600\n",
            "Epoch 109/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2093 - acc: 0.7100 - val_loss: 0.2176 - val_acc: 0.5600\n",
            "Epoch 110/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.2090 - acc: 0.7200 - val_loss: 0.2174 - val_acc: 0.5600\n",
            "Epoch 111/1500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.2088 - acc: 0.7200 - val_loss: 0.2173 - val_acc: 0.5600\n",
            "Epoch 112/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.2085 - acc: 0.7200 - val_loss: 0.2170 - val_acc: 0.5600\n",
            "Epoch 113/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.2082 - acc: 0.7200 - val_loss: 0.2168 - val_acc: 0.5600\n",
            "Epoch 114/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.2080 - acc: 0.7200 - val_loss: 0.2164 - val_acc: 0.5600\n",
            "Epoch 115/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.2077 - acc: 0.7200 - val_loss: 0.2161 - val_acc: 0.5600\n",
            "Epoch 116/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.2074 - acc: 0.7200 - val_loss: 0.2159 - val_acc: 0.5600\n",
            "Epoch 117/1500\n",
            "100/100 [==============================] - 0s 150us/sample - loss: 0.2071 - acc: 0.7200 - val_loss: 0.2156 - val_acc: 0.5600\n",
            "Epoch 118/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2069 - acc: 0.7200 - val_loss: 0.2152 - val_acc: 0.5600\n",
            "Epoch 119/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.2065 - acc: 0.7200 - val_loss: 0.2150 - val_acc: 0.5600\n",
            "Epoch 120/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.2063 - acc: 0.7200 - val_loss: 0.2147 - val_acc: 0.5600\n",
            "Epoch 121/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.2060 - acc: 0.7200 - val_loss: 0.2145 - val_acc: 0.5600\n",
            "Epoch 122/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.2057 - acc: 0.7200 - val_loss: 0.2142 - val_acc: 0.5600\n",
            "Epoch 123/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.2054 - acc: 0.7200 - val_loss: 0.2140 - val_acc: 0.5600\n",
            "Epoch 124/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.2051 - acc: 0.7200 - val_loss: 0.2136 - val_acc: 0.5600\n",
            "Epoch 125/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.2049 - acc: 0.7200 - val_loss: 0.2136 - val_acc: 0.5600\n",
            "Epoch 126/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.2045 - acc: 0.7200 - val_loss: 0.2134 - val_acc: 0.5600\n",
            "Epoch 127/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.2043 - acc: 0.7200 - val_loss: 0.2131 - val_acc: 0.5600\n",
            "Epoch 128/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.2040 - acc: 0.7200 - val_loss: 0.2131 - val_acc: 0.5600\n",
            "Epoch 129/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.2036 - acc: 0.7200 - val_loss: 0.2127 - val_acc: 0.5600\n",
            "Epoch 130/1500\n",
            "100/100 [==============================] - 0s 164us/sample - loss: 0.2033 - acc: 0.7200 - val_loss: 0.2124 - val_acc: 0.5600\n",
            "Epoch 131/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.2030 - acc: 0.7200 - val_loss: 0.2122 - val_acc: 0.5600\n",
            "Epoch 132/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.2027 - acc: 0.7200 - val_loss: 0.2119 - val_acc: 0.5600\n",
            "Epoch 133/1500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.2024 - acc: 0.7200 - val_loss: 0.2116 - val_acc: 0.5600\n",
            "Epoch 134/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.2021 - acc: 0.7200 - val_loss: 0.2113 - val_acc: 0.5600\n",
            "Epoch 135/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.2018 - acc: 0.7200 - val_loss: 0.2111 - val_acc: 0.5600\n",
            "Epoch 136/1500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.2014 - acc: 0.7200 - val_loss: 0.2109 - val_acc: 0.5600\n",
            "Epoch 137/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.2012 - acc: 0.7200 - val_loss: 0.2107 - val_acc: 0.5600\n",
            "Epoch 138/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.2009 - acc: 0.7200 - val_loss: 0.2108 - val_acc: 0.5600\n",
            "Epoch 139/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.2005 - acc: 0.7200 - val_loss: 0.2104 - val_acc: 0.5600\n",
            "Epoch 140/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.2003 - acc: 0.7200 - val_loss: 0.2103 - val_acc: 0.5600\n",
            "Epoch 141/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1999 - acc: 0.7200 - val_loss: 0.2099 - val_acc: 0.5600\n",
            "Epoch 142/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1995 - acc: 0.7200 - val_loss: 0.2097 - val_acc: 0.5600\n",
            "Epoch 143/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1992 - acc: 0.7200 - val_loss: 0.2094 - val_acc: 0.5600\n",
            "Epoch 144/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1989 - acc: 0.7200 - val_loss: 0.2092 - val_acc: 0.5600\n",
            "Epoch 145/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1985 - acc: 0.7200 - val_loss: 0.2089 - val_acc: 0.5600\n",
            "Epoch 146/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1982 - acc: 0.7200 - val_loss: 0.2088 - val_acc: 0.5600\n",
            "Epoch 147/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1979 - acc: 0.7200 - val_loss: 0.2084 - val_acc: 0.5600\n",
            "Epoch 148/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1975 - acc: 0.7200 - val_loss: 0.2081 - val_acc: 0.5600\n",
            "Epoch 149/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1972 - acc: 0.7200 - val_loss: 0.2078 - val_acc: 0.5600\n",
            "Epoch 150/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1968 - acc: 0.7200 - val_loss: 0.2074 - val_acc: 0.5600\n",
            "Epoch 151/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1965 - acc: 0.7200 - val_loss: 0.2072 - val_acc: 0.5600\n",
            "Epoch 152/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1963 - acc: 0.7200 - val_loss: 0.2070 - val_acc: 0.5600\n",
            "Epoch 153/1500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.1959 - acc: 0.7200 - val_loss: 0.2066 - val_acc: 0.5600\n",
            "Epoch 154/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1956 - acc: 0.7200 - val_loss: 0.2063 - val_acc: 0.5600\n",
            "Epoch 155/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1952 - acc: 0.7200 - val_loss: 0.2061 - val_acc: 0.5600\n",
            "Epoch 156/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1948 - acc: 0.7200 - val_loss: 0.2058 - val_acc: 0.5600\n",
            "Epoch 157/1500\n",
            "100/100 [==============================] - 0s 127us/sample - loss: 0.1945 - acc: 0.7200 - val_loss: 0.2055 - val_acc: 0.5600\n",
            "Epoch 158/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1941 - acc: 0.7200 - val_loss: 0.2052 - val_acc: 0.5600\n",
            "Epoch 159/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1937 - acc: 0.7200 - val_loss: 0.2049 - val_acc: 0.5600\n",
            "Epoch 160/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1934 - acc: 0.7200 - val_loss: 0.2045 - val_acc: 0.5600\n",
            "Epoch 161/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1930 - acc: 0.7200 - val_loss: 0.2043 - val_acc: 0.5600\n",
            "Epoch 162/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1926 - acc: 0.7200 - val_loss: 0.2040 - val_acc: 0.5600\n",
            "Epoch 163/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1922 - acc: 0.7200 - val_loss: 0.2037 - val_acc: 0.5600\n",
            "Epoch 164/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1918 - acc: 0.7200 - val_loss: 0.2035 - val_acc: 0.5600\n",
            "Epoch 165/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1914 - acc: 0.7200 - val_loss: 0.2032 - val_acc: 0.5600\n",
            "Epoch 166/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.1910 - acc: 0.7200 - val_loss: 0.2029 - val_acc: 0.5600\n",
            "Epoch 167/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1906 - acc: 0.7200 - val_loss: 0.2026 - val_acc: 0.5600\n",
            "Epoch 168/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1902 - acc: 0.7200 - val_loss: 0.2022 - val_acc: 0.5600\n",
            "Epoch 169/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1898 - acc: 0.7200 - val_loss: 0.2016 - val_acc: 0.5600\n",
            "Epoch 170/1500\n",
            "100/100 [==============================] - 0s 127us/sample - loss: 0.1893 - acc: 0.7200 - val_loss: 0.2013 - val_acc: 0.5600\n",
            "Epoch 171/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1889 - acc: 0.7200 - val_loss: 0.2011 - val_acc: 0.5600\n",
            "Epoch 172/1500\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.1886 - acc: 0.7200 - val_loss: 0.2007 - val_acc: 0.5600\n",
            "Epoch 173/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1881 - acc: 0.7200 - val_loss: 0.2001 - val_acc: 0.5600\n",
            "Epoch 174/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1877 - acc: 0.7200 - val_loss: 0.1997 - val_acc: 0.5600\n",
            "Epoch 175/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1872 - acc: 0.7200 - val_loss: 0.1993 - val_acc: 0.5600\n",
            "Epoch 176/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1868 - acc: 0.7200 - val_loss: 0.1991 - val_acc: 0.5600\n",
            "Epoch 177/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1864 - acc: 0.7200 - val_loss: 0.1987 - val_acc: 0.5600\n",
            "Epoch 178/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1861 - acc: 0.7200 - val_loss: 0.1980 - val_acc: 0.5600\n",
            "Epoch 179/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1856 - acc: 0.7200 - val_loss: 0.1979 - val_acc: 0.5600\n",
            "Epoch 180/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1852 - acc: 0.7200 - val_loss: 0.1974 - val_acc: 0.5600\n",
            "Epoch 181/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1848 - acc: 0.7200 - val_loss: 0.1971 - val_acc: 0.5600\n",
            "Epoch 182/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1844 - acc: 0.7200 - val_loss: 0.1970 - val_acc: 0.5600\n",
            "Epoch 183/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1840 - acc: 0.7200 - val_loss: 0.1965 - val_acc: 0.5600\n",
            "Epoch 184/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1836 - acc: 0.7200 - val_loss: 0.1962 - val_acc: 0.5600\n",
            "Epoch 185/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1832 - acc: 0.7200 - val_loss: 0.1956 - val_acc: 0.5600\n",
            "Epoch 186/1500\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.1828 - acc: 0.7200 - val_loss: 0.1953 - val_acc: 0.5600\n",
            "Epoch 187/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1824 - acc: 0.7200 - val_loss: 0.1949 - val_acc: 0.5600\n",
            "Epoch 188/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1819 - acc: 0.7200 - val_loss: 0.1945 - val_acc: 0.5600\n",
            "Epoch 189/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1816 - acc: 0.7200 - val_loss: 0.1943 - val_acc: 0.5600\n",
            "Epoch 190/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1812 - acc: 0.7200 - val_loss: 0.1940 - val_acc: 0.5600\n",
            "Epoch 191/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1808 - acc: 0.7200 - val_loss: 0.1938 - val_acc: 0.5600\n",
            "Epoch 192/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1804 - acc: 0.7200 - val_loss: 0.1936 - val_acc: 0.5600\n",
            "Epoch 193/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1800 - acc: 0.7200 - val_loss: 0.1934 - val_acc: 0.5600\n",
            "Epoch 194/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1796 - acc: 0.7200 - val_loss: 0.1930 - val_acc: 0.5600\n",
            "Epoch 195/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1792 - acc: 0.7200 - val_loss: 0.1925 - val_acc: 0.5600\n",
            "Epoch 196/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1788 - acc: 0.7200 - val_loss: 0.1922 - val_acc: 0.5600\n",
            "Epoch 197/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1784 - acc: 0.7200 - val_loss: 0.1918 - val_acc: 0.5600\n",
            "Epoch 198/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1780 - acc: 0.7200 - val_loss: 0.1915 - val_acc: 0.5600\n",
            "Epoch 199/1500\n",
            "100/100 [==============================] - 0s 141us/sample - loss: 0.1776 - acc: 0.7200 - val_loss: 0.1912 - val_acc: 0.5600\n",
            "Epoch 200/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1772 - acc: 0.7200 - val_loss: 0.1907 - val_acc: 0.5600\n",
            "Epoch 201/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1768 - acc: 0.7200 - val_loss: 0.1900 - val_acc: 0.5600\n",
            "Epoch 202/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1763 - acc: 0.7200 - val_loss: 0.1897 - val_acc: 0.5600\n",
            "Epoch 203/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1760 - acc: 0.7200 - val_loss: 0.1892 - val_acc: 0.5600\n",
            "Epoch 204/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1756 - acc: 0.7200 - val_loss: 0.1887 - val_acc: 0.5600\n",
            "Epoch 205/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1752 - acc: 0.7200 - val_loss: 0.1884 - val_acc: 0.5600\n",
            "Epoch 206/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1748 - acc: 0.7200 - val_loss: 0.1880 - val_acc: 0.5600\n",
            "Epoch 207/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1744 - acc: 0.7200 - val_loss: 0.1873 - val_acc: 0.5600\n",
            "Epoch 208/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1740 - acc: 0.7200 - val_loss: 0.1870 - val_acc: 0.5600\n",
            "Epoch 209/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1736 - acc: 0.7200 - val_loss: 0.1866 - val_acc: 0.5600\n",
            "Epoch 210/1500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.1732 - acc: 0.7200 - val_loss: 0.1865 - val_acc: 0.5600\n",
            "Epoch 211/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1728 - acc: 0.7200 - val_loss: 0.1859 - val_acc: 0.5600\n",
            "Epoch 212/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1724 - acc: 0.7200 - val_loss: 0.1858 - val_acc: 0.5600\n",
            "Epoch 213/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1720 - acc: 0.7200 - val_loss: 0.1854 - val_acc: 0.5600\n",
            "Epoch 214/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1716 - acc: 0.7200 - val_loss: 0.1848 - val_acc: 0.5600\n",
            "Epoch 215/1500\n",
            "100/100 [==============================] - 0s 127us/sample - loss: 0.1712 - acc: 0.7200 - val_loss: 0.1842 - val_acc: 0.5600\n",
            "Epoch 216/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1708 - acc: 0.7200 - val_loss: 0.1840 - val_acc: 0.5600\n",
            "Epoch 217/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1704 - acc: 0.7200 - val_loss: 0.1836 - val_acc: 0.5600\n",
            "Epoch 218/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1700 - acc: 0.7200 - val_loss: 0.1833 - val_acc: 0.5600\n",
            "Epoch 219/1500\n",
            "100/100 [==============================] - 0s 144us/sample - loss: 0.1696 - acc: 0.7200 - val_loss: 0.1828 - val_acc: 0.5600\n",
            "Epoch 220/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1692 - acc: 0.7200 - val_loss: 0.1824 - val_acc: 0.5600\n",
            "Epoch 221/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1688 - acc: 0.7200 - val_loss: 0.1820 - val_acc: 0.5600\n",
            "Epoch 222/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1685 - acc: 0.7200 - val_loss: 0.1813 - val_acc: 0.5600\n",
            "Epoch 223/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1680 - acc: 0.7200 - val_loss: 0.1810 - val_acc: 0.5600\n",
            "Epoch 224/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1677 - acc: 0.7200 - val_loss: 0.1805 - val_acc: 0.5600\n",
            "Epoch 225/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1673 - acc: 0.7200 - val_loss: 0.1799 - val_acc: 0.5600\n",
            "Epoch 226/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1669 - acc: 0.7200 - val_loss: 0.1795 - val_acc: 0.5600\n",
            "Epoch 227/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1665 - acc: 0.7200 - val_loss: 0.1791 - val_acc: 0.5600\n",
            "Epoch 228/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1662 - acc: 0.7200 - val_loss: 0.1789 - val_acc: 0.5600\n",
            "Epoch 229/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1658 - acc: 0.7200 - val_loss: 0.1784 - val_acc: 0.5600\n",
            "Epoch 230/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.1654 - acc: 0.7200 - val_loss: 0.1780 - val_acc: 0.5600\n",
            "Epoch 231/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1650 - acc: 0.7200 - val_loss: 0.1777 - val_acc: 0.5600\n",
            "Epoch 232/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1647 - acc: 0.7200 - val_loss: 0.1772 - val_acc: 0.5600\n",
            "Epoch 233/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1643 - acc: 0.7200 - val_loss: 0.1769 - val_acc: 0.5600\n",
            "Epoch 234/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1639 - acc: 0.7200 - val_loss: 0.1766 - val_acc: 0.5600\n",
            "Epoch 235/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1635 - acc: 0.7200 - val_loss: 0.1762 - val_acc: 0.5600\n",
            "Epoch 236/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1632 - acc: 0.7200 - val_loss: 0.1758 - val_acc: 0.5600\n",
            "Epoch 237/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1628 - acc: 0.7200 - val_loss: 0.1752 - val_acc: 0.5600\n",
            "Epoch 238/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1624 - acc: 0.7200 - val_loss: 0.1747 - val_acc: 0.5600\n",
            "Epoch 239/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1621 - acc: 0.7200 - val_loss: 0.1743 - val_acc: 0.5600\n",
            "Epoch 240/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1617 - acc: 0.7200 - val_loss: 0.1740 - val_acc: 0.5600\n",
            "Epoch 241/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1614 - acc: 0.7200 - val_loss: 0.1737 - val_acc: 0.5600\n",
            "Epoch 242/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1610 - acc: 0.7200 - val_loss: 0.1731 - val_acc: 0.5600\n",
            "Epoch 243/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1606 - acc: 0.7200 - val_loss: 0.1727 - val_acc: 0.5600\n",
            "Epoch 244/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1602 - acc: 0.7200 - val_loss: 0.1724 - val_acc: 0.5600\n",
            "Epoch 245/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1599 - acc: 0.7200 - val_loss: 0.1720 - val_acc: 0.5600\n",
            "Epoch 246/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1595 - acc: 0.7200 - val_loss: 0.1716 - val_acc: 0.5600\n",
            "Epoch 247/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1592 - acc: 0.7200 - val_loss: 0.1713 - val_acc: 0.5600\n",
            "Epoch 248/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1588 - acc: 0.7200 - val_loss: 0.1709 - val_acc: 0.5600\n",
            "Epoch 249/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1585 - acc: 0.7200 - val_loss: 0.1708 - val_acc: 0.5600\n",
            "Epoch 250/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1582 - acc: 0.7200 - val_loss: 0.1706 - val_acc: 0.5600\n",
            "Epoch 251/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1578 - acc: 0.7200 - val_loss: 0.1702 - val_acc: 0.5600\n",
            "Epoch 252/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1575 - acc: 0.7200 - val_loss: 0.1698 - val_acc: 0.5600\n",
            "Epoch 253/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1571 - acc: 0.7200 - val_loss: 0.1693 - val_acc: 0.5600\n",
            "Epoch 254/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1567 - acc: 0.7200 - val_loss: 0.1690 - val_acc: 0.5600\n",
            "Epoch 255/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1564 - acc: 0.7200 - val_loss: 0.1685 - val_acc: 0.5600\n",
            "Epoch 256/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1561 - acc: 0.7200 - val_loss: 0.1683 - val_acc: 0.5600\n",
            "Epoch 257/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1557 - acc: 0.7200 - val_loss: 0.1681 - val_acc: 0.5600\n",
            "Epoch 258/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1554 - acc: 0.7200 - val_loss: 0.1678 - val_acc: 0.5600\n",
            "Epoch 259/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1551 - acc: 0.7200 - val_loss: 0.1675 - val_acc: 0.5600\n",
            "Epoch 260/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1548 - acc: 0.7200 - val_loss: 0.1670 - val_acc: 0.5600\n",
            "Epoch 261/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1544 - acc: 0.7200 - val_loss: 0.1667 - val_acc: 0.5600\n",
            "Epoch 262/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1541 - acc: 0.7200 - val_loss: 0.1664 - val_acc: 0.5600\n",
            "Epoch 263/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1538 - acc: 0.7200 - val_loss: 0.1660 - val_acc: 0.5600\n",
            "Epoch 264/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1535 - acc: 0.7200 - val_loss: 0.1656 - val_acc: 0.5600\n",
            "Epoch 265/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1531 - acc: 0.7200 - val_loss: 0.1651 - val_acc: 0.5600\n",
            "Epoch 266/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1528 - acc: 0.7200 - val_loss: 0.1647 - val_acc: 0.5600\n",
            "Epoch 267/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1526 - acc: 0.7200 - val_loss: 0.1647 - val_acc: 0.5600\n",
            "Epoch 268/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1522 - acc: 0.7200 - val_loss: 0.1644 - val_acc: 0.5600\n",
            "Epoch 269/1500\n",
            "100/100 [==============================] - 0s 143us/sample - loss: 0.1519 - acc: 0.7200 - val_loss: 0.1643 - val_acc: 0.5600\n",
            "Epoch 270/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1516 - acc: 0.7200 - val_loss: 0.1639 - val_acc: 0.5600\n",
            "Epoch 271/1500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.1513 - acc: 0.7200 - val_loss: 0.1637 - val_acc: 0.5600\n",
            "Epoch 272/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1510 - acc: 0.7200 - val_loss: 0.1634 - val_acc: 0.5600\n",
            "Epoch 273/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1507 - acc: 0.7200 - val_loss: 0.1631 - val_acc: 0.5600\n",
            "Epoch 274/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1504 - acc: 0.7200 - val_loss: 0.1626 - val_acc: 0.5600\n",
            "Epoch 275/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1500 - acc: 0.7200 - val_loss: 0.1624 - val_acc: 0.5600\n",
            "Epoch 276/1500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.1498 - acc: 0.7200 - val_loss: 0.1625 - val_acc: 0.5600\n",
            "Epoch 277/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1495 - acc: 0.7200 - val_loss: 0.1622 - val_acc: 0.5600\n",
            "Epoch 278/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1492 - acc: 0.7200 - val_loss: 0.1620 - val_acc: 0.5600\n",
            "Epoch 279/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1489 - acc: 0.7200 - val_loss: 0.1617 - val_acc: 0.5600\n",
            "Epoch 280/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1487 - acc: 0.7200 - val_loss: 0.1613 - val_acc: 0.5600\n",
            "Epoch 281/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1484 - acc: 0.7200 - val_loss: 0.1610 - val_acc: 0.5600\n",
            "Epoch 282/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1481 - acc: 0.7200 - val_loss: 0.1610 - val_acc: 0.5600\n",
            "Epoch 283/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1478 - acc: 0.7200 - val_loss: 0.1607 - val_acc: 0.5600\n",
            "Epoch 284/1500\n",
            "100/100 [==============================] - 0s 78us/sample - loss: 0.1476 - acc: 0.7200 - val_loss: 0.1602 - val_acc: 0.5600\n",
            "Epoch 285/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1473 - acc: 0.7200 - val_loss: 0.1600 - val_acc: 0.5600\n",
            "Epoch 286/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1470 - acc: 0.7200 - val_loss: 0.1598 - val_acc: 0.5600\n",
            "Epoch 287/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1468 - acc: 0.7200 - val_loss: 0.1594 - val_acc: 0.5600\n",
            "Epoch 288/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1465 - acc: 0.7200 - val_loss: 0.1591 - val_acc: 0.5600\n",
            "Epoch 289/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1462 - acc: 0.7200 - val_loss: 0.1588 - val_acc: 0.5600\n",
            "Epoch 290/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1460 - acc: 0.7200 - val_loss: 0.1585 - val_acc: 0.5600\n",
            "Epoch 291/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1457 - acc: 0.7200 - val_loss: 0.1581 - val_acc: 0.5600\n",
            "Epoch 292/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1454 - acc: 0.7200 - val_loss: 0.1580 - val_acc: 0.5600\n",
            "Epoch 293/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1452 - acc: 0.7200 - val_loss: 0.1578 - val_acc: 0.5600\n",
            "Epoch 294/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1450 - acc: 0.7200 - val_loss: 0.1574 - val_acc: 0.5600\n",
            "Epoch 295/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1447 - acc: 0.7200 - val_loss: 0.1573 - val_acc: 0.5600\n",
            "Epoch 296/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1445 - acc: 0.7200 - val_loss: 0.1570 - val_acc: 0.5600\n",
            "Epoch 297/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1442 - acc: 0.7200 - val_loss: 0.1568 - val_acc: 0.5600\n",
            "Epoch 298/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1440 - acc: 0.7200 - val_loss: 0.1566 - val_acc: 0.5600\n",
            "Epoch 299/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1438 - acc: 0.7200 - val_loss: 0.1564 - val_acc: 0.5600\n",
            "Epoch 300/1500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.1435 - acc: 0.7200 - val_loss: 0.1561 - val_acc: 0.5600\n",
            "Epoch 301/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1432 - acc: 0.7200 - val_loss: 0.1561 - val_acc: 0.5600\n",
            "Epoch 302/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1430 - acc: 0.7200 - val_loss: 0.1561 - val_acc: 0.5600\n",
            "Epoch 303/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1427 - acc: 0.7200 - val_loss: 0.1557 - val_acc: 0.5600\n",
            "Epoch 304/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1425 - acc: 0.7200 - val_loss: 0.1558 - val_acc: 0.5600\n",
            "Epoch 305/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1423 - acc: 0.7200 - val_loss: 0.1555 - val_acc: 0.5600\n",
            "Epoch 306/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1421 - acc: 0.7200 - val_loss: 0.1553 - val_acc: 0.5600\n",
            "Epoch 307/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1419 - acc: 0.7200 - val_loss: 0.1551 - val_acc: 0.5600\n",
            "Epoch 308/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1416 - acc: 0.7200 - val_loss: 0.1549 - val_acc: 0.5600\n",
            "Epoch 309/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1414 - acc: 0.7200 - val_loss: 0.1546 - val_acc: 0.5600\n",
            "Epoch 310/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1412 - acc: 0.7200 - val_loss: 0.1544 - val_acc: 0.5600\n",
            "Epoch 311/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1410 - acc: 0.7200 - val_loss: 0.1543 - val_acc: 0.5600\n",
            "Epoch 312/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1408 - acc: 0.7200 - val_loss: 0.1541 - val_acc: 0.5600\n",
            "Epoch 313/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1406 - acc: 0.7200 - val_loss: 0.1536 - val_acc: 0.5600\n",
            "Epoch 314/1500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.1404 - acc: 0.7200 - val_loss: 0.1533 - val_acc: 0.5600\n",
            "Epoch 315/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.1402 - acc: 0.7200 - val_loss: 0.1533 - val_acc: 0.5600\n",
            "Epoch 316/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1400 - acc: 0.7200 - val_loss: 0.1531 - val_acc: 0.5600\n",
            "Epoch 317/1500\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.1397 - acc: 0.7200 - val_loss: 0.1531 - val_acc: 0.5600\n",
            "Epoch 318/1500\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.1395 - acc: 0.7200 - val_loss: 0.1529 - val_acc: 0.5600\n",
            "Epoch 319/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1393 - acc: 0.7200 - val_loss: 0.1529 - val_acc: 0.5600\n",
            "Epoch 320/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1392 - acc: 0.7200 - val_loss: 0.1528 - val_acc: 0.5600\n",
            "Epoch 321/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1389 - acc: 0.7200 - val_loss: 0.1529 - val_acc: 0.5600\n",
            "Epoch 322/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1387 - acc: 0.7200 - val_loss: 0.1526 - val_acc: 0.5600\n",
            "Epoch 323/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1385 - acc: 0.7200 - val_loss: 0.1525 - val_acc: 0.5600\n",
            "Epoch 324/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1383 - acc: 0.7200 - val_loss: 0.1522 - val_acc: 0.5600\n",
            "Epoch 325/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1382 - acc: 0.7200 - val_loss: 0.1520 - val_acc: 0.5600\n",
            "Epoch 326/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1380 - acc: 0.7200 - val_loss: 0.1519 - val_acc: 0.5600\n",
            "Epoch 327/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1378 - acc: 0.7200 - val_loss: 0.1515 - val_acc: 0.5600\n",
            "Epoch 328/1500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.1376 - acc: 0.7200 - val_loss: 0.1513 - val_acc: 0.5600\n",
            "Epoch 329/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1375 - acc: 0.7200 - val_loss: 0.1515 - val_acc: 0.5600\n",
            "Epoch 330/1500\n",
            "100/100 [==============================] - 0s 137us/sample - loss: 0.1372 - acc: 0.7200 - val_loss: 0.1512 - val_acc: 0.5600\n",
            "Epoch 331/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1370 - acc: 0.7200 - val_loss: 0.1512 - val_acc: 0.5600\n",
            "Epoch 332/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1369 - acc: 0.7200 - val_loss: 0.1512 - val_acc: 0.5600\n",
            "Epoch 333/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1367 - acc: 0.7200 - val_loss: 0.1508 - val_acc: 0.5600\n",
            "Epoch 334/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1365 - acc: 0.7200 - val_loss: 0.1506 - val_acc: 0.5600\n",
            "Epoch 335/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1363 - acc: 0.7200 - val_loss: 0.1503 - val_acc: 0.5600\n",
            "Epoch 336/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1362 - acc: 0.7200 - val_loss: 0.1503 - val_acc: 0.5600\n",
            "Epoch 337/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1360 - acc: 0.7200 - val_loss: 0.1501 - val_acc: 0.5600\n",
            "Epoch 338/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.1358 - acc: 0.7200 - val_loss: 0.1499 - val_acc: 0.5600\n",
            "Epoch 339/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1356 - acc: 0.7200 - val_loss: 0.1497 - val_acc: 0.5600\n",
            "Epoch 340/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1355 - acc: 0.7200 - val_loss: 0.1495 - val_acc: 0.5600\n",
            "Epoch 341/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1353 - acc: 0.7200 - val_loss: 0.1496 - val_acc: 0.5600\n",
            "Epoch 342/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1352 - acc: 0.7200 - val_loss: 0.1495 - val_acc: 0.5600\n",
            "Epoch 343/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1350 - acc: 0.7200 - val_loss: 0.1493 - val_acc: 0.5600\n",
            "Epoch 344/1500\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.1348 - acc: 0.7200 - val_loss: 0.1491 - val_acc: 0.5600\n",
            "Epoch 345/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1347 - acc: 0.7200 - val_loss: 0.1490 - val_acc: 0.5600\n",
            "Epoch 346/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1345 - acc: 0.7200 - val_loss: 0.1491 - val_acc: 0.5600\n",
            "Epoch 347/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1344 - acc: 0.7200 - val_loss: 0.1488 - val_acc: 0.5600\n",
            "Epoch 348/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1342 - acc: 0.7200 - val_loss: 0.1486 - val_acc: 0.5600\n",
            "Epoch 349/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1341 - acc: 0.7200 - val_loss: 0.1486 - val_acc: 0.5600\n",
            "Epoch 350/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1339 - acc: 0.7200 - val_loss: 0.1485 - val_acc: 0.5600\n",
            "Epoch 351/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1337 - acc: 0.7200 - val_loss: 0.1483 - val_acc: 0.5600\n",
            "Epoch 352/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1336 - acc: 0.7200 - val_loss: 0.1483 - val_acc: 0.5600\n",
            "Epoch 353/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1335 - acc: 0.7200 - val_loss: 0.1483 - val_acc: 0.5600\n",
            "Epoch 354/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1333 - acc: 0.7200 - val_loss: 0.1480 - val_acc: 0.5600\n",
            "Epoch 355/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1331 - acc: 0.7200 - val_loss: 0.1479 - val_acc: 0.5600\n",
            "Epoch 356/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1330 - acc: 0.7200 - val_loss: 0.1478 - val_acc: 0.5600\n",
            "Epoch 357/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1329 - acc: 0.7200 - val_loss: 0.1477 - val_acc: 0.5600\n",
            "Epoch 358/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1327 - acc: 0.7200 - val_loss: 0.1475 - val_acc: 0.5600\n",
            "Epoch 359/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1326 - acc: 0.7200 - val_loss: 0.1473 - val_acc: 0.5600\n",
            "Epoch 360/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1324 - acc: 0.7200 - val_loss: 0.1470 - val_acc: 0.5600\n",
            "Epoch 361/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1322 - acc: 0.7200 - val_loss: 0.1469 - val_acc: 0.5600\n",
            "Epoch 362/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1321 - acc: 0.7200 - val_loss: 0.1468 - val_acc: 0.5600\n",
            "Epoch 363/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1320 - acc: 0.7200 - val_loss: 0.1468 - val_acc: 0.5600\n",
            "Epoch 364/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1318 - acc: 0.7200 - val_loss: 0.1466 - val_acc: 0.5600\n",
            "Epoch 365/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1317 - acc: 0.7200 - val_loss: 0.1465 - val_acc: 0.5600\n",
            "Epoch 366/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1316 - acc: 0.7200 - val_loss: 0.1463 - val_acc: 0.5600\n",
            "Epoch 367/1500\n",
            "100/100 [==============================] - 0s 160us/sample - loss: 0.1314 - acc: 0.7200 - val_loss: 0.1461 - val_acc: 0.5600\n",
            "Epoch 368/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1313 - acc: 0.7200 - val_loss: 0.1460 - val_acc: 0.5600\n",
            "Epoch 369/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.1312 - acc: 0.7200 - val_loss: 0.1460 - val_acc: 0.5600\n",
            "Epoch 370/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1310 - acc: 0.7200 - val_loss: 0.1460 - val_acc: 0.5600\n",
            "Epoch 371/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1309 - acc: 0.7200 - val_loss: 0.1459 - val_acc: 0.5600\n",
            "Epoch 372/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1308 - acc: 0.7200 - val_loss: 0.1457 - val_acc: 0.5600\n",
            "Epoch 373/1500\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.1307 - acc: 0.7200 - val_loss: 0.1457 - val_acc: 0.5600\n",
            "Epoch 374/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1306 - acc: 0.7200 - val_loss: 0.1454 - val_acc: 0.5600\n",
            "Epoch 375/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1304 - acc: 0.7200 - val_loss: 0.1456 - val_acc: 0.5600\n",
            "Epoch 376/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1303 - acc: 0.7200 - val_loss: 0.1452 - val_acc: 0.5600\n",
            "Epoch 377/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1302 - acc: 0.7200 - val_loss: 0.1447 - val_acc: 0.5600\n",
            "Epoch 378/1500\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.1300 - acc: 0.7200 - val_loss: 0.1446 - val_acc: 0.5600\n",
            "Epoch 379/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1299 - acc: 0.7200 - val_loss: 0.1446 - val_acc: 0.5600\n",
            "Epoch 380/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1298 - acc: 0.7200 - val_loss: 0.1443 - val_acc: 0.5600\n",
            "Epoch 381/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1297 - acc: 0.7200 - val_loss: 0.1441 - val_acc: 0.5600\n",
            "Epoch 382/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1296 - acc: 0.7200 - val_loss: 0.1442 - val_acc: 0.5600\n",
            "Epoch 383/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1295 - acc: 0.7200 - val_loss: 0.1441 - val_acc: 0.5600\n",
            "Epoch 384/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1293 - acc: 0.7200 - val_loss: 0.1441 - val_acc: 0.5600\n",
            "Epoch 385/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1292 - acc: 0.7200 - val_loss: 0.1437 - val_acc: 0.5600\n",
            "Epoch 386/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1291 - acc: 0.7200 - val_loss: 0.1435 - val_acc: 0.5600\n",
            "Epoch 387/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1290 - acc: 0.7200 - val_loss: 0.1434 - val_acc: 0.5600\n",
            "Epoch 388/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1289 - acc: 0.7200 - val_loss: 0.1434 - val_acc: 0.5600\n",
            "Epoch 389/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1288 - acc: 0.7200 - val_loss: 0.1431 - val_acc: 0.5600\n",
            "Epoch 390/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1287 - acc: 0.7200 - val_loss: 0.1427 - val_acc: 0.5600\n",
            "Epoch 391/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1286 - acc: 0.7200 - val_loss: 0.1425 - val_acc: 0.5600\n",
            "Epoch 392/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1284 - acc: 0.7200 - val_loss: 0.1425 - val_acc: 0.5600\n",
            "Epoch 393/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1283 - acc: 0.7200 - val_loss: 0.1424 - val_acc: 0.5600\n",
            "Epoch 394/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1283 - acc: 0.7200 - val_loss: 0.1423 - val_acc: 0.5600\n",
            "Epoch 395/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1281 - acc: 0.7200 - val_loss: 0.1420 - val_acc: 0.5600\n",
            "Epoch 396/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1280 - acc: 0.7200 - val_loss: 0.1419 - val_acc: 0.5600\n",
            "Epoch 397/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1279 - acc: 0.7200 - val_loss: 0.1417 - val_acc: 0.5600\n",
            "Epoch 398/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1278 - acc: 0.7200 - val_loss: 0.1419 - val_acc: 0.5600\n",
            "Epoch 399/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1277 - acc: 0.7200 - val_loss: 0.1420 - val_acc: 0.5600\n",
            "Epoch 400/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1276 - acc: 0.7200 - val_loss: 0.1420 - val_acc: 0.5600\n",
            "Epoch 401/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1275 - acc: 0.7200 - val_loss: 0.1420 - val_acc: 0.5600\n",
            "Epoch 402/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1274 - acc: 0.7200 - val_loss: 0.1419 - val_acc: 0.5600\n",
            "Epoch 403/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1273 - acc: 0.7200 - val_loss: 0.1418 - val_acc: 0.5600\n",
            "Epoch 404/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1272 - acc: 0.7200 - val_loss: 0.1415 - val_acc: 0.5600\n",
            "Epoch 405/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1271 - acc: 0.7200 - val_loss: 0.1412 - val_acc: 0.5600\n",
            "Epoch 406/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1270 - acc: 0.7200 - val_loss: 0.1411 - val_acc: 0.5600\n",
            "Epoch 407/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1269 - acc: 0.7200 - val_loss: 0.1410 - val_acc: 0.5600\n",
            "Epoch 408/1500\n",
            "100/100 [==============================] - 0s 218us/sample - loss: 0.1268 - acc: 0.7200 - val_loss: 0.1411 - val_acc: 0.5600\n",
            "Epoch 409/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1267 - acc: 0.7200 - val_loss: 0.1410 - val_acc: 0.5600\n",
            "Epoch 410/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1266 - acc: 0.7200 - val_loss: 0.1408 - val_acc: 0.5600\n",
            "Epoch 411/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1265 - acc: 0.7200 - val_loss: 0.1408 - val_acc: 0.5600\n",
            "Epoch 412/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1264 - acc: 0.7200 - val_loss: 0.1406 - val_acc: 0.5600\n",
            "Epoch 413/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1263 - acc: 0.7200 - val_loss: 0.1404 - val_acc: 0.5600\n",
            "Epoch 414/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1262 - acc: 0.7200 - val_loss: 0.1404 - val_acc: 0.5600\n",
            "Epoch 415/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1261 - acc: 0.7200 - val_loss: 0.1404 - val_acc: 0.5600\n",
            "Epoch 416/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1261 - acc: 0.7200 - val_loss: 0.1402 - val_acc: 0.5600\n",
            "Epoch 417/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1260 - acc: 0.7200 - val_loss: 0.1400 - val_acc: 0.5600\n",
            "Epoch 418/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1258 - acc: 0.7200 - val_loss: 0.1400 - val_acc: 0.5600\n",
            "Epoch 419/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1258 - acc: 0.7200 - val_loss: 0.1399 - val_acc: 0.5600\n",
            "Epoch 420/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1257 - acc: 0.7200 - val_loss: 0.1399 - val_acc: 0.5600\n",
            "Epoch 421/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1256 - acc: 0.7200 - val_loss: 0.1397 - val_acc: 0.5600\n",
            "Epoch 422/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1256 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 423/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1254 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 424/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.1253 - acc: 0.7200 - val_loss: 0.1391 - val_acc: 0.5600\n",
            "Epoch 425/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1253 - acc: 0.7200 - val_loss: 0.1393 - val_acc: 0.5600\n",
            "Epoch 426/1500\n",
            "100/100 [==============================] - 0s 140us/sample - loss: 0.1252 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 427/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1251 - acc: 0.7200 - val_loss: 0.1392 - val_acc: 0.5600\n",
            "Epoch 428/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1250 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 429/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1249 - acc: 0.7200 - val_loss: 0.1395 - val_acc: 0.5600\n",
            "Epoch 430/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1248 - acc: 0.7200 - val_loss: 0.1395 - val_acc: 0.5600\n",
            "Epoch 431/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1248 - acc: 0.7200 - val_loss: 0.1397 - val_acc: 0.5600\n",
            "Epoch 432/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1246 - acc: 0.7200 - val_loss: 0.1396 - val_acc: 0.5600\n",
            "Epoch 433/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1246 - acc: 0.7200 - val_loss: 0.1395 - val_acc: 0.5600\n",
            "Epoch 434/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1245 - acc: 0.7200 - val_loss: 0.1396 - val_acc: 0.5600\n",
            "Epoch 435/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1244 - acc: 0.7200 - val_loss: 0.1396 - val_acc: 0.5600\n",
            "Epoch 436/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1243 - acc: 0.7200 - val_loss: 0.1397 - val_acc: 0.5600\n",
            "Epoch 437/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1243 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 438/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1242 - acc: 0.7200 - val_loss: 0.1394 - val_acc: 0.5600\n",
            "Epoch 439/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1241 - acc: 0.7200 - val_loss: 0.1395 - val_acc: 0.5600\n",
            "Epoch 440/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1241 - acc: 0.7200 - val_loss: 0.1389 - val_acc: 0.5600\n",
            "Epoch 441/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1239 - acc: 0.7200 - val_loss: 0.1389 - val_acc: 0.5600\n",
            "Epoch 442/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1239 - acc: 0.7200 - val_loss: 0.1388 - val_acc: 0.5600\n",
            "Epoch 443/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1238 - acc: 0.7200 - val_loss: 0.1388 - val_acc: 0.5600\n",
            "Epoch 444/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1238 - acc: 0.7200 - val_loss: 0.1390 - val_acc: 0.5600\n",
            "Epoch 445/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1237 - acc: 0.7200 - val_loss: 0.1391 - val_acc: 0.5600\n",
            "Epoch 446/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1236 - acc: 0.7200 - val_loss: 0.1390 - val_acc: 0.5600\n",
            "Epoch 447/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1235 - acc: 0.7200 - val_loss: 0.1393 - val_acc: 0.5600\n",
            "Epoch 448/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1234 - acc: 0.7200 - val_loss: 0.1391 - val_acc: 0.5600\n",
            "Epoch 449/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1234 - acc: 0.7200 - val_loss: 0.1389 - val_acc: 0.5600\n",
            "Epoch 450/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1233 - acc: 0.7200 - val_loss: 0.1384 - val_acc: 0.5600\n",
            "Epoch 451/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1232 - acc: 0.7200 - val_loss: 0.1382 - val_acc: 0.5600\n",
            "Epoch 452/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1232 - acc: 0.7200 - val_loss: 0.1378 - val_acc: 0.5600\n",
            "Epoch 453/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1231 - acc: 0.7200 - val_loss: 0.1378 - val_acc: 0.5600\n",
            "Epoch 454/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1230 - acc: 0.7200 - val_loss: 0.1377 - val_acc: 0.5600\n",
            "Epoch 455/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1229 - acc: 0.7200 - val_loss: 0.1377 - val_acc: 0.5600\n",
            "Epoch 456/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1228 - acc: 0.7200 - val_loss: 0.1377 - val_acc: 0.5600\n",
            "Epoch 457/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1228 - acc: 0.7200 - val_loss: 0.1374 - val_acc: 0.5600\n",
            "Epoch 458/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1227 - acc: 0.7200 - val_loss: 0.1371 - val_acc: 0.5600\n",
            "Epoch 459/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1226 - acc: 0.7200 - val_loss: 0.1371 - val_acc: 0.5600\n",
            "Epoch 460/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1225 - acc: 0.7200 - val_loss: 0.1369 - val_acc: 0.5600\n",
            "Epoch 461/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1225 - acc: 0.7200 - val_loss: 0.1367 - val_acc: 0.5600\n",
            "Epoch 462/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1224 - acc: 0.7200 - val_loss: 0.1365 - val_acc: 0.5600\n",
            "Epoch 463/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1223 - acc: 0.7200 - val_loss: 0.1365 - val_acc: 0.5600\n",
            "Epoch 464/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1223 - acc: 0.7200 - val_loss: 0.1365 - val_acc: 0.5600\n",
            "Epoch 465/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1222 - acc: 0.7200 - val_loss: 0.1365 - val_acc: 0.5600\n",
            "Epoch 466/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1222 - acc: 0.7200 - val_loss: 0.1369 - val_acc: 0.5600\n",
            "Epoch 467/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1221 - acc: 0.7200 - val_loss: 0.1367 - val_acc: 0.5600\n",
            "Epoch 468/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1220 - acc: 0.7200 - val_loss: 0.1366 - val_acc: 0.5600\n",
            "Epoch 469/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1219 - acc: 0.7200 - val_loss: 0.1363 - val_acc: 0.5600\n",
            "Epoch 470/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1219 - acc: 0.7200 - val_loss: 0.1361 - val_acc: 0.5600\n",
            "Epoch 471/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1218 - acc: 0.7200 - val_loss: 0.1359 - val_acc: 0.5600\n",
            "Epoch 472/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1217 - acc: 0.7200 - val_loss: 0.1360 - val_acc: 0.5600\n",
            "Epoch 473/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1217 - acc: 0.7200 - val_loss: 0.1357 - val_acc: 0.5600\n",
            "Epoch 474/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1216 - acc: 0.7200 - val_loss: 0.1356 - val_acc: 0.5600\n",
            "Epoch 475/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1215 - acc: 0.7200 - val_loss: 0.1357 - val_acc: 0.5600\n",
            "Epoch 476/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1215 - acc: 0.7200 - val_loss: 0.1357 - val_acc: 0.5600\n",
            "Epoch 477/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1215 - acc: 0.7200 - val_loss: 0.1358 - val_acc: 0.5600\n",
            "Epoch 478/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1214 - acc: 0.7200 - val_loss: 0.1358 - val_acc: 0.5600\n",
            "Epoch 479/1500\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.1213 - acc: 0.7200 - val_loss: 0.1356 - val_acc: 0.5600\n",
            "Epoch 480/1500\n",
            "100/100 [==============================] - 0s 147us/sample - loss: 0.1212 - acc: 0.7200 - val_loss: 0.1356 - val_acc: 0.5600\n",
            "Epoch 481/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1212 - acc: 0.7200 - val_loss: 0.1357 - val_acc: 0.5600\n",
            "Epoch 482/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1211 - acc: 0.7200 - val_loss: 0.1355 - val_acc: 0.5600\n",
            "Epoch 483/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1210 - acc: 0.7200 - val_loss: 0.1353 - val_acc: 0.5600\n",
            "Epoch 484/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1210 - acc: 0.7200 - val_loss: 0.1352 - val_acc: 0.5600\n",
            "Epoch 485/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1210 - acc: 0.7200 - val_loss: 0.1353 - val_acc: 0.5600\n",
            "Epoch 486/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1208 - acc: 0.7200 - val_loss: 0.1353 - val_acc: 0.5600\n",
            "Epoch 487/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1208 - acc: 0.7200 - val_loss: 0.1353 - val_acc: 0.5600\n",
            "Epoch 488/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1208 - acc: 0.7200 - val_loss: 0.1351 - val_acc: 0.5600\n",
            "Epoch 489/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1207 - acc: 0.7200 - val_loss: 0.1353 - val_acc: 0.5600\n",
            "Epoch 490/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1206 - acc: 0.7200 - val_loss: 0.1352 - val_acc: 0.5600\n",
            "Epoch 491/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1206 - acc: 0.7200 - val_loss: 0.1351 - val_acc: 0.5600\n",
            "Epoch 492/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.1205 - acc: 0.7200 - val_loss: 0.1351 - val_acc: 0.5600\n",
            "Epoch 493/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1204 - acc: 0.7200 - val_loss: 0.1351 - val_acc: 0.5600\n",
            "Epoch 494/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1204 - acc: 0.7200 - val_loss: 0.1351 - val_acc: 0.5600\n",
            "Epoch 495/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1203 - acc: 0.7200 - val_loss: 0.1350 - val_acc: 0.5600\n",
            "Epoch 496/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1203 - acc: 0.7200 - val_loss: 0.1349 - val_acc: 0.5600\n",
            "Epoch 497/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1202 - acc: 0.7200 - val_loss: 0.1349 - val_acc: 0.5600\n",
            "Epoch 498/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1201 - acc: 0.7200 - val_loss: 0.1349 - val_acc: 0.5600\n",
            "Epoch 499/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1202 - acc: 0.7200 - val_loss: 0.1349 - val_acc: 0.5600\n",
            "Epoch 500/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1200 - acc: 0.7200 - val_loss: 0.1347 - val_acc: 0.5600\n",
            "Epoch 501/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1200 - acc: 0.7200 - val_loss: 0.1349 - val_acc: 0.5600\n",
            "Epoch 502/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1199 - acc: 0.7200 - val_loss: 0.1348 - val_acc: 0.5600\n",
            "Epoch 503/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1199 - acc: 0.7200 - val_loss: 0.1345 - val_acc: 0.5600\n",
            "Epoch 504/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1198 - acc: 0.7200 - val_loss: 0.1343 - val_acc: 0.5600\n",
            "Epoch 505/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1198 - acc: 0.7200 - val_loss: 0.1342 - val_acc: 0.5600\n",
            "Epoch 506/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1197 - acc: 0.7200 - val_loss: 0.1340 - val_acc: 0.5600\n",
            "Epoch 507/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1197 - acc: 0.7200 - val_loss: 0.1339 - val_acc: 0.5600\n",
            "Epoch 508/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1196 - acc: 0.7200 - val_loss: 0.1338 - val_acc: 0.5600\n",
            "Epoch 509/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1195 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 510/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1195 - acc: 0.7200 - val_loss: 0.1333 - val_acc: 0.5600\n",
            "Epoch 511/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1194 - acc: 0.7200 - val_loss: 0.1333 - val_acc: 0.5600\n",
            "Epoch 512/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1194 - acc: 0.7200 - val_loss: 0.1335 - val_acc: 0.5600\n",
            "Epoch 513/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1193 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 514/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1193 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 515/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1192 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 516/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1192 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 517/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1191 - acc: 0.7200 - val_loss: 0.1333 - val_acc: 0.5600\n",
            "Epoch 518/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1191 - acc: 0.7200 - val_loss: 0.1335 - val_acc: 0.5600\n",
            "Epoch 519/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1190 - acc: 0.7200 - val_loss: 0.1335 - val_acc: 0.5600\n",
            "Epoch 520/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1189 - acc: 0.7200 - val_loss: 0.1333 - val_acc: 0.5600\n",
            "Epoch 521/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1189 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 522/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1188 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 523/1500\n",
            "100/100 [==============================] - 0s 193us/sample - loss: 0.1188 - acc: 0.7200 - val_loss: 0.1336 - val_acc: 0.5600\n",
            "Epoch 524/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1187 - acc: 0.7200 - val_loss: 0.1333 - val_acc: 0.5600\n",
            "Epoch 525/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1187 - acc: 0.7200 - val_loss: 0.1332 - val_acc: 0.5600\n",
            "Epoch 526/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1186 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 527/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1186 - acc: 0.7200 - val_loss: 0.1337 - val_acc: 0.5600\n",
            "Epoch 528/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1185 - acc: 0.7200 - val_loss: 0.1337 - val_acc: 0.5600\n",
            "Epoch 529/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1185 - acc: 0.7200 - val_loss: 0.1337 - val_acc: 0.5600\n",
            "Epoch 530/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1184 - acc: 0.7200 - val_loss: 0.1335 - val_acc: 0.5600\n",
            "Epoch 531/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1184 - acc: 0.7200 - val_loss: 0.1336 - val_acc: 0.5600\n",
            "Epoch 532/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1184 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 533/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1183 - acc: 0.7200 - val_loss: 0.1334 - val_acc: 0.5600\n",
            "Epoch 534/1500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.1182 - acc: 0.7200 - val_loss: 0.1332 - val_acc: 0.5600\n",
            "Epoch 535/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1182 - acc: 0.7200 - val_loss: 0.1333 - val_acc: 0.5600\n",
            "Epoch 536/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1181 - acc: 0.7200 - val_loss: 0.1331 - val_acc: 0.5600\n",
            "Epoch 537/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1181 - acc: 0.7200 - val_loss: 0.1328 - val_acc: 0.5600\n",
            "Epoch 538/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1180 - acc: 0.7200 - val_loss: 0.1331 - val_acc: 0.5600\n",
            "Epoch 539/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1180 - acc: 0.7200 - val_loss: 0.1330 - val_acc: 0.5600\n",
            "Epoch 540/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1180 - acc: 0.7200 - val_loss: 0.1329 - val_acc: 0.5600\n",
            "Epoch 541/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1179 - acc: 0.7200 - val_loss: 0.1329 - val_acc: 0.5600\n",
            "Epoch 542/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1178 - acc: 0.7200 - val_loss: 0.1328 - val_acc: 0.5600\n",
            "Epoch 543/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1178 - acc: 0.7200 - val_loss: 0.1326 - val_acc: 0.5600\n",
            "Epoch 544/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1177 - acc: 0.7200 - val_loss: 0.1326 - val_acc: 0.5600\n",
            "Epoch 545/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1177 - acc: 0.7200 - val_loss: 0.1328 - val_acc: 0.5600\n",
            "Epoch 546/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1176 - acc: 0.7200 - val_loss: 0.1329 - val_acc: 0.5600\n",
            "Epoch 547/1500\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.1177 - acc: 0.7200 - val_loss: 0.1330 - val_acc: 0.5600\n",
            "Epoch 548/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1175 - acc: 0.7200 - val_loss: 0.1330 - val_acc: 0.5600\n",
            "Epoch 549/1500\n",
            "100/100 [==============================] - 0s 188us/sample - loss: 0.1175 - acc: 0.7200 - val_loss: 0.1329 - val_acc: 0.5600\n",
            "Epoch 550/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1174 - acc: 0.7200 - val_loss: 0.1326 - val_acc: 0.5600\n",
            "Epoch 551/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1174 - acc: 0.7200 - val_loss: 0.1326 - val_acc: 0.5600\n",
            "Epoch 552/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1174 - acc: 0.7200 - val_loss: 0.1322 - val_acc: 0.5600\n",
            "Epoch 553/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1173 - acc: 0.7200 - val_loss: 0.1324 - val_acc: 0.5600\n",
            "Epoch 554/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1172 - acc: 0.7200 - val_loss: 0.1323 - val_acc: 0.5600\n",
            "Epoch 555/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1172 - acc: 0.7200 - val_loss: 0.1323 - val_acc: 0.5600\n",
            "Epoch 556/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1171 - acc: 0.7200 - val_loss: 0.1321 - val_acc: 0.5600\n",
            "Epoch 557/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1171 - acc: 0.7200 - val_loss: 0.1322 - val_acc: 0.5600\n",
            "Epoch 558/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1171 - acc: 0.7200 - val_loss: 0.1319 - val_acc: 0.5600\n",
            "Epoch 559/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1170 - acc: 0.7200 - val_loss: 0.1321 - val_acc: 0.5600\n",
            "Epoch 560/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1169 - acc: 0.7200 - val_loss: 0.1321 - val_acc: 0.5600\n",
            "Epoch 561/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1169 - acc: 0.7200 - val_loss: 0.1323 - val_acc: 0.5600\n",
            "Epoch 562/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1168 - acc: 0.7200 - val_loss: 0.1320 - val_acc: 0.5600\n",
            "Epoch 563/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1168 - acc: 0.7200 - val_loss: 0.1319 - val_acc: 0.5600\n",
            "Epoch 564/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1167 - acc: 0.7200 - val_loss: 0.1318 - val_acc: 0.5600\n",
            "Epoch 565/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1167 - acc: 0.7200 - val_loss: 0.1319 - val_acc: 0.5600\n",
            "Epoch 566/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1167 - acc: 0.7200 - val_loss: 0.1320 - val_acc: 0.5600\n",
            "Epoch 567/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1166 - acc: 0.7200 - val_loss: 0.1317 - val_acc: 0.5600\n",
            "Epoch 568/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1165 - acc: 0.7200 - val_loss: 0.1315 - val_acc: 0.5600\n",
            "Epoch 569/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1165 - acc: 0.7200 - val_loss: 0.1313 - val_acc: 0.5600\n",
            "Epoch 570/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1165 - acc: 0.7200 - val_loss: 0.1312 - val_acc: 0.5600\n",
            "Epoch 571/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1164 - acc: 0.7200 - val_loss: 0.1311 - val_acc: 0.5600\n",
            "Epoch 572/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.1164 - acc: 0.7200 - val_loss: 0.1313 - val_acc: 0.5600\n",
            "Epoch 573/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1164 - acc: 0.7200 - val_loss: 0.1311 - val_acc: 0.5600\n",
            "Epoch 574/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1163 - acc: 0.7200 - val_loss: 0.1311 - val_acc: 0.5600\n",
            "Epoch 575/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1162 - acc: 0.7200 - val_loss: 0.1309 - val_acc: 0.5600\n",
            "Epoch 576/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1162 - acc: 0.7200 - val_loss: 0.1311 - val_acc: 0.5600\n",
            "Epoch 577/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1161 - acc: 0.7200 - val_loss: 0.1307 - val_acc: 0.5600\n",
            "Epoch 578/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1161 - acc: 0.7200 - val_loss: 0.1306 - val_acc: 0.5600\n",
            "Epoch 579/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1160 - acc: 0.7200 - val_loss: 0.1307 - val_acc: 0.5600\n",
            "Epoch 580/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1160 - acc: 0.7200 - val_loss: 0.1308 - val_acc: 0.5600\n",
            "Epoch 581/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1160 - acc: 0.7200 - val_loss: 0.1306 - val_acc: 0.5600\n",
            "Epoch 582/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1159 - acc: 0.7200 - val_loss: 0.1305 - val_acc: 0.5600\n",
            "Epoch 583/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1158 - acc: 0.7200 - val_loss: 0.1304 - val_acc: 0.5600\n",
            "Epoch 584/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1158 - acc: 0.7200 - val_loss: 0.1305 - val_acc: 0.5600\n",
            "Epoch 585/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1157 - acc: 0.7200 - val_loss: 0.1304 - val_acc: 0.5600\n",
            "Epoch 586/1500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.1157 - acc: 0.7200 - val_loss: 0.1304 - val_acc: 0.5600\n",
            "Epoch 587/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1156 - acc: 0.7200 - val_loss: 0.1304 - val_acc: 0.5600\n",
            "Epoch 588/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1156 - acc: 0.7200 - val_loss: 0.1303 - val_acc: 0.5600\n",
            "Epoch 589/1500\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.1156 - acc: 0.7200 - val_loss: 0.1303 - val_acc: 0.5600\n",
            "Epoch 590/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1155 - acc: 0.7200 - val_loss: 0.1301 - val_acc: 0.5600\n",
            "Epoch 591/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1154 - acc: 0.7200 - val_loss: 0.1300 - val_acc: 0.5600\n",
            "Epoch 592/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1154 - acc: 0.7200 - val_loss: 0.1298 - val_acc: 0.5600\n",
            "Epoch 593/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.1153 - acc: 0.7200 - val_loss: 0.1297 - val_acc: 0.5600\n",
            "Epoch 594/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1153 - acc: 0.7200 - val_loss: 0.1297 - val_acc: 0.5600\n",
            "Epoch 595/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1153 - acc: 0.7200 - val_loss: 0.1293 - val_acc: 0.5600\n",
            "Epoch 596/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1152 - acc: 0.7200 - val_loss: 0.1294 - val_acc: 0.5600\n",
            "Epoch 597/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1152 - acc: 0.7200 - val_loss: 0.1292 - val_acc: 0.5600\n",
            "Epoch 598/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1151 - acc: 0.7200 - val_loss: 0.1292 - val_acc: 0.5600\n",
            "Epoch 599/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1151 - acc: 0.7200 - val_loss: 0.1289 - val_acc: 0.5600\n",
            "Epoch 600/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1151 - acc: 0.7200 - val_loss: 0.1291 - val_acc: 0.5600\n",
            "Epoch 601/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1150 - acc: 0.7200 - val_loss: 0.1292 - val_acc: 0.5600\n",
            "Epoch 602/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1150 - acc: 0.7200 - val_loss: 0.1292 - val_acc: 0.5600\n",
            "Epoch 603/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.1149 - acc: 0.7200 - val_loss: 0.1290 - val_acc: 0.5600\n",
            "Epoch 604/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1149 - acc: 0.7200 - val_loss: 0.1291 - val_acc: 0.5600\n",
            "Epoch 605/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1148 - acc: 0.7200 - val_loss: 0.1291 - val_acc: 0.5600\n",
            "Epoch 606/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1147 - acc: 0.7200 - val_loss: 0.1290 - val_acc: 0.5600\n",
            "Epoch 607/1500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.1147 - acc: 0.7200 - val_loss: 0.1291 - val_acc: 0.5600\n",
            "Epoch 608/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1147 - acc: 0.7200 - val_loss: 0.1289 - val_acc: 0.5600\n",
            "Epoch 609/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1146 - acc: 0.7200 - val_loss: 0.1287 - val_acc: 0.5600\n",
            "Epoch 610/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1146 - acc: 0.7200 - val_loss: 0.1286 - val_acc: 0.5600\n",
            "Epoch 611/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1146 - acc: 0.7200 - val_loss: 0.1285 - val_acc: 0.5600\n",
            "Epoch 612/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1145 - acc: 0.7200 - val_loss: 0.1286 - val_acc: 0.5600\n",
            "Epoch 613/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1145 - acc: 0.7200 - val_loss: 0.1288 - val_acc: 0.5600\n",
            "Epoch 614/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1144 - acc: 0.7200 - val_loss: 0.1288 - val_acc: 0.5600\n",
            "Epoch 615/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1143 - acc: 0.7200 - val_loss: 0.1286 - val_acc: 0.5600\n",
            "Epoch 616/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1143 - acc: 0.7200 - val_loss: 0.1285 - val_acc: 0.5600\n",
            "Epoch 617/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1143 - acc: 0.7200 - val_loss: 0.1285 - val_acc: 0.5600\n",
            "Epoch 618/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1142 - acc: 0.7200 - val_loss: 0.1285 - val_acc: 0.5600\n",
            "Epoch 619/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1142 - acc: 0.7200 - val_loss: 0.1281 - val_acc: 0.5600\n",
            "Epoch 620/1500\n",
            "100/100 [==============================] - 0s 176us/sample - loss: 0.1141 - acc: 0.7200 - val_loss: 0.1279 - val_acc: 0.5600\n",
            "Epoch 621/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1141 - acc: 0.7200 - val_loss: 0.1279 - val_acc: 0.5600\n",
            "Epoch 622/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1141 - acc: 0.7200 - val_loss: 0.1275 - val_acc: 0.5600\n",
            "Epoch 623/1500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.1141 - acc: 0.7200 - val_loss: 0.1275 - val_acc: 0.5600\n",
            "Epoch 624/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1139 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 625/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1139 - acc: 0.7200 - val_loss: 0.1275 - val_acc: 0.5600\n",
            "Epoch 626/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1139 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 627/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1139 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 628/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1138 - acc: 0.7200 - val_loss: 0.1277 - val_acc: 0.5600\n",
            "Epoch 629/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1137 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 630/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1137 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 631/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.1136 - acc: 0.7200 - val_loss: 0.1275 - val_acc: 0.5600\n",
            "Epoch 632/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1136 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 633/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1136 - acc: 0.7200 - val_loss: 0.1279 - val_acc: 0.5600\n",
            "Epoch 634/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1135 - acc: 0.7200 - val_loss: 0.1279 - val_acc: 0.5600\n",
            "Epoch 635/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1135 - acc: 0.7200 - val_loss: 0.1278 - val_acc: 0.5600\n",
            "Epoch 636/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1134 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 637/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1134 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 638/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1133 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 639/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1133 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 640/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1132 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 641/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1132 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 642/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1132 - acc: 0.7200 - val_loss: 0.1276 - val_acc: 0.5600\n",
            "Epoch 643/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1131 - acc: 0.7200 - val_loss: 0.1279 - val_acc: 0.5600\n",
            "Epoch 644/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1131 - acc: 0.7200 - val_loss: 0.1281 - val_acc: 0.5600\n",
            "Epoch 645/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1131 - acc: 0.7200 - val_loss: 0.1281 - val_acc: 0.5600\n",
            "Epoch 646/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1130 - acc: 0.7200 - val_loss: 0.1278 - val_acc: 0.5600\n",
            "Epoch 647/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1129 - acc: 0.7200 - val_loss: 0.1277 - val_acc: 0.5600\n",
            "Epoch 648/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1129 - acc: 0.7200 - val_loss: 0.1278 - val_acc: 0.5600\n",
            "Epoch 649/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1129 - acc: 0.7200 - val_loss: 0.1278 - val_acc: 0.5600\n",
            "Epoch 650/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1129 - acc: 0.7200 - val_loss: 0.1274 - val_acc: 0.5600\n",
            "Epoch 651/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1128 - acc: 0.7200 - val_loss: 0.1272 - val_acc: 0.5600\n",
            "Epoch 652/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1127 - acc: 0.7200 - val_loss: 0.1269 - val_acc: 0.5600\n",
            "Epoch 653/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1127 - acc: 0.7200 - val_loss: 0.1272 - val_acc: 0.5600\n",
            "Epoch 654/1500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.1127 - acc: 0.7200 - val_loss: 0.1271 - val_acc: 0.5600\n",
            "Epoch 655/1500\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.1126 - acc: 0.7200 - val_loss: 0.1269 - val_acc: 0.5600\n",
            "Epoch 656/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1126 - acc: 0.7200 - val_loss: 0.1270 - val_acc: 0.5600\n",
            "Epoch 657/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1125 - acc: 0.7200 - val_loss: 0.1271 - val_acc: 0.5600\n",
            "Epoch 658/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1125 - acc: 0.7200 - val_loss: 0.1271 - val_acc: 0.5600\n",
            "Epoch 659/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1124 - acc: 0.7200 - val_loss: 0.1272 - val_acc: 0.5600\n",
            "Epoch 660/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1124 - acc: 0.7200 - val_loss: 0.1271 - val_acc: 0.5600\n",
            "Epoch 661/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1124 - acc: 0.7200 - val_loss: 0.1272 - val_acc: 0.5600\n",
            "Epoch 662/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1125 - acc: 0.7200 - val_loss: 0.1270 - val_acc: 0.5600\n",
            "Epoch 663/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1123 - acc: 0.7200 - val_loss: 0.1269 - val_acc: 0.5600\n",
            "Epoch 664/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1123 - acc: 0.7200 - val_loss: 0.1267 - val_acc: 0.5600\n",
            "Epoch 665/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1122 - acc: 0.7200 - val_loss: 0.1265 - val_acc: 0.5600\n",
            "Epoch 666/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1122 - acc: 0.7200 - val_loss: 0.1266 - val_acc: 0.5600\n",
            "Epoch 667/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1121 - acc: 0.7200 - val_loss: 0.1267 - val_acc: 0.5600\n",
            "Epoch 668/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.1121 - acc: 0.7200 - val_loss: 0.1267 - val_acc: 0.5600\n",
            "Epoch 669/1500\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.1120 - acc: 0.7200 - val_loss: 0.1267 - val_acc: 0.5600\n",
            "Epoch 670/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1120 - acc: 0.7200 - val_loss: 0.1266 - val_acc: 0.5600\n",
            "Epoch 671/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1119 - acc: 0.7200 - val_loss: 0.1265 - val_acc: 0.5600\n",
            "Epoch 672/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1119 - acc: 0.7200 - val_loss: 0.1267 - val_acc: 0.5600\n",
            "Epoch 673/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1119 - acc: 0.7200 - val_loss: 0.1266 - val_acc: 0.5600\n",
            "Epoch 674/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1119 - acc: 0.7200 - val_loss: 0.1266 - val_acc: 0.5600\n",
            "Epoch 675/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1118 - acc: 0.7200 - val_loss: 0.1265 - val_acc: 0.5600\n",
            "Epoch 676/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1118 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 677/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1117 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 678/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1117 - acc: 0.7200 - val_loss: 0.1264 - val_acc: 0.5600\n",
            "Epoch 679/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1116 - acc: 0.7200 - val_loss: 0.1264 - val_acc: 0.5600\n",
            "Epoch 680/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1116 - acc: 0.7200 - val_loss: 0.1266 - val_acc: 0.5600\n",
            "Epoch 681/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1115 - acc: 0.7200 - val_loss: 0.1265 - val_acc: 0.5600\n",
            "Epoch 682/1500\n",
            "100/100 [==============================] - 0s 157us/sample - loss: 0.1115 - acc: 0.7200 - val_loss: 0.1264 - val_acc: 0.5600\n",
            "Epoch 683/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1115 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 684/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1114 - acc: 0.7200 - val_loss: 0.1262 - val_acc: 0.5600\n",
            "Epoch 685/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.1114 - acc: 0.7200 - val_loss: 0.1258 - val_acc: 0.5600\n",
            "Epoch 686/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1114 - acc: 0.7200 - val_loss: 0.1257 - val_acc: 0.5600\n",
            "Epoch 687/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1113 - acc: 0.7200 - val_loss: 0.1259 - val_acc: 0.5600\n",
            "Epoch 688/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1113 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 689/1500\n",
            "100/100 [==============================] - 0s 137us/sample - loss: 0.1112 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 690/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.1113 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 691/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1112 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 692/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1112 - acc: 0.7200 - val_loss: 0.1261 - val_acc: 0.5600\n",
            "Epoch 693/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1111 - acc: 0.7200 - val_loss: 0.1263 - val_acc: 0.5600\n",
            "Epoch 694/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1110 - acc: 0.7200 - val_loss: 0.1262 - val_acc: 0.5600\n",
            "Epoch 695/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1110 - acc: 0.7200 - val_loss: 0.1259 - val_acc: 0.5600\n",
            "Epoch 696/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1110 - acc: 0.7200 - val_loss: 0.1259 - val_acc: 0.5600\n",
            "Epoch 697/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1109 - acc: 0.7200 - val_loss: 0.1257 - val_acc: 0.5600\n",
            "Epoch 698/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1109 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 699/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1108 - acc: 0.7200 - val_loss: 0.1255 - val_acc: 0.5600\n",
            "Epoch 700/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1108 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 701/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1108 - acc: 0.7200 - val_loss: 0.1252 - val_acc: 0.5600\n",
            "Epoch 702/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1107 - acc: 0.7200 - val_loss: 0.1252 - val_acc: 0.5600\n",
            "Epoch 703/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1107 - acc: 0.7200 - val_loss: 0.1252 - val_acc: 0.5600\n",
            "Epoch 704/1500\n",
            "100/100 [==============================] - 0s 161us/sample - loss: 0.1107 - acc: 0.7200 - val_loss: 0.1255 - val_acc: 0.5600\n",
            "Epoch 705/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1106 - acc: 0.7200 - val_loss: 0.1256 - val_acc: 0.5600\n",
            "Epoch 706/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1106 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 707/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1106 - acc: 0.7200 - val_loss: 0.1253 - val_acc: 0.5600\n",
            "Epoch 708/1500\n",
            "100/100 [==============================] - 0s 127us/sample - loss: 0.1105 - acc: 0.7200 - val_loss: 0.1255 - val_acc: 0.5600\n",
            "Epoch 709/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1105 - acc: 0.7200 - val_loss: 0.1255 - val_acc: 0.5600\n",
            "Epoch 710/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1104 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 711/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1104 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 712/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1104 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 713/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1104 - acc: 0.7200 - val_loss: 0.1256 - val_acc: 0.5600\n",
            "Epoch 714/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1103 - acc: 0.7200 - val_loss: 0.1254 - val_acc: 0.5600\n",
            "Epoch 715/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1102 - acc: 0.7200 - val_loss: 0.1253 - val_acc: 0.5600\n",
            "Epoch 716/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1102 - acc: 0.7200 - val_loss: 0.1250 - val_acc: 0.5600\n",
            "Epoch 717/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1102 - acc: 0.7200 - val_loss: 0.1248 - val_acc: 0.5600\n",
            "Epoch 718/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1101 - acc: 0.7200 - val_loss: 0.1247 - val_acc: 0.5600\n",
            "Epoch 719/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1101 - acc: 0.7200 - val_loss: 0.1247 - val_acc: 0.5600\n",
            "Epoch 720/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1101 - acc: 0.7200 - val_loss: 0.1246 - val_acc: 0.5600\n",
            "Epoch 721/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1101 - acc: 0.7200 - val_loss: 0.1244 - val_acc: 0.5600\n",
            "Epoch 722/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1100 - acc: 0.7200 - val_loss: 0.1244 - val_acc: 0.5600\n",
            "Epoch 723/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1100 - acc: 0.7200 - val_loss: 0.1244 - val_acc: 0.5600\n",
            "Epoch 724/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1099 - acc: 0.7200 - val_loss: 0.1244 - val_acc: 0.5600\n",
            "Epoch 725/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1099 - acc: 0.7200 - val_loss: 0.1246 - val_acc: 0.5600\n",
            "Epoch 726/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1098 - acc: 0.7200 - val_loss: 0.1244 - val_acc: 0.5600\n",
            "Epoch 727/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1098 - acc: 0.7200 - val_loss: 0.1242 - val_acc: 0.5600\n",
            "Epoch 728/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1098 - acc: 0.7200 - val_loss: 0.1240 - val_acc: 0.5600\n",
            "Epoch 729/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1098 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 730/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1097 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 731/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1097 - acc: 0.7200 - val_loss: 0.1240 - val_acc: 0.5600\n",
            "Epoch 732/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1097 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 733/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1096 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 734/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1096 - acc: 0.7300 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 735/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1096 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 736/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1095 - acc: 0.7300 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 737/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1095 - acc: 0.7200 - val_loss: 0.1232 - val_acc: 0.5600\n",
            "Epoch 738/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1094 - acc: 0.7300 - val_loss: 0.1232 - val_acc: 0.5600\n",
            "Epoch 739/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1094 - acc: 0.7300 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 740/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1094 - acc: 0.7300 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 741/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1093 - acc: 0.7200 - val_loss: 0.1234 - val_acc: 0.5600\n",
            "Epoch 742/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1093 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 743/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1093 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 744/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1093 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 745/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1092 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 746/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1091 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 747/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1092 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 748/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1091 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 749/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1090 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 750/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1090 - acc: 0.7200 - val_loss: 0.1240 - val_acc: 0.5600\n",
            "Epoch 751/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1089 - acc: 0.7200 - val_loss: 0.1241 - val_acc: 0.5600\n",
            "Epoch 752/1500\n",
            "100/100 [==============================] - 0s 133us/sample - loss: 0.1089 - acc: 0.7200 - val_loss: 0.1240 - val_acc: 0.5600\n",
            "Epoch 753/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1089 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 754/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.1088 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 755/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1088 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 756/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1088 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 757/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1088 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 758/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1087 - acc: 0.7200 - val_loss: 0.1240 - val_acc: 0.5600\n",
            "Epoch 759/1500\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.1087 - acc: 0.7200 - val_loss: 0.1240 - val_acc: 0.5600\n",
            "Epoch 760/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1086 - acc: 0.7200 - val_loss: 0.1241 - val_acc: 0.5600\n",
            "Epoch 761/1500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.1086 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 762/1500\n",
            "100/100 [==============================] - 0s 143us/sample - loss: 0.1085 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 763/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1085 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 764/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1085 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 765/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1085 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 766/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1084 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 767/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1084 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 768/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1083 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 769/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1084 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 770/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1082 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 771/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1082 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 772/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1082 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 773/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1082 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 774/1500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.1081 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 775/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.1081 - acc: 0.7200 - val_loss: 0.1238 - val_acc: 0.5600\n",
            "Epoch 776/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1080 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 777/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.1080 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 778/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1080 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 779/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1079 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 780/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1079 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 781/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1079 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 782/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1079 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 783/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1078 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 784/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1077 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 785/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1077 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 786/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1077 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 787/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1076 - acc: 0.7200 - val_loss: 0.1239 - val_acc: 0.5600\n",
            "Epoch 788/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1077 - acc: 0.7200 - val_loss: 0.1237 - val_acc: 0.5600\n",
            "Epoch 789/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1076 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 790/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1076 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 791/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1075 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 792/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1075 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 793/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1074 - acc: 0.7200 - val_loss: 0.1232 - val_acc: 0.5600\n",
            "Epoch 794/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1074 - acc: 0.7200 - val_loss: 0.1234 - val_acc: 0.5600\n",
            "Epoch 795/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1073 - acc: 0.7200 - val_loss: 0.1234 - val_acc: 0.5600\n",
            "Epoch 796/1500\n",
            "100/100 [==============================] - 0s 141us/sample - loss: 0.1073 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 797/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1073 - acc: 0.7200 - val_loss: 0.1235 - val_acc: 0.5600\n",
            "Epoch 798/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1073 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 799/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1072 - acc: 0.7200 - val_loss: 0.1236 - val_acc: 0.5600\n",
            "Epoch 800/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1072 - acc: 0.7200 - val_loss: 0.1234 - val_acc: 0.5600\n",
            "Epoch 801/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1071 - acc: 0.7200 - val_loss: 0.1234 - val_acc: 0.5600\n",
            "Epoch 802/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1072 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 803/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1071 - acc: 0.7200 - val_loss: 0.1234 - val_acc: 0.5600\n",
            "Epoch 804/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1070 - acc: 0.7200 - val_loss: 0.1233 - val_acc: 0.5600\n",
            "Epoch 805/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1070 - acc: 0.7200 - val_loss: 0.1231 - val_acc: 0.5600\n",
            "Epoch 806/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1070 - acc: 0.7200 - val_loss: 0.1232 - val_acc: 0.5600\n",
            "Epoch 807/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1070 - acc: 0.7200 - val_loss: 0.1230 - val_acc: 0.5600\n",
            "Epoch 808/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1069 - acc: 0.7200 - val_loss: 0.1228 - val_acc: 0.5600\n",
            "Epoch 809/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1069 - acc: 0.7200 - val_loss: 0.1225 - val_acc: 0.5600\n",
            "Epoch 810/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1068 - acc: 0.7200 - val_loss: 0.1225 - val_acc: 0.5600\n",
            "Epoch 811/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1068 - acc: 0.7200 - val_loss: 0.1228 - val_acc: 0.5600\n",
            "Epoch 812/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1068 - acc: 0.7200 - val_loss: 0.1225 - val_acc: 0.5600\n",
            "Epoch 813/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1067 - acc: 0.7200 - val_loss: 0.1225 - val_acc: 0.5600\n",
            "Epoch 814/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1067 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 815/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1067 - acc: 0.7200 - val_loss: 0.1228 - val_acc: 0.5600\n",
            "Epoch 816/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1066 - acc: 0.7200 - val_loss: 0.1227 - val_acc: 0.5600\n",
            "Epoch 817/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1066 - acc: 0.7200 - val_loss: 0.1226 - val_acc: 0.5600\n",
            "Epoch 818/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1065 - acc: 0.7200 - val_loss: 0.1226 - val_acc: 0.5600\n",
            "Epoch 819/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1065 - acc: 0.7200 - val_loss: 0.1226 - val_acc: 0.5600\n",
            "Epoch 820/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1065 - acc: 0.7200 - val_loss: 0.1223 - val_acc: 0.5600\n",
            "Epoch 821/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1065 - acc: 0.7200 - val_loss: 0.1222 - val_acc: 0.5600\n",
            "Epoch 822/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1064 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 823/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1064 - acc: 0.7200 - val_loss: 0.1223 - val_acc: 0.5600\n",
            "Epoch 824/1500\n",
            "100/100 [==============================] - 0s 147us/sample - loss: 0.1064 - acc: 0.7200 - val_loss: 0.1223 - val_acc: 0.5600\n",
            "Epoch 825/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1063 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 826/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1064 - acc: 0.7300 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 827/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1062 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 828/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1062 - acc: 0.7200 - val_loss: 0.1225 - val_acc: 0.5600\n",
            "Epoch 829/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1061 - acc: 0.7200 - val_loss: 0.1223 - val_acc: 0.5600\n",
            "Epoch 830/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1061 - acc: 0.7200 - val_loss: 0.1226 - val_acc: 0.5600\n",
            "Epoch 831/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1061 - acc: 0.7200 - val_loss: 0.1225 - val_acc: 0.5600\n",
            "Epoch 832/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1060 - acc: 0.7200 - val_loss: 0.1221 - val_acc: 0.5600\n",
            "Epoch 833/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1060 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 834/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1059 - acc: 0.7200 - val_loss: 0.1226 - val_acc: 0.5600\n",
            "Epoch 835/1500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.1059 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 836/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1059 - acc: 0.7200 - val_loss: 0.1224 - val_acc: 0.5600\n",
            "Epoch 837/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1059 - acc: 0.7200 - val_loss: 0.1222 - val_acc: 0.5600\n",
            "Epoch 838/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1058 - acc: 0.7200 - val_loss: 0.1220 - val_acc: 0.5600\n",
            "Epoch 839/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1058 - acc: 0.7300 - val_loss: 0.1219 - val_acc: 0.5600\n",
            "Epoch 840/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1057 - acc: 0.7300 - val_loss: 0.1217 - val_acc: 0.5600\n",
            "Epoch 841/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1057 - acc: 0.7300 - val_loss: 0.1217 - val_acc: 0.5600\n",
            "Epoch 842/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1056 - acc: 0.7300 - val_loss: 0.1217 - val_acc: 0.5600\n",
            "Epoch 843/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1056 - acc: 0.7300 - val_loss: 0.1218 - val_acc: 0.5600\n",
            "Epoch 844/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1055 - acc: 0.7200 - val_loss: 0.1218 - val_acc: 0.5600\n",
            "Epoch 845/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1055 - acc: 0.7300 - val_loss: 0.1217 - val_acc: 0.5600\n",
            "Epoch 846/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1055 - acc: 0.7300 - val_loss: 0.1219 - val_acc: 0.5600\n",
            "Epoch 847/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1054 - acc: 0.7300 - val_loss: 0.1219 - val_acc: 0.5600\n",
            "Epoch 848/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1054 - acc: 0.7300 - val_loss: 0.1221 - val_acc: 0.5600\n",
            "Epoch 849/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1054 - acc: 0.7200 - val_loss: 0.1221 - val_acc: 0.5600\n",
            "Epoch 850/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1053 - acc: 0.7200 - val_loss: 0.1218 - val_acc: 0.5600\n",
            "Epoch 851/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1053 - acc: 0.7300 - val_loss: 0.1215 - val_acc: 0.5600\n",
            "Epoch 852/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1052 - acc: 0.7300 - val_loss: 0.1213 - val_acc: 0.5600\n",
            "Epoch 853/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1052 - acc: 0.7300 - val_loss: 0.1212 - val_acc: 0.5600\n",
            "Epoch 854/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1052 - acc: 0.7300 - val_loss: 0.1209 - val_acc: 0.5600\n",
            "Epoch 855/1500\n",
            "100/100 [==============================] - 0s 207us/sample - loss: 0.1051 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 856/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1051 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 857/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1051 - acc: 0.7300 - val_loss: 0.1209 - val_acc: 0.5600\n",
            "Epoch 858/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1050 - acc: 0.7300 - val_loss: 0.1207 - val_acc: 0.5600\n",
            "Epoch 859/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.1050 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 860/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1049 - acc: 0.7300 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 861/1500\n",
            "100/100 [==============================] - 0s 133us/sample - loss: 0.1049 - acc: 0.7400 - val_loss: 0.1203 - val_acc: 0.5600\n",
            "Epoch 862/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1048 - acc: 0.7400 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 863/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1049 - acc: 0.7300 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 864/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1048 - acc: 0.7400 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 865/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1047 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 866/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1047 - acc: 0.7400 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 867/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1046 - acc: 0.7300 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 868/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1046 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 869/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1045 - acc: 0.7300 - val_loss: 0.1203 - val_acc: 0.5600\n",
            "Epoch 870/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1045 - acc: 0.7400 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 871/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1045 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 872/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1044 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 873/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1044 - acc: 0.7300 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 874/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1043 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 875/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1043 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 876/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.1042 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 877/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1042 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 878/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1041 - acc: 0.7300 - val_loss: 0.1207 - val_acc: 0.5600\n",
            "Epoch 879/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.1041 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 880/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1041 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 881/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1041 - acc: 0.7300 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 882/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1040 - acc: 0.7300 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 883/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1039 - acc: 0.7300 - val_loss: 0.1201 - val_acc: 0.5600\n",
            "Epoch 884/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1039 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 885/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1039 - acc: 0.7400 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 886/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1038 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 887/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1038 - acc: 0.7300 - val_loss: 0.1206 - val_acc: 0.5600\n",
            "Epoch 888/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1037 - acc: 0.7300 - val_loss: 0.1207 - val_acc: 0.5600\n",
            "Epoch 889/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.1037 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 890/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1036 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 891/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1036 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 892/1500\n",
            "100/100 [==============================] - 0s 123us/sample - loss: 0.1035 - acc: 0.7300 - val_loss: 0.1208 - val_acc: 0.5600\n",
            "Epoch 893/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1035 - acc: 0.7300 - val_loss: 0.1207 - val_acc: 0.5600\n",
            "Epoch 894/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1034 - acc: 0.7300 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 895/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.1034 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 896/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1033 - acc: 0.7300 - val_loss: 0.1203 - val_acc: 0.5600\n",
            "Epoch 897/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1033 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 898/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1033 - acc: 0.7300 - val_loss: 0.1205 - val_acc: 0.5600\n",
            "Epoch 899/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1032 - acc: 0.7300 - val_loss: 0.1204 - val_acc: 0.5600\n",
            "Epoch 900/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1032 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 901/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1031 - acc: 0.7300 - val_loss: 0.1202 - val_acc: 0.5600\n",
            "Epoch 902/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1031 - acc: 0.7300 - val_loss: 0.1200 - val_acc: 0.5600\n",
            "Epoch 903/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1030 - acc: 0.7300 - val_loss: 0.1199 - val_acc: 0.5600\n",
            "Epoch 904/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1030 - acc: 0.7300 - val_loss: 0.1200 - val_acc: 0.5600\n",
            "Epoch 905/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.1030 - acc: 0.7300 - val_loss: 0.1199 - val_acc: 0.5600\n",
            "Epoch 906/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1029 - acc: 0.7300 - val_loss: 0.1197 - val_acc: 0.5600\n",
            "Epoch 907/1500\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.1029 - acc: 0.7400 - val_loss: 0.1193 - val_acc: 0.5600\n",
            "Epoch 908/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.1028 - acc: 0.7400 - val_loss: 0.1191 - val_acc: 0.5800\n",
            "Epoch 909/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1027 - acc: 0.7400 - val_loss: 0.1190 - val_acc: 0.5800\n",
            "Epoch 910/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.1027 - acc: 0.7400 - val_loss: 0.1188 - val_acc: 0.5800\n",
            "Epoch 911/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.1026 - acc: 0.7400 - val_loss: 0.1188 - val_acc: 0.5800\n",
            "Epoch 912/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1026 - acc: 0.7400 - val_loss: 0.1185 - val_acc: 0.5800\n",
            "Epoch 913/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1025 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 914/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1026 - acc: 0.7400 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 915/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1024 - acc: 0.7400 - val_loss: 0.1182 - val_acc: 0.5800\n",
            "Epoch 916/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.1024 - acc: 0.7500 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 917/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.1023 - acc: 0.7400 - val_loss: 0.1185 - val_acc: 0.5800\n",
            "Epoch 918/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.1023 - acc: 0.7400 - val_loss: 0.1183 - val_acc: 0.5800\n",
            "Epoch 919/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.1022 - acc: 0.7500 - val_loss: 0.1181 - val_acc: 0.5800\n",
            "Epoch 920/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1022 - acc: 0.7500 - val_loss: 0.1183 - val_acc: 0.5800\n",
            "Epoch 921/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.1022 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 922/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1021 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 923/1500\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.1021 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 924/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.1020 - acc: 0.7400 - val_loss: 0.1185 - val_acc: 0.5800\n",
            "Epoch 925/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1020 - acc: 0.7400 - val_loss: 0.1187 - val_acc: 0.5800\n",
            "Epoch 926/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.1019 - acc: 0.7400 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 927/1500\n",
            "100/100 [==============================] - 0s 134us/sample - loss: 0.1018 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 928/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1018 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 929/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1018 - acc: 0.7400 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 930/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1017 - acc: 0.7400 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 931/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1017 - acc: 0.7400 - val_loss: 0.1187 - val_acc: 0.5800\n",
            "Epoch 932/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1016 - acc: 0.7400 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 933/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.1015 - acc: 0.7400 - val_loss: 0.1186 - val_acc: 0.5800\n",
            "Epoch 934/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.1015 - acc: 0.7400 - val_loss: 0.1182 - val_acc: 0.5800\n",
            "Epoch 935/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1014 - acc: 0.7400 - val_loss: 0.1179 - val_acc: 0.5800\n",
            "Epoch 936/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1014 - acc: 0.7400 - val_loss: 0.1178 - val_acc: 0.5800\n",
            "Epoch 937/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.1013 - acc: 0.7500 - val_loss: 0.1179 - val_acc: 0.5800\n",
            "Epoch 938/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1013 - acc: 0.7500 - val_loss: 0.1179 - val_acc: 0.5800\n",
            "Epoch 939/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1012 - acc: 0.7500 - val_loss: 0.1184 - val_acc: 0.5800\n",
            "Epoch 940/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.1012 - acc: 0.7400 - val_loss: 0.1188 - val_acc: 0.5600\n",
            "Epoch 941/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1011 - acc: 0.7400 - val_loss: 0.1189 - val_acc: 0.5600\n",
            "Epoch 942/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.1011 - acc: 0.7400 - val_loss: 0.1187 - val_acc: 0.5600\n",
            "Epoch 943/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.1010 - acc: 0.7400 - val_loss: 0.1188 - val_acc: 0.5600\n",
            "Epoch 944/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1010 - acc: 0.7400 - val_loss: 0.1185 - val_acc: 0.5800\n",
            "Epoch 945/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1010 - acc: 0.7400 - val_loss: 0.1183 - val_acc: 0.5800\n",
            "Epoch 946/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.1008 - acc: 0.7400 - val_loss: 0.1185 - val_acc: 0.5800\n",
            "Epoch 947/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1009 - acc: 0.7400 - val_loss: 0.1185 - val_acc: 0.5800\n",
            "Epoch 948/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1008 - acc: 0.7400 - val_loss: 0.1182 - val_acc: 0.5800\n",
            "Epoch 949/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1007 - acc: 0.7400 - val_loss: 0.1179 - val_acc: 0.5800\n",
            "Epoch 950/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.1006 - acc: 0.7400 - val_loss: 0.1174 - val_acc: 0.5800\n",
            "Epoch 951/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1005 - acc: 0.7500 - val_loss: 0.1174 - val_acc: 0.5800\n",
            "Epoch 952/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1006 - acc: 0.7400 - val_loss: 0.1170 - val_acc: 0.5800\n",
            "Epoch 953/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.1005 - acc: 0.7500 - val_loss: 0.1167 - val_acc: 0.5800\n",
            "Epoch 954/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.1004 - acc: 0.7600 - val_loss: 0.1163 - val_acc: 0.6200\n",
            "Epoch 955/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.1004 - acc: 0.8000 - val_loss: 0.1167 - val_acc: 0.5800\n",
            "Epoch 956/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.1003 - acc: 0.7500 - val_loss: 0.1165 - val_acc: 0.6000\n",
            "Epoch 957/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.1002 - acc: 0.7700 - val_loss: 0.1168 - val_acc: 0.5800\n",
            "Epoch 958/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.1002 - acc: 0.7500 - val_loss: 0.1168 - val_acc: 0.5800\n",
            "Epoch 959/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.1002 - acc: 0.7500 - val_loss: 0.1171 - val_acc: 0.5800\n",
            "Epoch 960/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.1001 - acc: 0.7500 - val_loss: 0.1172 - val_acc: 0.5800\n",
            "Epoch 961/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.1001 - acc: 0.7500 - val_loss: 0.1176 - val_acc: 0.5800\n",
            "Epoch 962/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.1000 - acc: 0.7500 - val_loss: 0.1178 - val_acc: 0.5800\n",
            "Epoch 963/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0999 - acc: 0.7400 - val_loss: 0.1176 - val_acc: 0.5800\n",
            "Epoch 964/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0998 - acc: 0.7500 - val_loss: 0.1175 - val_acc: 0.5800\n",
            "Epoch 965/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0998 - acc: 0.7500 - val_loss: 0.1173 - val_acc: 0.5800\n",
            "Epoch 966/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0997 - acc: 0.7500 - val_loss: 0.1172 - val_acc: 0.5800\n",
            "Epoch 967/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0997 - acc: 0.7500 - val_loss: 0.1173 - val_acc: 0.5800\n",
            "Epoch 968/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0996 - acc: 0.7500 - val_loss: 0.1171 - val_acc: 0.5800\n",
            "Epoch 969/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0995 - acc: 0.7500 - val_loss: 0.1171 - val_acc: 0.5800\n",
            "Epoch 970/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0995 - acc: 0.7500 - val_loss: 0.1171 - val_acc: 0.5800\n",
            "Epoch 971/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0994 - acc: 0.7500 - val_loss: 0.1171 - val_acc: 0.5800\n",
            "Epoch 972/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0994 - acc: 0.7500 - val_loss: 0.1173 - val_acc: 0.5800\n",
            "Epoch 973/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0994 - acc: 0.7500 - val_loss: 0.1169 - val_acc: 0.5800\n",
            "Epoch 974/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0992 - acc: 0.7500 - val_loss: 0.1167 - val_acc: 0.5800\n",
            "Epoch 975/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0993 - acc: 0.7500 - val_loss: 0.1170 - val_acc: 0.5800\n",
            "Epoch 976/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0992 - acc: 0.7500 - val_loss: 0.1172 - val_acc: 0.5800\n",
            "Epoch 977/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0991 - acc: 0.7500 - val_loss: 0.1173 - val_acc: 0.5800\n",
            "Epoch 978/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0990 - acc: 0.7400 - val_loss: 0.1169 - val_acc: 0.5800\n",
            "Epoch 979/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0990 - acc: 0.7500 - val_loss: 0.1166 - val_acc: 0.5800\n",
            "Epoch 980/1500\n",
            "100/100 [==============================] - 0s 163us/sample - loss: 0.0990 - acc: 0.7500 - val_loss: 0.1166 - val_acc: 0.5800\n",
            "Epoch 981/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0989 - acc: 0.7500 - val_loss: 0.1165 - val_acc: 0.5800\n",
            "Epoch 982/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0988 - acc: 0.7500 - val_loss: 0.1163 - val_acc: 0.5800\n",
            "Epoch 983/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0987 - acc: 0.7500 - val_loss: 0.1162 - val_acc: 0.5800\n",
            "Epoch 984/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0987 - acc: 0.7500 - val_loss: 0.1162 - val_acc: 0.5800\n",
            "Epoch 985/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0986 - acc: 0.7500 - val_loss: 0.1158 - val_acc: 0.6200\n",
            "Epoch 986/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0985 - acc: 0.7700 - val_loss: 0.1153 - val_acc: 0.6400\n",
            "Epoch 987/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0985 - acc: 0.7900 - val_loss: 0.1148 - val_acc: 0.6800\n",
            "Epoch 988/1500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0984 - acc: 0.8200 - val_loss: 0.1151 - val_acc: 0.6400\n",
            "Epoch 989/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0983 - acc: 0.8100 - val_loss: 0.1155 - val_acc: 0.6200\n",
            "Epoch 990/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0983 - acc: 0.7700 - val_loss: 0.1150 - val_acc: 0.6400\n",
            "Epoch 991/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0982 - acc: 0.7900 - val_loss: 0.1149 - val_acc: 0.6400\n",
            "Epoch 992/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0982 - acc: 0.8200 - val_loss: 0.1149 - val_acc: 0.6400\n",
            "Epoch 993/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0981 - acc: 0.8100 - val_loss: 0.1148 - val_acc: 0.6400\n",
            "Epoch 994/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0980 - acc: 0.8100 - val_loss: 0.1152 - val_acc: 0.6400\n",
            "Epoch 995/1500\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.0980 - acc: 0.8000 - val_loss: 0.1152 - val_acc: 0.6400\n",
            "Epoch 996/1500\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0980 - acc: 0.7900 - val_loss: 0.1151 - val_acc: 0.6400\n",
            "Epoch 997/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0978 - acc: 0.7900 - val_loss: 0.1147 - val_acc: 0.6400\n",
            "Epoch 998/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0977 - acc: 0.8100 - val_loss: 0.1146 - val_acc: 0.6600\n",
            "Epoch 999/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0977 - acc: 0.8300 - val_loss: 0.1147 - val_acc: 0.6400\n",
            "Epoch 1000/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0976 - acc: 0.8100 - val_loss: 0.1146 - val_acc: 0.6400\n",
            "Epoch 1001/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0976 - acc: 0.8100 - val_loss: 0.1145 - val_acc: 0.6400\n",
            "Epoch 1002/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0975 - acc: 0.8200 - val_loss: 0.1149 - val_acc: 0.6400\n",
            "Epoch 1003/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0974 - acc: 0.7900 - val_loss: 0.1143 - val_acc: 0.7000\n",
            "Epoch 1004/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0974 - acc: 0.8000 - val_loss: 0.1143 - val_acc: 0.7000\n",
            "Epoch 1005/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0973 - acc: 0.8100 - val_loss: 0.1143 - val_acc: 0.7000\n",
            "Epoch 1006/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0973 - acc: 0.8100 - val_loss: 0.1143 - val_acc: 0.7000\n",
            "Epoch 1007/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0972 - acc: 0.8200 - val_loss: 0.1140 - val_acc: 0.7000\n",
            "Epoch 1008/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0971 - acc: 0.8300 - val_loss: 0.1142 - val_acc: 0.7000\n",
            "Epoch 1009/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0971 - acc: 0.8200 - val_loss: 0.1143 - val_acc: 0.6600\n",
            "Epoch 1010/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0970 - acc: 0.8100 - val_loss: 0.1141 - val_acc: 0.7000\n",
            "Epoch 1011/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0970 - acc: 0.8300 - val_loss: 0.1141 - val_acc: 0.6800\n",
            "Epoch 1012/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0969 - acc: 0.8100 - val_loss: 0.1148 - val_acc: 0.6200\n",
            "Epoch 1013/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0968 - acc: 0.7900 - val_loss: 0.1137 - val_acc: 0.7000\n",
            "Epoch 1014/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0967 - acc: 0.8300 - val_loss: 0.1136 - val_acc: 0.7000\n",
            "Epoch 1015/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0967 - acc: 0.8300 - val_loss: 0.1137 - val_acc: 0.7000\n",
            "Epoch 1016/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0966 - acc: 0.8300 - val_loss: 0.1134 - val_acc: 0.7000\n",
            "Epoch 1017/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0965 - acc: 0.8300 - val_loss: 0.1127 - val_acc: 0.7200\n",
            "Epoch 1018/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0965 - acc: 0.8600 - val_loss: 0.1122 - val_acc: 0.7200\n",
            "Epoch 1019/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0964 - acc: 0.8700 - val_loss: 0.1129 - val_acc: 0.7200\n",
            "Epoch 1020/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0963 - acc: 0.8400 - val_loss: 0.1127 - val_acc: 0.7200\n",
            "Epoch 1021/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0962 - acc: 0.8400 - val_loss: 0.1128 - val_acc: 0.7200\n",
            "Epoch 1022/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0961 - acc: 0.8300 - val_loss: 0.1123 - val_acc: 0.7200\n",
            "Epoch 1023/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0963 - acc: 0.8300 - val_loss: 0.1114 - val_acc: 0.7600\n",
            "Epoch 1024/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0961 - acc: 0.9100 - val_loss: 0.1121 - val_acc: 0.7200\n",
            "Epoch 1025/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0960 - acc: 0.8700 - val_loss: 0.1125 - val_acc: 0.7200\n",
            "Epoch 1026/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0960 - acc: 0.8700 - val_loss: 0.1122 - val_acc: 0.7200\n",
            "Epoch 1027/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0959 - acc: 0.8500 - val_loss: 0.1119 - val_acc: 0.7200\n",
            "Epoch 1028/1500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0958 - acc: 0.8700 - val_loss: 0.1119 - val_acc: 0.7200\n",
            "Epoch 1029/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0956 - acc: 0.8700 - val_loss: 0.1120 - val_acc: 0.7200\n",
            "Epoch 1030/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0956 - acc: 0.8700 - val_loss: 0.1118 - val_acc: 0.7200\n",
            "Epoch 1031/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.0955 - acc: 0.8700 - val_loss: 0.1114 - val_acc: 0.7200\n",
            "Epoch 1032/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0956 - acc: 0.9000 - val_loss: 0.1123 - val_acc: 0.7200\n",
            "Epoch 1033/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0954 - acc: 0.8500 - val_loss: 0.1129 - val_acc: 0.7000\n",
            "Epoch 1034/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0953 - acc: 0.8300 - val_loss: 0.1124 - val_acc: 0.7200\n",
            "Epoch 1035/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0953 - acc: 0.8500 - val_loss: 0.1123 - val_acc: 0.7200\n",
            "Epoch 1036/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0952 - acc: 0.8500 - val_loss: 0.1125 - val_acc: 0.7200\n",
            "Epoch 1037/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0951 - acc: 0.8300 - val_loss: 0.1121 - val_acc: 0.7200\n",
            "Epoch 1038/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0950 - acc: 0.8500 - val_loss: 0.1119 - val_acc: 0.7200\n",
            "Epoch 1039/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0950 - acc: 0.8700 - val_loss: 0.1121 - val_acc: 0.7200\n",
            "Epoch 1040/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0949 - acc: 0.8700 - val_loss: 0.1121 - val_acc: 0.7200\n",
            "Epoch 1041/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0950 - acc: 0.8500 - val_loss: 0.1124 - val_acc: 0.7200\n",
            "Epoch 1042/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0947 - acc: 0.8300 - val_loss: 0.1119 - val_acc: 0.7200\n",
            "Epoch 1043/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0946 - acc: 0.8500 - val_loss: 0.1125 - val_acc: 0.7200\n",
            "Epoch 1044/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0945 - acc: 0.8300 - val_loss: 0.1122 - val_acc: 0.7200\n",
            "Epoch 1045/1500\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.0946 - acc: 0.8300 - val_loss: 0.1118 - val_acc: 0.7200\n",
            "Epoch 1046/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0944 - acc: 0.8500 - val_loss: 0.1113 - val_acc: 0.7200\n",
            "Epoch 1047/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0943 - acc: 0.8700 - val_loss: 0.1110 - val_acc: 0.7200\n",
            "Epoch 1048/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0943 - acc: 0.8700 - val_loss: 0.1108 - val_acc: 0.7200\n",
            "Epoch 1049/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0942 - acc: 0.8900 - val_loss: 0.1107 - val_acc: 0.7200\n",
            "Epoch 1050/1500\n",
            "100/100 [==============================] - 0s 147us/sample - loss: 0.0941 - acc: 0.9000 - val_loss: 0.1111 - val_acc: 0.7200\n",
            "Epoch 1051/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0940 - acc: 0.8700 - val_loss: 0.1110 - val_acc: 0.7200\n",
            "Epoch 1052/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0940 - acc: 0.8700 - val_loss: 0.1114 - val_acc: 0.7200\n",
            "Epoch 1053/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0939 - acc: 0.8500 - val_loss: 0.1114 - val_acc: 0.7200\n",
            "Epoch 1054/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0938 - acc: 0.8400 - val_loss: 0.1107 - val_acc: 0.7200\n",
            "Epoch 1055/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0937 - acc: 0.8700 - val_loss: 0.1101 - val_acc: 0.7600\n",
            "Epoch 1056/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0936 - acc: 0.9000 - val_loss: 0.1103 - val_acc: 0.7200\n",
            "Epoch 1057/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0935 - acc: 0.8900 - val_loss: 0.1098 - val_acc: 0.7600\n",
            "Epoch 1058/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0935 - acc: 0.9000 - val_loss: 0.1098 - val_acc: 0.7600\n",
            "Epoch 1059/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0934 - acc: 0.9100 - val_loss: 0.1099 - val_acc: 0.7400\n",
            "Epoch 1060/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0933 - acc: 0.9000 - val_loss: 0.1100 - val_acc: 0.7200\n",
            "Epoch 1061/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0932 - acc: 0.8900 - val_loss: 0.1100 - val_acc: 0.7200\n",
            "Epoch 1062/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0931 - acc: 0.9000 - val_loss: 0.1098 - val_acc: 0.7400\n",
            "Epoch 1063/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0930 - acc: 0.9000 - val_loss: 0.1098 - val_acc: 0.7400\n",
            "Epoch 1064/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0931 - acc: 0.9300 - val_loss: 0.1108 - val_acc: 0.7200\n",
            "Epoch 1065/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0929 - acc: 0.8600 - val_loss: 0.1109 - val_acc: 0.7200\n",
            "Epoch 1066/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0929 - acc: 0.8600 - val_loss: 0.1105 - val_acc: 0.7200\n",
            "Epoch 1067/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0928 - acc: 0.8700 - val_loss: 0.1108 - val_acc: 0.7200\n",
            "Epoch 1068/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0927 - acc: 0.8600 - val_loss: 0.1105 - val_acc: 0.7200\n",
            "Epoch 1069/1500\n",
            "100/100 [==============================] - 0s 165us/sample - loss: 0.0928 - acc: 0.8800 - val_loss: 0.1102 - val_acc: 0.7200\n",
            "Epoch 1070/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0925 - acc: 0.8700 - val_loss: 0.1102 - val_acc: 0.7200\n",
            "Epoch 1071/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0925 - acc: 0.8700 - val_loss: 0.1098 - val_acc: 0.7200\n",
            "Epoch 1072/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0924 - acc: 0.9000 - val_loss: 0.1095 - val_acc: 0.7200\n",
            "Epoch 1073/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0923 - acc: 0.9000 - val_loss: 0.1091 - val_acc: 0.7600\n",
            "Epoch 1074/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0923 - acc: 0.9100 - val_loss: 0.1091 - val_acc: 0.7400\n",
            "Epoch 1075/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0921 - acc: 0.9000 - val_loss: 0.1090 - val_acc: 0.7600\n",
            "Epoch 1076/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0921 - acc: 0.9000 - val_loss: 0.1093 - val_acc: 0.7200\n",
            "Epoch 1077/1500\n",
            "100/100 [==============================] - 0s 137us/sample - loss: 0.0919 - acc: 0.9000 - val_loss: 0.1089 - val_acc: 0.7600\n",
            "Epoch 1078/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0919 - acc: 0.9000 - val_loss: 0.1091 - val_acc: 0.7200\n",
            "Epoch 1079/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0919 - acc: 0.9100 - val_loss: 0.1083 - val_acc: 0.8000\n",
            "Epoch 1080/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0917 - acc: 0.9400 - val_loss: 0.1085 - val_acc: 0.7600\n",
            "Epoch 1081/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0916 - acc: 0.9300 - val_loss: 0.1082 - val_acc: 0.8000\n",
            "Epoch 1082/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0915 - acc: 0.9300 - val_loss: 0.1078 - val_acc: 0.8200\n",
            "Epoch 1083/1500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.0915 - acc: 0.9400 - val_loss: 0.1077 - val_acc: 0.8200\n",
            "Epoch 1084/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0914 - acc: 0.9400 - val_loss: 0.1074 - val_acc: 0.8200\n",
            "Epoch 1085/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0914 - acc: 0.9500 - val_loss: 0.1078 - val_acc: 0.8000\n",
            "Epoch 1086/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0913 - acc: 0.9300 - val_loss: 0.1086 - val_acc: 0.7400\n",
            "Epoch 1087/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0912 - acc: 0.9000 - val_loss: 0.1099 - val_acc: 0.7200\n",
            "Epoch 1088/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0911 - acc: 0.8700 - val_loss: 0.1093 - val_acc: 0.7200\n",
            "Epoch 1089/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0909 - acc: 0.9000 - val_loss: 0.1094 - val_acc: 0.7200\n",
            "Epoch 1090/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0910 - acc: 0.8900 - val_loss: 0.1106 - val_acc: 0.7200\n",
            "Epoch 1091/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0910 - acc: 0.8500 - val_loss: 0.1104 - val_acc: 0.7200\n",
            "Epoch 1092/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0908 - acc: 0.8400 - val_loss: 0.1092 - val_acc: 0.7200\n",
            "Epoch 1093/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0907 - acc: 0.8900 - val_loss: 0.1089 - val_acc: 0.7200\n",
            "Epoch 1094/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0906 - acc: 0.8900 - val_loss: 0.1082 - val_acc: 0.7400\n",
            "Epoch 1095/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0904 - acc: 0.9000 - val_loss: 0.1087 - val_acc: 0.7200\n",
            "Epoch 1096/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0903 - acc: 0.9000 - val_loss: 0.1086 - val_acc: 0.7200\n",
            "Epoch 1097/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0903 - acc: 0.9000 - val_loss: 0.1078 - val_acc: 0.7600\n",
            "Epoch 1098/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0902 - acc: 0.9100 - val_loss: 0.1076 - val_acc: 0.7600\n",
            "Epoch 1099/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0901 - acc: 0.9300 - val_loss: 0.1077 - val_acc: 0.7600\n",
            "Epoch 1100/1500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0900 - acc: 0.9100 - val_loss: 0.1076 - val_acc: 0.7600\n",
            "Epoch 1101/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0903 - acc: 0.8900 - val_loss: 0.1069 - val_acc: 0.8200\n",
            "Epoch 1102/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0898 - acc: 0.9400 - val_loss: 0.1064 - val_acc: 0.8200\n",
            "Epoch 1103/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0898 - acc: 0.9400 - val_loss: 0.1058 - val_acc: 0.8400\n",
            "Epoch 1104/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0898 - acc: 0.9600 - val_loss: 0.1065 - val_acc: 0.8200\n",
            "Epoch 1105/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0896 - acc: 0.9400 - val_loss: 0.1068 - val_acc: 0.8000\n",
            "Epoch 1106/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0894 - acc: 0.9300 - val_loss: 0.1069 - val_acc: 0.8000\n",
            "Epoch 1107/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0894 - acc: 0.9300 - val_loss: 0.1077 - val_acc: 0.7200\n",
            "Epoch 1108/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0893 - acc: 0.9100 - val_loss: 0.1078 - val_acc: 0.7200\n",
            "Epoch 1109/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0893 - acc: 0.9000 - val_loss: 0.1087 - val_acc: 0.7200\n",
            "Epoch 1110/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0893 - acc: 0.8900 - val_loss: 0.1091 - val_acc: 0.7200\n",
            "Epoch 1111/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0892 - acc: 0.8600 - val_loss: 0.1085 - val_acc: 0.7200\n",
            "Epoch 1112/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0890 - acc: 0.8900 - val_loss: 0.1072 - val_acc: 0.7400\n",
            "Epoch 1113/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0888 - acc: 0.9100 - val_loss: 0.1065 - val_acc: 0.8000\n",
            "Epoch 1114/1500\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.0888 - acc: 0.9300 - val_loss: 0.1054 - val_acc: 0.8200\n",
            "Epoch 1115/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0886 - acc: 0.9500 - val_loss: 0.1051 - val_acc: 0.8400\n",
            "Epoch 1116/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0886 - acc: 0.9600 - val_loss: 0.1054 - val_acc: 0.8200\n",
            "Epoch 1117/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0884 - acc: 0.9600 - val_loss: 0.1055 - val_acc: 0.8200\n",
            "Epoch 1118/1500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0884 - acc: 0.9500 - val_loss: 0.1054 - val_acc: 0.8200\n",
            "Epoch 1119/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0883 - acc: 0.9600 - val_loss: 0.1057 - val_acc: 0.8200\n",
            "Epoch 1120/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0882 - acc: 0.9400 - val_loss: 0.1058 - val_acc: 0.8000\n",
            "Epoch 1121/1500\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.0882 - acc: 0.9400 - val_loss: 0.1046 - val_acc: 0.8400\n",
            "Epoch 1122/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0881 - acc: 0.9600 - val_loss: 0.1049 - val_acc: 0.8200\n",
            "Epoch 1123/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0879 - acc: 0.9500 - val_loss: 0.1053 - val_acc: 0.8200\n",
            "Epoch 1124/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0879 - acc: 0.9400 - val_loss: 0.1045 - val_acc: 0.8400\n",
            "Epoch 1125/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0877 - acc: 0.9600 - val_loss: 0.1042 - val_acc: 0.8400\n",
            "Epoch 1126/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0876 - acc: 0.9600 - val_loss: 0.1049 - val_acc: 0.8200\n",
            "Epoch 1127/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0876 - acc: 0.9400 - val_loss: 0.1051 - val_acc: 0.8200\n",
            "Epoch 1128/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0875 - acc: 0.9400 - val_loss: 0.1042 - val_acc: 0.8400\n",
            "Epoch 1129/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0873 - acc: 0.9600 - val_loss: 0.1042 - val_acc: 0.8400\n",
            "Epoch 1130/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0872 - acc: 0.9600 - val_loss: 0.1042 - val_acc: 0.8200\n",
            "Epoch 1131/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0871 - acc: 0.9600 - val_loss: 0.1040 - val_acc: 0.8400\n",
            "Epoch 1132/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0871 - acc: 0.9600 - val_loss: 0.1042 - val_acc: 0.8200\n",
            "Epoch 1133/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0870 - acc: 0.9600 - val_loss: 0.1052 - val_acc: 0.8000\n",
            "Epoch 1134/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0869 - acc: 0.9300 - val_loss: 0.1046 - val_acc: 0.8200\n",
            "Epoch 1135/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0867 - acc: 0.9500 - val_loss: 0.1042 - val_acc: 0.8200\n",
            "Epoch 1136/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0867 - acc: 0.9500 - val_loss: 0.1038 - val_acc: 0.8400\n",
            "Epoch 1137/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0865 - acc: 0.9600 - val_loss: 0.1038 - val_acc: 0.8200\n",
            "Epoch 1138/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0864 - acc: 0.9600 - val_loss: 0.1033 - val_acc: 0.8400\n",
            "Epoch 1139/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0863 - acc: 0.9600 - val_loss: 0.1029 - val_acc: 0.8400\n",
            "Epoch 1140/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0864 - acc: 0.9500 - val_loss: 0.1025 - val_acc: 0.8600\n",
            "Epoch 1141/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0861 - acc: 0.9500 - val_loss: 0.1025 - val_acc: 0.8600\n",
            "Epoch 1142/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0860 - acc: 0.9600 - val_loss: 0.1026 - val_acc: 0.8600\n",
            "Epoch 1143/1500\n",
            "100/100 [==============================] - 0s 154us/sample - loss: 0.0860 - acc: 0.9500 - val_loss: 0.1032 - val_acc: 0.8400\n",
            "Epoch 1144/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0858 - acc: 0.9600 - val_loss: 0.1029 - val_acc: 0.8400\n",
            "Epoch 1145/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0857 - acc: 0.9600 - val_loss: 0.1037 - val_acc: 0.8200\n",
            "Epoch 1146/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0857 - acc: 0.9600 - val_loss: 0.1031 - val_acc: 0.8400\n",
            "Epoch 1147/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0857 - acc: 0.9500 - val_loss: 0.1044 - val_acc: 0.8000\n",
            "Epoch 1148/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0856 - acc: 0.9300 - val_loss: 0.1024 - val_acc: 0.8400\n",
            "Epoch 1149/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0853 - acc: 0.9600 - val_loss: 0.1030 - val_acc: 0.8200\n",
            "Epoch 1150/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0853 - acc: 0.9600 - val_loss: 0.1022 - val_acc: 0.8400\n",
            "Epoch 1151/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0852 - acc: 0.9500 - val_loss: 0.1028 - val_acc: 0.8200\n",
            "Epoch 1152/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0850 - acc: 0.9600 - val_loss: 0.1026 - val_acc: 0.8400\n",
            "Epoch 1153/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0851 - acc: 0.9600 - val_loss: 0.1026 - val_acc: 0.8400\n",
            "Epoch 1154/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0848 - acc: 0.9600 - val_loss: 0.1020 - val_acc: 0.8400\n",
            "Epoch 1155/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0848 - acc: 0.9600 - val_loss: 0.1031 - val_acc: 0.8200\n",
            "Epoch 1156/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0849 - acc: 0.9400 - val_loss: 0.1015 - val_acc: 0.8600\n",
            "Epoch 1157/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0845 - acc: 0.9600 - val_loss: 0.1016 - val_acc: 0.8400\n",
            "Epoch 1158/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0844 - acc: 0.9500 - val_loss: 0.1019 - val_acc: 0.8400\n",
            "Epoch 1159/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0844 - acc: 0.9500 - val_loss: 0.1021 - val_acc: 0.8400\n",
            "Epoch 1160/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0842 - acc: 0.9600 - val_loss: 0.1015 - val_acc: 0.8400\n",
            "Epoch 1161/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.0843 - acc: 0.9600 - val_loss: 0.1023 - val_acc: 0.8200\n",
            "Epoch 1162/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0841 - acc: 0.9600 - val_loss: 0.1015 - val_acc: 0.8400\n",
            "Epoch 1163/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0839 - acc: 0.9500 - val_loss: 0.1011 - val_acc: 0.8400\n",
            "Epoch 1164/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0838 - acc: 0.9500 - val_loss: 0.1000 - val_acc: 0.9000\n",
            "Epoch 1165/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0837 - acc: 0.9600 - val_loss: 0.1004 - val_acc: 0.8800\n",
            "Epoch 1166/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0836 - acc: 0.9600 - val_loss: 0.1005 - val_acc: 0.8600\n",
            "Epoch 1167/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0835 - acc: 0.9600 - val_loss: 0.1021 - val_acc: 0.8200\n",
            "Epoch 1168/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0834 - acc: 0.9600 - val_loss: 0.1016 - val_acc: 0.8400\n",
            "Epoch 1169/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0834 - acc: 0.9500 - val_loss: 0.1013 - val_acc: 0.8400\n",
            "Epoch 1170/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0832 - acc: 0.9600 - val_loss: 0.1005 - val_acc: 0.8600\n",
            "Epoch 1171/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0832 - acc: 0.9600 - val_loss: 0.1006 - val_acc: 0.8400\n",
            "Epoch 1172/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0830 - acc: 0.9500 - val_loss: 0.1011 - val_acc: 0.8400\n",
            "Epoch 1173/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0831 - acc: 0.9500 - val_loss: 0.1005 - val_acc: 0.8400\n",
            "Epoch 1174/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0828 - acc: 0.9500 - val_loss: 0.1009 - val_acc: 0.8400\n",
            "Epoch 1175/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0828 - acc: 0.9600 - val_loss: 0.0996 - val_acc: 0.8800\n",
            "Epoch 1176/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0827 - acc: 0.9600 - val_loss: 0.0990 - val_acc: 0.8800\n",
            "Epoch 1177/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0825 - acc: 0.9600 - val_loss: 0.0998 - val_acc: 0.8600\n",
            "Epoch 1178/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0824 - acc: 0.9500 - val_loss: 0.0984 - val_acc: 0.9000\n",
            "Epoch 1179/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0822 - acc: 0.9600 - val_loss: 0.0989 - val_acc: 0.8800\n",
            "Epoch 1180/1500\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0822 - acc: 0.9600 - val_loss: 0.0994 - val_acc: 0.8800\n",
            "Epoch 1181/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0821 - acc: 0.9500 - val_loss: 0.0991 - val_acc: 0.8800\n",
            "Epoch 1182/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0819 - acc: 0.9600 - val_loss: 0.0989 - val_acc: 0.8800\n",
            "Epoch 1183/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0818 - acc: 0.9600 - val_loss: 0.0981 - val_acc: 0.9000\n",
            "Epoch 1184/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0817 - acc: 0.9600 - val_loss: 0.0987 - val_acc: 0.8800\n",
            "Epoch 1185/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0816 - acc: 0.9600 - val_loss: 0.0990 - val_acc: 0.8600\n",
            "Epoch 1186/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0815 - acc: 0.9600 - val_loss: 0.0995 - val_acc: 0.8400\n",
            "Epoch 1187/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0814 - acc: 0.9500 - val_loss: 0.0985 - val_acc: 0.8800\n",
            "Epoch 1188/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0813 - acc: 0.9600 - val_loss: 0.0985 - val_acc: 0.8800\n",
            "Epoch 1189/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0812 - acc: 0.9600 - val_loss: 0.0976 - val_acc: 0.9000\n",
            "Epoch 1190/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0811 - acc: 0.9600 - val_loss: 0.0987 - val_acc: 0.8600\n",
            "Epoch 1191/1500\n",
            "100/100 [==============================] - 0s 152us/sample - loss: 0.0810 - acc: 0.9500 - val_loss: 0.0989 - val_acc: 0.8400\n",
            "Epoch 1192/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0809 - acc: 0.9600 - val_loss: 0.0985 - val_acc: 0.8600\n",
            "Epoch 1193/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0807 - acc: 0.9600 - val_loss: 0.0973 - val_acc: 0.9000\n",
            "Epoch 1194/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0808 - acc: 0.9700 - val_loss: 0.0979 - val_acc: 0.8800\n",
            "Epoch 1195/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0806 - acc: 0.9600 - val_loss: 0.0979 - val_acc: 0.8800\n",
            "Epoch 1196/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0804 - acc: 0.9600 - val_loss: 0.0970 - val_acc: 0.9000\n",
            "Epoch 1197/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0803 - acc: 0.9600 - val_loss: 0.0969 - val_acc: 0.9000\n",
            "Epoch 1198/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0802 - acc: 0.9600 - val_loss: 0.0958 - val_acc: 0.9200\n",
            "Epoch 1199/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0803 - acc: 0.9700 - val_loss: 0.0957 - val_acc: 0.9200\n",
            "Epoch 1200/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0801 - acc: 0.9600 - val_loss: 0.0955 - val_acc: 0.9200\n",
            "Epoch 1201/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0799 - acc: 0.9800 - val_loss: 0.0961 - val_acc: 0.9000\n",
            "Epoch 1202/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0798 - acc: 0.9600 - val_loss: 0.0951 - val_acc: 0.9200\n",
            "Epoch 1203/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0798 - acc: 0.9700 - val_loss: 0.0950 - val_acc: 0.9200\n",
            "Epoch 1204/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0796 - acc: 0.9800 - val_loss: 0.0953 - val_acc: 0.9200\n",
            "Epoch 1205/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0796 - acc: 0.9600 - val_loss: 0.0956 - val_acc: 0.9000\n",
            "Epoch 1206/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0794 - acc: 0.9600 - val_loss: 0.0951 - val_acc: 0.9200\n",
            "Epoch 1207/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0796 - acc: 0.9600 - val_loss: 0.0952 - val_acc: 0.9200\n",
            "Epoch 1208/1500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0793 - acc: 0.9600 - val_loss: 0.0957 - val_acc: 0.9000\n",
            "Epoch 1209/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0789 - acc: 0.9600 - val_loss: 0.0958 - val_acc: 0.9000\n",
            "Epoch 1210/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0790 - acc: 0.9600 - val_loss: 0.0950 - val_acc: 0.9200\n",
            "Epoch 1211/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0788 - acc: 0.9600 - val_loss: 0.0943 - val_acc: 0.9200\n",
            "Epoch 1212/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0787 - acc: 0.9800 - val_loss: 0.0942 - val_acc: 0.9200\n",
            "Epoch 1213/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0787 - acc: 0.9700 - val_loss: 0.0948 - val_acc: 0.9000\n",
            "Epoch 1214/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0784 - acc: 0.9600 - val_loss: 0.0955 - val_acc: 0.8800\n",
            "Epoch 1215/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0784 - acc: 0.9600 - val_loss: 0.0946 - val_acc: 0.9000\n",
            "Epoch 1216/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0782 - acc: 0.9600 - val_loss: 0.0949 - val_acc: 0.9000\n",
            "Epoch 1217/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0781 - acc: 0.9600 - val_loss: 0.0941 - val_acc: 0.9200\n",
            "Epoch 1218/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0783 - acc: 0.9700 - val_loss: 0.0948 - val_acc: 0.9000\n",
            "Epoch 1219/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0779 - acc: 0.9600 - val_loss: 0.0938 - val_acc: 0.9200\n",
            "Epoch 1220/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0778 - acc: 0.9700 - val_loss: 0.0934 - val_acc: 0.9200\n",
            "Epoch 1221/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0778 - acc: 0.9700 - val_loss: 0.0932 - val_acc: 0.9200\n",
            "Epoch 1222/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0775 - acc: 0.9800 - val_loss: 0.0945 - val_acc: 0.9000\n",
            "Epoch 1223/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0775 - acc: 0.9700 - val_loss: 0.0940 - val_acc: 0.9000\n",
            "Epoch 1224/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0774 - acc: 0.9600 - val_loss: 0.0940 - val_acc: 0.9000\n",
            "Epoch 1225/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0772 - acc: 0.9600 - val_loss: 0.0939 - val_acc: 0.9000\n",
            "Epoch 1226/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0771 - acc: 0.9600 - val_loss: 0.0938 - val_acc: 0.9000\n",
            "Epoch 1227/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0771 - acc: 0.9600 - val_loss: 0.0934 - val_acc: 0.9000\n",
            "Epoch 1228/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0769 - acc: 0.9700 - val_loss: 0.0939 - val_acc: 0.8800\n",
            "Epoch 1229/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0769 - acc: 0.9700 - val_loss: 0.0938 - val_acc: 0.9000\n",
            "Epoch 1230/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0766 - acc: 0.9700 - val_loss: 0.0932 - val_acc: 0.9000\n",
            "Epoch 1231/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0764 - acc: 0.9600 - val_loss: 0.0934 - val_acc: 0.9000\n",
            "Epoch 1232/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0766 - acc: 0.9600 - val_loss: 0.0933 - val_acc: 0.9000\n",
            "Epoch 1233/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0762 - acc: 0.9600 - val_loss: 0.0919 - val_acc: 0.9200\n",
            "Epoch 1234/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0761 - acc: 0.9800 - val_loss: 0.0922 - val_acc: 0.9200\n",
            "Epoch 1235/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0760 - acc: 0.9800 - val_loss: 0.0933 - val_acc: 0.8800\n",
            "Epoch 1236/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0759 - acc: 0.9600 - val_loss: 0.0930 - val_acc: 0.9000\n",
            "Epoch 1237/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0758 - acc: 0.9600 - val_loss: 0.0914 - val_acc: 0.9200\n",
            "Epoch 1238/1500\n",
            "100/100 [==============================] - 0s 154us/sample - loss: 0.0759 - acc: 0.9800 - val_loss: 0.0905 - val_acc: 0.9000\n",
            "Epoch 1239/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0756 - acc: 0.9800 - val_loss: 0.0915 - val_acc: 0.9200\n",
            "Epoch 1240/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0756 - acc: 0.9800 - val_loss: 0.0933 - val_acc: 0.8800\n",
            "Epoch 1241/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0754 - acc: 0.9600 - val_loss: 0.0932 - val_acc: 0.8800\n",
            "Epoch 1242/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0753 - acc: 0.9600 - val_loss: 0.0912 - val_acc: 0.9200\n",
            "Epoch 1243/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0751 - acc: 0.9800 - val_loss: 0.0911 - val_acc: 0.9200\n",
            "Epoch 1244/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0750 - acc: 0.9800 - val_loss: 0.0908 - val_acc: 0.9200\n",
            "Epoch 1245/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0749 - acc: 0.9800 - val_loss: 0.0917 - val_acc: 0.9000\n",
            "Epoch 1246/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0748 - acc: 0.9700 - val_loss: 0.0904 - val_acc: 0.9200\n",
            "Epoch 1247/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0746 - acc: 0.9800 - val_loss: 0.0903 - val_acc: 0.9200\n",
            "Epoch 1248/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0745 - acc: 0.9800 - val_loss: 0.0912 - val_acc: 0.9000\n",
            "Epoch 1249/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0744 - acc: 0.9700 - val_loss: 0.0918 - val_acc: 0.9000\n",
            "Epoch 1250/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0745 - acc: 0.9600 - val_loss: 0.0913 - val_acc: 0.9000\n",
            "Epoch 1251/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0744 - acc: 0.9600 - val_loss: 0.0900 - val_acc: 0.9200\n",
            "Epoch 1252/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0742 - acc: 0.9800 - val_loss: 0.0908 - val_acc: 0.9000\n",
            "Epoch 1253/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0740 - acc: 0.9600 - val_loss: 0.0900 - val_acc: 0.9200\n",
            "Epoch 1254/1500\n",
            "100/100 [==============================] - 0s 143us/sample - loss: 0.0738 - acc: 0.9800 - val_loss: 0.0894 - val_acc: 0.9200\n",
            "Epoch 1255/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0737 - acc: 0.9800 - val_loss: 0.0887 - val_acc: 0.9200\n",
            "Epoch 1256/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0739 - acc: 0.9800 - val_loss: 0.0887 - val_acc: 0.9200\n",
            "Epoch 1257/1500\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.0736 - acc: 0.9800 - val_loss: 0.0878 - val_acc: 0.9800\n",
            "Epoch 1258/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0735 - acc: 0.9800 - val_loss: 0.0884 - val_acc: 0.9200\n",
            "Epoch 1259/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0733 - acc: 0.9800 - val_loss: 0.0886 - val_acc: 0.9200\n",
            "Epoch 1260/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0732 - acc: 0.9800 - val_loss: 0.0899 - val_acc: 0.9000\n",
            "Epoch 1261/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0732 - acc: 0.9800 - val_loss: 0.0912 - val_acc: 0.8800\n",
            "Epoch 1262/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0733 - acc: 0.9600 - val_loss: 0.0889 - val_acc: 0.9200\n",
            "Epoch 1263/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0728 - acc: 0.9800 - val_loss: 0.0893 - val_acc: 0.9200\n",
            "Epoch 1264/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0726 - acc: 0.9800 - val_loss: 0.0891 - val_acc: 0.9200\n",
            "Epoch 1265/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0725 - acc: 0.9800 - val_loss: 0.0899 - val_acc: 0.9000\n",
            "Epoch 1266/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0726 - acc: 0.9700 - val_loss: 0.0899 - val_acc: 0.9000\n",
            "Epoch 1267/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0726 - acc: 0.9600 - val_loss: 0.0892 - val_acc: 0.9000\n",
            "Epoch 1268/1500\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.0722 - acc: 0.9800 - val_loss: 0.0906 - val_acc: 0.8800\n",
            "Epoch 1269/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0727 - acc: 0.9600 - val_loss: 0.0881 - val_acc: 0.9200\n",
            "Epoch 1270/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0720 - acc: 0.9800 - val_loss: 0.0869 - val_acc: 0.9000\n",
            "Epoch 1271/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0720 - acc: 0.9800 - val_loss: 0.0874 - val_acc: 0.9200\n",
            "Epoch 1272/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0719 - acc: 0.9800 - val_loss: 0.0865 - val_acc: 0.9000\n",
            "Epoch 1273/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0717 - acc: 0.9800 - val_loss: 0.0873 - val_acc: 0.9200\n",
            "Epoch 1274/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0716 - acc: 0.9800 - val_loss: 0.0880 - val_acc: 0.9200\n",
            "Epoch 1275/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0714 - acc: 0.9800 - val_loss: 0.0878 - val_acc: 0.9200\n",
            "Epoch 1276/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0715 - acc: 0.9800 - val_loss: 0.0873 - val_acc: 0.9200\n",
            "Epoch 1277/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0712 - acc: 0.9800 - val_loss: 0.0871 - val_acc: 0.9200\n",
            "Epoch 1278/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0710 - acc: 0.9800 - val_loss: 0.0882 - val_acc: 0.9000\n",
            "Epoch 1279/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0709 - acc: 0.9600 - val_loss: 0.0874 - val_acc: 0.9200\n",
            "Epoch 1280/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0710 - acc: 0.9800 - val_loss: 0.0864 - val_acc: 0.9200\n",
            "Epoch 1281/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0708 - acc: 0.9800 - val_loss: 0.0870 - val_acc: 0.9200\n",
            "Epoch 1282/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0707 - acc: 0.9800 - val_loss: 0.0881 - val_acc: 0.9000\n",
            "Epoch 1283/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0705 - acc: 0.9700 - val_loss: 0.0885 - val_acc: 0.8800\n",
            "Epoch 1284/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0705 - acc: 0.9600 - val_loss: 0.0861 - val_acc: 0.9200\n",
            "Epoch 1285/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0702 - acc: 0.9800 - val_loss: 0.0879 - val_acc: 0.9000\n",
            "Epoch 1286/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0701 - acc: 0.9600 - val_loss: 0.0874 - val_acc: 0.9000\n",
            "Epoch 1287/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0699 - acc: 0.9800 - val_loss: 0.0878 - val_acc: 0.8800\n",
            "Epoch 1288/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0698 - acc: 0.9800 - val_loss: 0.0871 - val_acc: 0.9000\n",
            "Epoch 1289/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0699 - acc: 0.9800 - val_loss: 0.0862 - val_acc: 0.9200\n",
            "Epoch 1290/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0695 - acc: 0.9800 - val_loss: 0.0851 - val_acc: 0.9200\n",
            "Epoch 1291/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0695 - acc: 0.9800 - val_loss: 0.0853 - val_acc: 0.9200\n",
            "Epoch 1292/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0695 - acc: 0.9800 - val_loss: 0.0844 - val_acc: 0.9000\n",
            "Epoch 1293/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0693 - acc: 0.9800 - val_loss: 0.0842 - val_acc: 0.9000\n",
            "Epoch 1294/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0693 - acc: 0.9800 - val_loss: 0.0836 - val_acc: 0.9800\n",
            "Epoch 1295/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0691 - acc: 0.9800 - val_loss: 0.0835 - val_acc: 0.9800\n",
            "Epoch 1296/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0691 - acc: 0.9800 - val_loss: 0.0845 - val_acc: 0.9200\n",
            "Epoch 1297/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0691 - acc: 0.9800 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 1298/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0688 - acc: 0.9800 - val_loss: 0.0826 - val_acc: 0.9800\n",
            "Epoch 1299/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0689 - acc: 0.9800 - val_loss: 0.0836 - val_acc: 0.9000\n",
            "Epoch 1300/1500\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.0685 - acc: 0.9800 - val_loss: 0.0855 - val_acc: 0.9000\n",
            "Epoch 1301/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0684 - acc: 0.9800 - val_loss: 0.0857 - val_acc: 0.9000\n",
            "Epoch 1302/1500\n",
            "100/100 [==============================] - 0s 81us/sample - loss: 0.0687 - acc: 0.9800 - val_loss: 0.0849 - val_acc: 0.9000\n",
            "Epoch 1303/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0683 - acc: 0.9700 - val_loss: 0.0852 - val_acc: 0.9000\n",
            "Epoch 1304/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0680 - acc: 0.9800 - val_loss: 0.0843 - val_acc: 0.9200\n",
            "Epoch 1305/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0682 - acc: 0.9800 - val_loss: 0.0859 - val_acc: 0.8800\n",
            "Epoch 1306/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0678 - acc: 0.9600 - val_loss: 0.0859 - val_acc: 0.8800\n",
            "Epoch 1307/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0677 - acc: 0.9700 - val_loss: 0.0839 - val_acc: 0.9200\n",
            "Epoch 1308/1500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.0675 - acc: 0.9800 - val_loss: 0.0835 - val_acc: 0.9200\n",
            "Epoch 1309/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0675 - acc: 0.9800 - val_loss: 0.0831 - val_acc: 0.9200\n",
            "Epoch 1310/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0673 - acc: 0.9800 - val_loss: 0.0832 - val_acc: 0.9200\n",
            "Epoch 1311/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0672 - acc: 0.9800 - val_loss: 0.0832 - val_acc: 0.9200\n",
            "Epoch 1312/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0672 - acc: 0.9800 - val_loss: 0.0825 - val_acc: 0.9200\n",
            "Epoch 1313/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0670 - acc: 0.9800 - val_loss: 0.0840 - val_acc: 0.9000\n",
            "Epoch 1314/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0669 - acc: 0.9800 - val_loss: 0.0838 - val_acc: 0.9000\n",
            "Epoch 1315/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0669 - acc: 0.9800 - val_loss: 0.0827 - val_acc: 0.9200\n",
            "Epoch 1316/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0665 - acc: 0.9800 - val_loss: 0.0826 - val_acc: 0.9200\n",
            "Epoch 1317/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0664 - acc: 0.9800 - val_loss: 0.0818 - val_acc: 0.9000\n",
            "Epoch 1318/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0665 - acc: 0.9800 - val_loss: 0.0807 - val_acc: 0.9800\n",
            "Epoch 1319/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0665 - acc: 0.9800 - val_loss: 0.0810 - val_acc: 0.9800\n",
            "Epoch 1320/1500\n",
            "100/100 [==============================] - 0s 152us/sample - loss: 0.0664 - acc: 0.9800 - val_loss: 0.0815 - val_acc: 0.9200\n",
            "Epoch 1321/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0660 - acc: 0.9800 - val_loss: 0.0828 - val_acc: 0.9200\n",
            "Epoch 1322/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0661 - acc: 0.9800 - val_loss: 0.0824 - val_acc: 0.9200\n",
            "Epoch 1323/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0659 - acc: 0.9800 - val_loss: 0.0833 - val_acc: 0.9000\n",
            "Epoch 1324/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0657 - acc: 0.9800 - val_loss: 0.0808 - val_acc: 0.9000\n",
            "Epoch 1325/1500\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.0656 - acc: 0.9800 - val_loss: 0.0801 - val_acc: 0.9800\n",
            "Epoch 1326/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0655 - acc: 0.9800 - val_loss: 0.0812 - val_acc: 0.9200\n",
            "Epoch 1327/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0655 - acc: 0.9800 - val_loss: 0.0806 - val_acc: 0.9000\n",
            "Epoch 1328/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0652 - acc: 0.9800 - val_loss: 0.0808 - val_acc: 0.9200\n",
            "Epoch 1329/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0652 - acc: 0.9800 - val_loss: 0.0798 - val_acc: 0.9800\n",
            "Epoch 1330/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0650 - acc: 0.9800 - val_loss: 0.0804 - val_acc: 0.9000\n",
            "Epoch 1331/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0648 - acc: 0.9800 - val_loss: 0.0808 - val_acc: 0.9200\n",
            "Epoch 1332/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0647 - acc: 0.9800 - val_loss: 0.0805 - val_acc: 0.9200\n",
            "Epoch 1333/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0646 - acc: 0.9800 - val_loss: 0.0807 - val_acc: 0.9200\n",
            "Epoch 1334/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0645 - acc: 0.9800 - val_loss: 0.0799 - val_acc: 0.9200\n",
            "Epoch 1335/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0644 - acc: 0.9800 - val_loss: 0.0787 - val_acc: 0.9800\n",
            "Epoch 1336/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0647 - acc: 0.9800 - val_loss: 0.0785 - val_acc: 0.9800\n",
            "Epoch 1337/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0643 - acc: 0.9800 - val_loss: 0.0793 - val_acc: 0.9000\n",
            "Epoch 1338/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0642 - acc: 0.9800 - val_loss: 0.0802 - val_acc: 0.9200\n",
            "Epoch 1339/1500\n",
            "100/100 [==============================] - 0s 154us/sample - loss: 0.0639 - acc: 0.9800 - val_loss: 0.0820 - val_acc: 0.9000\n",
            "Epoch 1340/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0640 - acc: 0.9800 - val_loss: 0.0799 - val_acc: 0.9200\n",
            "Epoch 1341/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0637 - acc: 0.9800 - val_loss: 0.0805 - val_acc: 0.9200\n",
            "Epoch 1342/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0636 - acc: 0.9800 - val_loss: 0.0806 - val_acc: 0.9000\n",
            "Epoch 1343/1500\n",
            "100/100 [==============================] - 0s 118us/sample - loss: 0.0635 - acc: 0.9800 - val_loss: 0.0801 - val_acc: 0.9200\n",
            "Epoch 1344/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0633 - acc: 0.9800 - val_loss: 0.0807 - val_acc: 0.9000\n",
            "Epoch 1345/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0634 - acc: 0.9600 - val_loss: 0.0772 - val_acc: 0.9800\n",
            "Epoch 1346/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0634 - acc: 0.9900 - val_loss: 0.0774 - val_acc: 0.9800\n",
            "Epoch 1347/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0631 - acc: 0.9800 - val_loss: 0.0774 - val_acc: 0.9800\n",
            "Epoch 1348/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0633 - acc: 0.9800 - val_loss: 0.0776 - val_acc: 0.9800\n",
            "Epoch 1349/1500\n",
            "100/100 [==============================] - 0s 110us/sample - loss: 0.0629 - acc: 0.9800 - val_loss: 0.0789 - val_acc: 0.9200\n",
            "Epoch 1350/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0627 - acc: 0.9800 - val_loss: 0.0783 - val_acc: 0.9200\n",
            "Epoch 1351/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0625 - acc: 0.9800 - val_loss: 0.0790 - val_acc: 0.9200\n",
            "Epoch 1352/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0624 - acc: 0.9800 - val_loss: 0.0788 - val_acc: 0.9200\n",
            "Epoch 1353/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0624 - acc: 0.9800 - val_loss: 0.0815 - val_acc: 0.8800\n",
            "Epoch 1354/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0625 - acc: 0.9700 - val_loss: 0.0775 - val_acc: 0.9000\n",
            "Epoch 1355/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0621 - acc: 0.9800 - val_loss: 0.0781 - val_acc: 0.9200\n",
            "Epoch 1356/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0620 - acc: 0.9800 - val_loss: 0.0799 - val_acc: 0.9000\n",
            "Epoch 1357/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0620 - acc: 0.9800 - val_loss: 0.0794 - val_acc: 0.9000\n",
            "Epoch 1358/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0621 - acc: 0.9600 - val_loss: 0.0785 - val_acc: 0.9200\n",
            "Epoch 1359/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0617 - acc: 0.9800 - val_loss: 0.0762 - val_acc: 0.9800\n",
            "Epoch 1360/1500\n",
            "100/100 [==============================] - 0s 117us/sample - loss: 0.0618 - acc: 0.9800 - val_loss: 0.0757 - val_acc: 0.9800\n",
            "Epoch 1361/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0615 - acc: 0.9800 - val_loss: 0.0779 - val_acc: 0.9200\n",
            "Epoch 1362/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0614 - acc: 0.9800 - val_loss: 0.0779 - val_acc: 0.9200\n",
            "Epoch 1363/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0613 - acc: 0.9800 - val_loss: 0.0763 - val_acc: 0.9600\n",
            "Epoch 1364/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0611 - acc: 0.9800 - val_loss: 0.0757 - val_acc: 0.9800\n",
            "Epoch 1365/1500\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.0612 - acc: 0.9900 - val_loss: 0.0758 - val_acc: 0.9800\n",
            "Epoch 1366/1500\n",
            "100/100 [==============================] - 0s 86us/sample - loss: 0.0610 - acc: 0.9800 - val_loss: 0.0751 - val_acc: 0.9800\n",
            "Epoch 1367/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0608 - acc: 0.9800 - val_loss: 0.0749 - val_acc: 0.9800\n",
            "Epoch 1368/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0612 - acc: 0.9800 - val_loss: 0.0778 - val_acc: 0.9000\n",
            "Epoch 1369/1500\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.0605 - acc: 0.9800 - val_loss: 0.0765 - val_acc: 0.9200\n",
            "Epoch 1370/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0604 - acc: 0.9800 - val_loss: 0.0782 - val_acc: 0.9000\n",
            "Epoch 1371/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0603 - acc: 0.9800 - val_loss: 0.0776 - val_acc: 0.9000\n",
            "Epoch 1372/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0605 - acc: 0.9800 - val_loss: 0.0778 - val_acc: 0.9000\n",
            "Epoch 1373/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0601 - acc: 0.9800 - val_loss: 0.0756 - val_acc: 0.9000\n",
            "Epoch 1374/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0599 - acc: 0.9800 - val_loss: 0.0768 - val_acc: 0.9200\n",
            "Epoch 1375/1500\n",
            "100/100 [==============================] - 0s 82us/sample - loss: 0.0599 - acc: 0.9800 - val_loss: 0.0767 - val_acc: 0.9200\n",
            "Epoch 1376/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0600 - acc: 0.9800 - val_loss: 0.0761 - val_acc: 0.9200\n",
            "Epoch 1377/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0598 - acc: 0.9800 - val_loss: 0.0746 - val_acc: 0.9800\n",
            "Epoch 1378/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0597 - acc: 0.9800 - val_loss: 0.0739 - val_acc: 0.9800\n",
            "Epoch 1379/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0595 - acc: 0.9800 - val_loss: 0.0738 - val_acc: 0.9800\n",
            "Epoch 1380/1500\n",
            "100/100 [==============================] - 0s 104us/sample - loss: 0.0594 - acc: 0.9800 - val_loss: 0.0733 - val_acc: 0.9800\n",
            "Epoch 1381/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0593 - acc: 0.9800 - val_loss: 0.0739 - val_acc: 0.9800\n",
            "Epoch 1382/1500\n",
            "100/100 [==============================] - 0s 157us/sample - loss: 0.0591 - acc: 0.9800 - val_loss: 0.0756 - val_acc: 0.9200\n",
            "Epoch 1383/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0590 - acc: 0.9800 - val_loss: 0.0756 - val_acc: 0.9200\n",
            "Epoch 1384/1500\n",
            "100/100 [==============================] - 0s 148us/sample - loss: 0.0590 - acc: 0.9800 - val_loss: 0.0778 - val_acc: 0.8800\n",
            "Epoch 1385/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0591 - acc: 0.9800 - val_loss: 0.0780 - val_acc: 0.8800\n",
            "Epoch 1386/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0590 - acc: 0.9700 - val_loss: 0.0758 - val_acc: 0.9000\n",
            "Epoch 1387/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0586 - acc: 0.9800 - val_loss: 0.0746 - val_acc: 0.9200\n",
            "Epoch 1388/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0585 - acc: 0.9800 - val_loss: 0.0771 - val_acc: 0.9000\n",
            "Epoch 1389/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0585 - acc: 0.9800 - val_loss: 0.0752 - val_acc: 0.9200\n",
            "Epoch 1390/1500\n",
            "100/100 [==============================] - 0s 83us/sample - loss: 0.0582 - acc: 0.9800 - val_loss: 0.0747 - val_acc: 0.9200\n",
            "Epoch 1391/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0581 - acc: 0.9800 - val_loss: 0.0759 - val_acc: 0.9000\n",
            "Epoch 1392/1500\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.0581 - acc: 0.9800 - val_loss: 0.0744 - val_acc: 0.9200\n",
            "Epoch 1393/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0581 - acc: 0.9800 - val_loss: 0.0717 - val_acc: 0.9800\n",
            "Epoch 1394/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0580 - acc: 0.9900 - val_loss: 0.0733 - val_acc: 0.9600\n",
            "Epoch 1395/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0580 - acc: 0.9800 - val_loss: 0.0747 - val_acc: 0.9200\n",
            "Epoch 1396/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0577 - acc: 0.9800 - val_loss: 0.0724 - val_acc: 0.9800\n",
            "Epoch 1397/1500\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.0575 - acc: 0.9800 - val_loss: 0.0719 - val_acc: 0.9800\n",
            "Epoch 1398/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0577 - acc: 0.9900 - val_loss: 0.0724 - val_acc: 0.9800\n",
            "Epoch 1399/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0573 - acc: 0.9800 - val_loss: 0.0746 - val_acc: 0.9000\n",
            "Epoch 1400/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0572 - acc: 0.9800 - val_loss: 0.0734 - val_acc: 0.9200\n",
            "Epoch 1401/1500\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.0573 - acc: 0.9800 - val_loss: 0.0708 - val_acc: 0.9800\n",
            "Epoch 1402/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0571 - acc: 0.9900 - val_loss: 0.0716 - val_acc: 0.9800\n",
            "Epoch 1403/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0570 - acc: 0.9800 - val_loss: 0.0700 - val_acc: 0.9800\n",
            "Epoch 1404/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0570 - acc: 0.9900 - val_loss: 0.0722 - val_acc: 0.9400\n",
            "Epoch 1405/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0566 - acc: 0.9800 - val_loss: 0.0722 - val_acc: 0.9400\n",
            "Epoch 1406/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0571 - acc: 0.9800 - val_loss: 0.0734 - val_acc: 0.9200\n",
            "Epoch 1407/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0565 - acc: 0.9800 - val_loss: 0.0717 - val_acc: 0.9600\n",
            "Epoch 1408/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0567 - acc: 0.9800 - val_loss: 0.0721 - val_acc: 0.9200\n",
            "Epoch 1409/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0563 - acc: 0.9800 - val_loss: 0.0742 - val_acc: 0.9000\n",
            "Epoch 1410/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0563 - acc: 0.9800 - val_loss: 0.0735 - val_acc: 0.9000\n",
            "Epoch 1411/1500\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.0561 - acc: 0.9800 - val_loss: 0.0710 - val_acc: 0.9800\n",
            "Epoch 1412/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0561 - acc: 0.9800 - val_loss: 0.0698 - val_acc: 0.9800\n",
            "Epoch 1413/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0561 - acc: 0.9800 - val_loss: 0.0697 - val_acc: 0.9800\n",
            "Epoch 1414/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0561 - acc: 0.9900 - val_loss: 0.0701 - val_acc: 0.9800\n",
            "Epoch 1415/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0556 - acc: 0.9800 - val_loss: 0.0711 - val_acc: 0.9400\n",
            "Epoch 1416/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0557 - acc: 0.9800 - val_loss: 0.0732 - val_acc: 0.9000\n",
            "Epoch 1417/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0554 - acc: 0.9800 - val_loss: 0.0723 - val_acc: 0.9200\n",
            "Epoch 1418/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0556 - acc: 0.9800 - val_loss: 0.0713 - val_acc: 0.9200\n",
            "Epoch 1419/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0557 - acc: 0.9800 - val_loss: 0.0726 - val_acc: 0.9000\n",
            "Epoch 1420/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0554 - acc: 0.9800 - val_loss: 0.0703 - val_acc: 0.9600\n",
            "Epoch 1421/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0549 - acc: 0.9800 - val_loss: 0.0725 - val_acc: 0.9000\n",
            "Epoch 1422/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0549 - acc: 0.9800 - val_loss: 0.0716 - val_acc: 0.9200\n",
            "Epoch 1423/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0547 - acc: 0.9800 - val_loss: 0.0715 - val_acc: 0.9200\n",
            "Epoch 1424/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0548 - acc: 0.9800 - val_loss: 0.0709 - val_acc: 0.9200\n",
            "Epoch 1425/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0545 - acc: 0.9800 - val_loss: 0.0697 - val_acc: 0.9600\n",
            "Epoch 1426/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0546 - acc: 0.9800 - val_loss: 0.0704 - val_acc: 0.9200\n",
            "Epoch 1427/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0544 - acc: 0.9800 - val_loss: 0.0716 - val_acc: 0.9000\n",
            "Epoch 1428/1500\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.0542 - acc: 0.9800 - val_loss: 0.0694 - val_acc: 0.9600\n",
            "Epoch 1429/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0541 - acc: 0.9800 - val_loss: 0.0704 - val_acc: 0.9200\n",
            "Epoch 1430/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0542 - acc: 0.9800 - val_loss: 0.0730 - val_acc: 0.8800\n",
            "Epoch 1431/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0541 - acc: 0.9800 - val_loss: 0.0720 - val_acc: 0.9000\n",
            "Epoch 1432/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0541 - acc: 0.9800 - val_loss: 0.0717 - val_acc: 0.9000\n",
            "Epoch 1433/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0539 - acc: 0.9800 - val_loss: 0.0698 - val_acc: 0.9200\n",
            "Epoch 1434/1500\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.0537 - acc: 0.9800 - val_loss: 0.0709 - val_acc: 0.9000\n",
            "Epoch 1435/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0535 - acc: 0.9800 - val_loss: 0.0692 - val_acc: 0.9600\n",
            "Epoch 1436/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0534 - acc: 0.9800 - val_loss: 0.0687 - val_acc: 0.9600\n",
            "Epoch 1437/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0533 - acc: 0.9800 - val_loss: 0.0711 - val_acc: 0.9000\n",
            "Epoch 1438/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0536 - acc: 0.9800 - val_loss: 0.0676 - val_acc: 0.9800\n",
            "Epoch 1439/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0534 - acc: 0.9900 - val_loss: 0.0700 - val_acc: 0.9200\n",
            "Epoch 1440/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0531 - acc: 0.9800 - val_loss: 0.0675 - val_acc: 0.9800\n",
            "Epoch 1441/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.0531 - acc: 0.9800 - val_loss: 0.0671 - val_acc: 0.9800\n",
            "Epoch 1442/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0530 - acc: 0.9900 - val_loss: 0.0687 - val_acc: 0.9400\n",
            "Epoch 1443/1500\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.0527 - acc: 0.9800 - val_loss: 0.0683 - val_acc: 0.9400\n",
            "Epoch 1444/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0526 - acc: 0.9800 - val_loss: 0.0692 - val_acc: 0.9200\n",
            "Epoch 1445/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0526 - acc: 0.9800 - val_loss: 0.0701 - val_acc: 0.9000\n",
            "Epoch 1446/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0525 - acc: 0.9800 - val_loss: 0.0687 - val_acc: 0.9200\n",
            "Epoch 1447/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0523 - acc: 0.9800 - val_loss: 0.0684 - val_acc: 0.9200\n",
            "Epoch 1448/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0525 - acc: 0.9800 - val_loss: 0.0658 - val_acc: 0.9800\n",
            "Epoch 1449/1500\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.0522 - acc: 0.9900 - val_loss: 0.0669 - val_acc: 0.9800\n",
            "Epoch 1450/1500\n",
            "100/100 [==============================] - 0s 91us/sample - loss: 0.0523 - acc: 0.9800 - val_loss: 0.0658 - val_acc: 0.9800\n",
            "Epoch 1451/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0521 - acc: 0.9900 - val_loss: 0.0679 - val_acc: 0.9400\n",
            "Epoch 1452/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0520 - acc: 0.9800 - val_loss: 0.0684 - val_acc: 0.9200\n",
            "Epoch 1453/1500\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.0518 - acc: 0.9800 - val_loss: 0.0654 - val_acc: 0.9800\n",
            "Epoch 1454/1500\n",
            "100/100 [==============================] - 0s 80us/sample - loss: 0.0517 - acc: 0.9900 - val_loss: 0.0665 - val_acc: 0.9800\n",
            "Epoch 1455/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0516 - acc: 0.9800 - val_loss: 0.0665 - val_acc: 0.9800\n",
            "Epoch 1456/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0515 - acc: 0.9800 - val_loss: 0.0668 - val_acc: 0.9600\n",
            "Epoch 1457/1500\n",
            "100/100 [==============================] - 0s 126us/sample - loss: 0.0513 - acc: 0.9900 - val_loss: 0.0697 - val_acc: 0.9000\n",
            "Epoch 1458/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0513 - acc: 0.9800 - val_loss: 0.0663 - val_acc: 0.9600\n",
            "Epoch 1459/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0513 - acc: 0.9800 - val_loss: 0.0649 - val_acc: 0.9800\n",
            "Epoch 1460/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0511 - acc: 0.9900 - val_loss: 0.0657 - val_acc: 0.9800\n",
            "Epoch 1461/1500\n",
            "100/100 [==============================] - 0s 87us/sample - loss: 0.0509 - acc: 0.9800 - val_loss: 0.0653 - val_acc: 0.9800\n",
            "Epoch 1462/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0512 - acc: 0.9900 - val_loss: 0.0649 - val_acc: 0.9800\n",
            "Epoch 1463/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0510 - acc: 0.9900 - val_loss: 0.0632 - val_acc: 0.9800\n",
            "Epoch 1464/1500\n",
            "100/100 [==============================] - 0s 92us/sample - loss: 0.0510 - acc: 0.9900 - val_loss: 0.0646 - val_acc: 0.9800\n",
            "Epoch 1465/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0506 - acc: 0.9800 - val_loss: 0.0646 - val_acc: 0.9800\n",
            "Epoch 1466/1500\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.0505 - acc: 0.9900 - val_loss: 0.0644 - val_acc: 0.9800\n",
            "Epoch 1467/1500\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.0505 - acc: 0.9800 - val_loss: 0.0653 - val_acc: 0.9800\n",
            "Epoch 1468/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0504 - acc: 0.9900 - val_loss: 0.0659 - val_acc: 0.9600\n",
            "Epoch 1469/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0506 - acc: 0.9800 - val_loss: 0.0646 - val_acc: 0.9800\n",
            "Epoch 1470/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0502 - acc: 0.9800 - val_loss: 0.0648 - val_acc: 0.9800\n",
            "Epoch 1471/1500\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.0500 - acc: 0.9800 - val_loss: 0.0645 - val_acc: 0.9800\n",
            "Epoch 1472/1500\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.0501 - acc: 0.9800 - val_loss: 0.0657 - val_acc: 0.9600\n",
            "Epoch 1473/1500\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0637 - val_acc: 0.9800\n",
            "Epoch 1474/1500\n",
            "100/100 [==============================] - 0s 90us/sample - loss: 0.0500 - acc: 0.9900 - val_loss: 0.0632 - val_acc: 0.9800\n",
            "Epoch 1475/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0501 - acc: 0.9900 - val_loss: 0.0633 - val_acc: 0.9800\n",
            "Epoch 1476/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0499 - acc: 0.9800 - val_loss: 0.0619 - val_acc: 0.9800\n",
            "Epoch 1477/1500\n",
            "100/100 [==============================] - 0s 122us/sample - loss: 0.0498 - acc: 0.9800 - val_loss: 0.0640 - val_acc: 0.9800\n",
            "Epoch 1478/1500\n",
            "100/100 [==============================] - 0s 85us/sample - loss: 0.0494 - acc: 0.9900 - val_loss: 0.0641 - val_acc: 0.9800\n",
            "Epoch 1479/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0496 - acc: 0.9800 - val_loss: 0.0647 - val_acc: 0.9600\n",
            "Epoch 1480/1500\n",
            "100/100 [==============================] - 0s 95us/sample - loss: 0.0492 - acc: 0.9800 - val_loss: 0.0636 - val_acc: 0.9800\n",
            "Epoch 1481/1500\n",
            "100/100 [==============================] - 0s 94us/sample - loss: 0.0491 - acc: 0.9900 - val_loss: 0.0640 - val_acc: 0.9800\n",
            "Epoch 1482/1500\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.0489 - acc: 0.9800 - val_loss: 0.0645 - val_acc: 0.9800\n",
            "Epoch 1483/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0488 - acc: 0.9800 - val_loss: 0.0633 - val_acc: 0.9800\n",
            "Epoch 1484/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0488 - acc: 0.9900 - val_loss: 0.0658 - val_acc: 0.9200\n",
            "Epoch 1485/1500\n",
            "100/100 [==============================] - 0s 108us/sample - loss: 0.0490 - acc: 0.9800 - val_loss: 0.0638 - val_acc: 0.9600\n",
            "Epoch 1486/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0486 - acc: 0.9800 - val_loss: 0.0655 - val_acc: 0.9200\n",
            "Epoch 1487/1500\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.0486 - acc: 0.9800 - val_loss: 0.0662 - val_acc: 0.9000\n",
            "Epoch 1488/1500\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.0486 - acc: 0.9800 - val_loss: 0.0627 - val_acc: 0.9800\n",
            "Epoch 1489/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0483 - acc: 0.9800 - val_loss: 0.0627 - val_acc: 0.9800\n",
            "Epoch 1490/1500\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.0483 - acc: 0.9900 - val_loss: 0.0630 - val_acc: 0.9800\n",
            "Epoch 1491/1500\n",
            "100/100 [==============================] - 0s 88us/sample - loss: 0.0483 - acc: 0.9800 - val_loss: 0.0619 - val_acc: 0.9800\n",
            "Epoch 1492/1500\n",
            "100/100 [==============================] - 0s 100us/sample - loss: 0.0481 - acc: 0.9800 - val_loss: 0.0623 - val_acc: 0.9800\n",
            "Epoch 1493/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0482 - acc: 0.9800 - val_loss: 0.0611 - val_acc: 0.9800\n",
            "Epoch 1494/1500\n",
            "100/100 [==============================] - 0s 89us/sample - loss: 0.0480 - acc: 0.9900 - val_loss: 0.0630 - val_acc: 0.9600\n",
            "Epoch 1495/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0480 - acc: 0.9800 - val_loss: 0.0644 - val_acc: 0.9200\n",
            "Epoch 1496/1500\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.0477 - acc: 0.9800 - val_loss: 0.0625 - val_acc: 0.9800\n",
            "Epoch 1497/1500\n",
            "100/100 [==============================] - 0s 93us/sample - loss: 0.0476 - acc: 0.9900 - val_loss: 0.0653 - val_acc: 0.9000\n",
            "Epoch 1498/1500\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.0477 - acc: 0.9800 - val_loss: 0.0622 - val_acc: 0.9800\n",
            "Epoch 1499/1500\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.0474 - acc: 0.9900 - val_loss: 0.0639 - val_acc: 0.9200\n",
            "Epoch 1500/1500\n",
            "100/100 [==============================] - 0s 113us/sample - loss: 0.0473 - acc: 0.9800 - val_loss: 0.0625 - val_acc: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f099a560e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky-VIVrfbM0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vla_accu=[]\n",
        "vla_accu=history_model.history['val_acc']\n",
        "vla_loss=[]\n",
        "val_loss=history_model.history['val_loss']\n",
        "\n",
        "Epochs=[]\n",
        "i=0\n",
        "for i in range(0,len(vla_accu)):\n",
        "  Epochs.append(i)\n",
        "  i += 1\n",
        "# Sepal length with Petal length\n",
        "plt.plot(Epochs,vla_accu,c='b',label=\"vlidation acc\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('valid accuracy')\n",
        "# plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTuYNtFAdxHB",
        "colab_type": "code",
        "outputId": "28debb44-0481-4ba5-de91-5476f188be6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'drive/My Drive/Bio/model-1.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "piccGRyMT1jD",
        "colab_type": "code",
        "outputId": "d9d21cfd-1eca-41aa-b69c-feeafb9734b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "model.summary()\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              multiple                  20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              multiple                  25        \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              multiple                  18        \n",
            "=================================================================\n",
            "Total params: 63\n",
            "Trainable params: 63\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fc4a62a6550>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC2jnw9vsNF5",
        "colab_type": "code",
        "outputId": "28aa4880-6c1d-49ba-ef46-9316919b5c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.predict(val_inputs[10:15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9245236 , 0.08677843, 0.05508441],\n",
              "       [0.06156909, 0.30243862, 0.74234533],\n",
              "       [0.9086228 , 0.10777846, 0.04662282],\n",
              "       [0.06236158, 0.38606724, 0.64347243],\n",
              "       [0.90817803, 0.10871404, 0.04611995]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6RVcnZYASUQ",
        "colab_type": "code",
        "outputId": "e07379e7-549b-4a30-d6e0-62699c463cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_out[5:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [1.0, 0.0, 0.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwlx7WypT1jI",
        "colab_type": "code",
        "outputId": "7ce6dbb8-8be8-4f3d-ee72-3e0996ab93ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(val_outputs[10:15])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IP02_1T1jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}