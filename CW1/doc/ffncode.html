<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>BEAST - Bioinspired Evolutionary Agent Simulation Toolkit: FeedForwardNet source code</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.3.2 -->
<div class="qindex"><a class="qindex" href="index.html">Main&nbsp;Page</a> | <a class="qindex" href="modules.html">Modules</a> | <a class="qindex" href="namespaces.html">Namespace List</a> | <a class="qindex" href="hierarchy.html">Class&nbsp;Hierarchy</a> | <a class="qindex" href="classes.html">Alphabetical&nbsp;List</a> | <a class="qindex" href="annotated.html">Compound&nbsp;List</a> | <a class="qindex" href="files.html">File&nbsp;List</a> | <a class="qindex" href="namespacemembers.html">Namespace&nbsp;Members</a> | <a class="qindex" href="functions.html">Compound&nbsp;Members</a> | <a class="qindex" href="globals.html">File&nbsp;Members</a> | <a class="qindex" href="pages.html">Related&nbsp;Pages</a></div>
<h1><a name="ffncode">FeedForwardNet source code</a>
</h1><div class="fragment"><pre><span class="preprocessor">#include "<a class="code" href="feedforwardnet_8h.html">feedforwardnet.h</a>"</span>

<span class="keyword">using</span> <span class="keyword">namespace </span>std;

<span class="keyword">namespace </span>BEAST {

FeedForwardNet::FeedForwardNet(<span class="keywordtype">int</span> in, <span class="keywordtype">int</span> out, <span class="keywordtype">int</span> hid, <span class="keywordtype">bool</span> sig, <span class="keywordtype">bool</span> bias)
{
    <a class="code" href="classBEAST_1_1WorldObject.html#a3">Init</a>(in, out, hid, sig, bias);
}

<span class="keywordtype">void</span> FeedForwardNet::Init(<span class="keywordtype">int</span> in, <span class="keywordtype">int</span> out, <span class="keywordtype">int</span> hid, <span class="keywordtype">bool</span> sig, <span class="keywordtype">bool</span> bias)
{
    inputs = in;
    outputs = out;
    hidden = hid;
    sigmoid = sig;
    biasNode = bias;
    inputValues = vector&lt;float&gt;(in);
    outputValues = vector&lt;float&gt;(out);
    hiddenLayer.clear();
    outputLayer.clear();

    <span class="comment">// For each hidden layer neuron, we instantiate a Neuron object.</span>
    <span class="comment">// The Neuron is initialised with the number of weights it needs,</span>
    <span class="comment">// which in this case is one per input. If biasNode has been set</span>
    <span class="comment">// to true, an extra weight is added. The use of this is explained</span>
    <span class="comment">// in the fire method.</span>
    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;hidden; ++i) {
        hiddenLayer.push_back(Neuron(inputs + (biasNode ? 1 : 0) ));
    }

    <span class="comment">// If the hidden layer size is set to 0, normally that would break the</span>
    <span class="comment">// network but here I'm taking it to mean the net is a perceptron (one</span>
    <span class="comment">// layer of inputs, one layer of outputs, no hidden layer) and so the</span>
    <span class="comment">// output layer neurons have &lt;inputs&gt;, rather than &lt;hidden&gt;, inputs.</span>
    <span class="keywordflow">if</span> (hid == 0) hid = inputs;
    <span class="comment">// Add one neuron per output value to the output layer, each with</span>
    <span class="comment">// one weight per hidden neuron (since this is the output layer,</span>
    <span class="comment">// inputs are coming from the hidden layer) and again an extra</span>
    <span class="comment">// weight if biasNode is set to true.</span>
    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i=0; i&lt;outputs; ++i) {
        outputLayer.push_back(Neuron(hid + (biasNode ? 1 : 0) ));
    }
}

FeedForwardNet::~FeedForwardNet()
{
}

<span class="keywordtype">void</span> FeedForwardNet::Randomise()
{
    vector&lt;Neuron&gt;::iterator i;

    <span class="keywordflow">for</span> (i = hiddenLayer.begin(); i != hiddenLayer.end(); ++i) {
        generate(i-&gt;weights.begin(), i-&gt;weights.end(), RandomNum);
    }

    <span class="keywordflow">for</span> (i = outputLayer.begin(); i != outputLayer.end(); ++i) {
        generate(i-&gt;weights.begin(), i-&gt;weights.end(), RandomNum);
    }
}

vector&lt;float&gt; FeedForwardNet::GetConfiguration()<span class="keyword">const</span>
{
    <span class="comment">// The configuration data contains no information about the</span>
    <span class="comment">// network's dimensions, bias nodes, or activation function.</span>

    vector&lt;float&gt; config;
    vector&lt;Neuron&gt;::const_iterator i;

    <span class="comment">// Using the STL copy template algorithm instead of a for loop. Wow!</span>
    <span class="keywordflow">for</span> (i = hiddenLayer.begin(); i != hiddenLayer.end(); ++i) {
        copy(i-&gt;weights.begin(), i-&gt;weights.end(), back_inserter(config));
    }

    <span class="keywordflow">for</span> (i = outputLayer.begin(); i != outputLayer.end(); ++i) {
        copy(i-&gt;weights.begin(), i-&gt;weights.end(), back_inserter(config));
    }

    <span class="keywordflow">return</span> config;
}

<span class="keywordtype">void</span> FeedForwardNet::SetConfiguration(<span class="keyword">const</span> vector&lt;float&gt;&amp; config)
{
    <span class="comment">// The configuration data contains no information about the</span>
    <span class="comment">// network's dimensions, bias nodes, or activation function.</span>

    <span class="comment">// First ensure the incoming vector is the right size</span>
    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> expectedSize = static_cast&lt;unsigned int&gt;(GetConfigurationLength());

    <span class="keywordflow">if</span> (config.size() != expectedSize) <span class="keywordflow">return</span>; <span class="comment">// Error to go here</span>

    vector&lt;Neuron&gt;::iterator i;
    vector&lt;float&gt;::const_iterator configIter(config.begin());

    <span class="comment">// Now we move through config, assigning series of size inputs + biasnode</span>
    <span class="comment">// to the weights of each Neuron.</span>

    <span class="keywordflow">for</span> (i = hiddenLayer.begin(); i != hiddenLayer.end(); ++i) {
        i-&gt;weights = vector&lt;float&gt;(configIter, configIter+inputs+(biasNode?1:0));
        configIter += inputs + (biasNode ? 1 : 0);
    }

    <span class="comment">// Same again for output layer</span>
    <span class="keywordflow">for</span> (i = outputLayer.begin(); i != outputLayer.end(); ++i) {
        i-&gt;weights = vector&lt;float&gt;(configIter, configIter+hidden+(biasNode?1:0));
        configIter += hidden + (biasNode ? 1 : 0);
    }

    <span class="comment">// One more error check:</span>
    <span class="keywordflow">if</span> (configIter != config.end()) <span class="keyword">true</span>; <span class="comment">// Another error</span>

    <span class="keywordflow">return</span>;
}

<span class="keywordtype">float</span> FeedForwardNet::Neuron::WeightedSum(vector&lt;float&gt;&amp; input)<span class="keyword">const</span>
{
    <span class="keywordflow">if</span> (input.size() &gt; weights.size()) {
        std::cerr &lt;&lt; <span class="stringliteral">"Error: too many inputs!"</span> &lt;&lt; std::endl;
    }

    <span class="comment">// All we're doing here is moving through the input values (which will</span>
    <span class="comment">// always be either the net's inputs or the outputs of the hidden layer)</span>
    <span class="comment">// and multiplying them by their respective weights</span>
    <span class="keywordflow">return</span> inner_product(input.begin(), input.end(), weights.begin(), 0.0f);

    <span class="comment">// Note that the output from this function isn't ready to be passed onto</span>
    <span class="comment">// the next layer yet - this weighted sum needs to be (optionally) biased</span>
    <span class="comment">// and put through the activation function - either sigmoid or threshold.</span>
}

<span class="keywordtype">void</span> FeedForwardNet::Fire()
{
    vector&lt;float&gt; hiddenOutput;         <span class="comment">// A holding space for the output</span>
    outputValues.clear();               <span class="comment">// of the hidden layer, to pass to</span>
    <span class="keywordtype">float</span> output;                       <span class="comment">// the output layer neurons.</span>
    
    <span class="comment">// If the size of the hidden layer is set to 0, this particular ANN class</span>
    <span class="comment">// recognises that to mean there is no hidden layer, and so the input</span>
    <span class="comment">// values should be processed directly by the output layer. When this</span>
    <span class="comment">// happens - i.e. there is only one round of neural processing - you have</span>
    <span class="comment">// a perceptron. Normally a zero-neuron hidden layer would just break the</span>
    <span class="comment">// network, but here we're forcing something else to happen.</span>
    <span class="keywordflow">if</span> (hidden == 0) hiddenOutput = inputValues;

    vector&lt;Neuron&gt;::const_iterator currentNeuron(hiddenLayer.begin());
    
    <span class="keywordflow">for</span> (; currentNeuron != hiddenLayer.end(); ++currentNeuron) {
        output = currentNeuron-&gt;WeightedSum(inputValues);

        <span class="keywordflow">if</span> (biasNode) {
            <span class="comment">// All this bit does is pick the last value on the current </span>
            <span class="comment">// neuron's vector of weights and subtract it from the</span>
            <span class="comment">// weighted sum:</span>
            output += currentNeuron-&gt;weights.back();
            <span class="comment">// The idea is that rather than insist on a neuron coming up with</span>
            <span class="comment">// outputs that are simply positive or negative, we might have a</span>
            <span class="comment">// neuron which produces a high valued output which we want to</span>
            <span class="comment">// tone down. So we subtract the bias value, which is just stored</span>
            <span class="comment">// at the end of the weights for convenience, from the neuron's</span>
            <span class="comment">// output. The end result is a much more flexible network.</span>
        }
        
        <span class="comment">// Now the value is processed by either a threshold function, which</span>
        <span class="comment">// will make our hard-computed output into nothing more than a 0 or 1,</span>
        <span class="comment">// or a sigmoid function which will make values &lt;0 a bit lower, and</span>
        <span class="comment">// values &gt;0 a bit higher. The net would work without this stage, but</span>
        <span class="comment">// not very well.</span>
        output = ActivationFunction(output);

        <span class="comment">// Now we store the outputs of each neuron ready to be passed onto the</span>
        <span class="comment">// next layer.</span>
        hiddenOutput.push_back(output);
    }

    <span class="comment">// Now we do exactly the same thing over again for the output layer. Note</span>
    <span class="comment">// that in this net we will never have more than one hidden layer, so I've</span>
    <span class="comment">// simply written out the firing code twice, once for each layer. Many-</span>
    <span class="comment">// layered ANN implementations would most likely do this bit as a loop,</span>
    <span class="comment">// with one iteration per layer.</span>
    <span class="keywordflow">for</span> (currentNeuron = outputLayer.begin();
         currentNeuron != outputLayer.end(); ++currentNeuron) {
        output = currentNeuron-&gt;WeightedSum(hiddenOutput);

        <span class="keywordflow">if</span> (biasNode) {
            output += currentNeuron-&gt;weights.back();
        }

        output = ActivationFunction(output);

        <span class="comment">// These are the values we'll be giving to the user when they request</span>
        <span class="comment">// the output with GetOutput();</span>
        outputValues.push_back(output);

    }
}

<span class="keywordtype">float</span> FeedForwardNet::ActivationFunction(<span class="keywordtype">float</span> n)
{
    <span class="keywordflow">if</span> (sigmoid) {
        <span class="comment">// This is the sigmoid function, refer to the lecture notes or a good</span>
        <span class="comment">// book on ANNs for a better diagram than this.</span>
        <span class="comment">//</span>
        <span class="comment">//   1 |       .-'''    The sigmoid function is somewhere between an</span>
        <span class="comment">//     |      /         identity function (i.e. returns whatever you</span>
        <span class="comment">//     |     /          put in) and a threshold (returns 0 for &lt;= 0,</span>
        <span class="comment">//   0 |__.-'_______    1 for &gt; 0). When plotted it's a smooth curve,</span>
        <span class="comment">//     -10    0   10    just like the one to the left.</span>
        <span class="comment">//</span>
        <span class="keywordflow">return</span> static_cast&lt;float&gt;(1.0 / (1.0 + exp(-n / FFN_ACTIVATION_RESPONSE)));
    }
    <span class="keywordflow">else</span> {
        <span class="comment">// This is just a threshold function. You'll want to use sigmoid for</span>
        <span class="comment">// most ANN applications, this is really more use for testing, e.g.</span>
        <span class="comment">// with the XOR problem (although of course that can be done with</span>
        <span class="comment">// sigmoid too)</span>
        <span class="keywordflow">return</span> n &gt; 0.0f ? 1.0f : 0.0f;
    }
}

<span class="keywordtype">void</span> FeedForwardNet::Serialise(ostream&amp; out)<span class="keyword">const</span>
{
    out &lt;&lt; <span class="stringliteral">"FeedForwardNet\n"</span>
        &lt;&lt; setprecision(36)
        &lt;&lt; inputs &lt;&lt; endl
        &lt;&lt; outputs &lt;&lt; endl
        &lt;&lt; hidden &lt;&lt; endl
        &lt;&lt; (sigmoid ? <span class="stringliteral">"sigmoid"</span> : <span class="stringliteral">"threshold"</span>) &lt;&lt; endl
        &lt;&lt; (biasNode ? <span class="stringliteral">"biasnode"</span> : <span class="stringliteral">"nobiasnode"</span>) &lt;&lt; endl;

    ostream_iterator&lt;float&gt; outIter(out, <span class="stringliteral">"\n"</span>);
    copy(inputValues.begin(), inputValues.end(), outIter);
    copy(outputValues.begin(), outputValues.end(), outIter);

    vector&lt;float&gt; config = GetConfiguration();
    copy(config.begin(), config.end(), outIter);
}

<span class="keywordtype">void</span> FeedForwardNet::Unserialise(istream&amp; in)
{
    string name;
    in &gt;&gt; name;
    <span class="keywordflow">if</span> (name != <span class="stringliteral">"FeedForwardNet"</span>) {
        <span class="keywordflow">throw</span> SerialException(SERIAL_ERROR_WRONG_TYPE, name, 
                              <span class="stringliteral">"This object is type FeedForwardNet"</span>);
    }

    in &gt;&gt; inputs
       &gt;&gt; outputs
       &gt;&gt; hidden
       &gt;&gt; switcher(<span class="stringliteral">"sigmoid"</span>, sigmoid)
       &gt;&gt; switcher(<span class="stringliteral">"biasnode"</span>, biasNode);

    <a class="code" href="classBEAST_1_1WorldObject.html#a3">Init</a>(inputs, outputs, hidden, sigmoid, biasNode); <span class="comment">// Looks a little fishy</span>

    <a class="code" href="group__serialisation.html#a4">copy_from_istream</a>(inputValues.begin(), inputValues.end(), in);
    <a class="code" href="group__serialisation.html#a4">copy_from_istream</a>(outputValues.begin(), outputValues.end(), in);

    vector&lt;float&gt; config(GetConfigurationLength());
    <a class="code" href="group__serialisation.html#a4">copy_from_istream</a>(config.begin(), config.end(), in);

    SetConfiguration(config);
}

string FeedForwardNet::ToString()<span class="keyword">const</span>
{
    <span class="comment">// I'm not going to comment this because, well, it's just too boring.</span>

    ostringstream out;
    vector&lt;Neuron&gt;::const_iterator i;
    vector&lt;float&gt;::const_iterator j;

    out &lt;&lt; setprecision(2) &lt;&lt; setiosflags(ios::fixed)
        &lt;&lt; <span class="stringliteral">"Input values:"</span> &lt;&lt; endl;

    <span class="keywordflow">for</span> (j = inputValues.begin(); j != inputValues.end(); ++j) {
        out &lt;&lt; setw(FFN_COLSIZE) &lt;&lt; *j;
    }

    out &lt;&lt; endl &lt;&lt; endl
        &lt;&lt; <span class="stringliteral">"Hidden layer weights: "</span> &lt;&lt; endl;

    <span class="keywordflow">for</span> (i = hiddenLayer.begin(); i != hiddenLayer.end(); ++i) {
        <span class="keywordflow">for</span> (j = i-&gt;weights.begin(); j != i-&gt;weights.end() - 1; ++j) {
            out &lt;&lt; setw(FFN_COLSIZE) &lt;&lt; *j;
        }
        <span class="keywordflow">if</span> (biasNode) out &lt;&lt; <span class="stringliteral">" bias: "</span>;
        out &lt;&lt; setw(FFN_COLSIZE) &lt;&lt; *j &lt;&lt; endl;
    }

    out &lt;&lt; endl
        &lt;&lt; <span class="stringliteral">"Output layer weights: "</span> &lt;&lt; endl;

    <span class="keywordflow">for</span> (i = outputLayer.begin(); i != outputLayer.end(); ++i) {
        <span class="keywordflow">for</span> (j = i-&gt;weights.begin(); j != i-&gt;weights.end() - 1; ++j) {
            out &lt;&lt; setw(FFN_COLSIZE) &lt;&lt; *j;
        }
        <span class="keywordflow">if</span> (biasNode) out &lt;&lt; <span class="stringliteral">" bias: "</span>;
        out &lt;&lt; setw(FFN_COLSIZE) &lt;&lt; *j &lt;&lt; endl;
    }

    out &lt;&lt; endl
        &lt;&lt; <span class="stringliteral">"Output values: "</span> &lt;&lt; endl;

    <span class="keywordflow">for</span> (j = outputValues.begin(); j != outputValues.end(); ++j) {
        out &lt;&lt; setw(FFN_COLSIZE) &lt;&lt; *j;
    }

    out &lt;&lt; endl &lt;&lt; endl;

    <span class="keywordflow">return</span> out.str();
}

<span class="keywordtype">int</span> FeedForwardNet::GetConfigurationLength()<span class="keyword">const</span>
{
    <span class="keywordflow">return</span> hidden * inputs + outputs * hidden
           + (biasNode ? 1 : 0) * (hidden + outputs);
}

ostream&amp; <a class="code" href="group__biosystems.html#a2">operator&lt;&lt; </a>(ostream&amp; out, <span class="keyword">const</span> FeedForwardNet&amp; ffn)
{
    ffn.Serialise(out);
    <span class="keywordflow">return</span> out;
}

istream&amp; <a class="code" href="group__biosystems.html#a3">operator&gt;&gt; </a>(istream&amp; in, FeedForwardNet&amp; ffn)
{
    ffn.Unserialise(in);
    <span class="keywordflow">return</span> in;
}

} <span class="comment">// namespace BEAST</span>
</pre></div> <hr size="1"><address style="align: right;"><small>Generated on Sun Feb 1 21:26:29 2004 for BEAST - Bioinspired Evolutionary Agent Simulation Toolkit by
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border=0 > 
</a>1.3.2 </small></address>
</body>
</html>
