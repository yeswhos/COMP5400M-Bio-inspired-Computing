<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>BEAST - Bioinspired Evolutionary Agent Simulation Toolkit: Tutorial 3: Introducing the Genetic Algorithm</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.3.2 -->
<div class="qindex"><a class="qindex" href="index.html">Main&nbsp;Page</a> | <a class="qindex" href="modules.html">Modules</a> | <a class="qindex" href="namespaces.html">Namespace List</a> | <a class="qindex" href="hierarchy.html">Class&nbsp;Hierarchy</a> | <a class="qindex" href="classes.html">Alphabetical&nbsp;List</a> | <a class="qindex" href="annotated.html">Compound&nbsp;List</a> | <a class="qindex" href="files.html">File&nbsp;List</a> | <a class="qindex" href="namespacemembers.html">Namespace&nbsp;Members</a> | <a class="qindex" href="functions.html">Compound&nbsp;Members</a> | <a class="qindex" href="globals.html">File&nbsp;Members</a> | <a class="qindex" href="pages.html">Related&nbsp;Pages</a></div>
<h1><a name="tutorial3">Tutorial 3: Introducing the Genetic Algorithm</a>
</h1>In this tutorial we will:<ul>
<li>Replace the hand-configured neural net from tutorial 2 with an equivalent net, developed using a GA.</li><li>Set up a predator-prey simulation and co-evolve more complex controllers.</li></ul>
<p>
In tutorial two, we replaced a hand-coded controller with a neural equivalent. It didn’t allow us to do anything new, but did prove the neural net works. In the first part of this tutorial, we’ll get rid of the hand-configured neural network and evolve a new one using a Genetic Algorithm. Again we won’t be doing anything new, but it should be a reasonable test for the GA.<h2><a name="tutorial3_1"></a>
Using the GA</h2>
The Genetic Algorithm class provided with the simulation environment has numerous features, only a few of which will be useful in any given simulation. The default configuration corresponds as closely as possible to the original GA developed by John Holland. It uses roulette-wheel selection and single-point crossover. The mutation operator has different defaults depending on whether your genes are binary, integer or real valued. If you create a GA which works on the bool type, a simple NOT function is used. To evolve neural networks however, we need to work with real values, in which case the default mutation operator is a normally distributed random function, so genes may be mutated by very high values occasionally, but usually smaller changes will occur.<p>
GeneticAlgorithm is actually a class template which takes for its template parameters the type of the individuals to be evolved (and also the type of the mutation function, although we can ignore that parameter as we will be using its default). The class specified for the first template parameter needs to contain certain methods before the GA can work on it:<ul>
<li>It must have a GetGenotype method, which returns a vector of genes (genotype) corresponding to the object’s configuration (phenotype).</li><li>It must have a SetGenotype method, which takes a vector of genes for its argument and configures an individual accordingly.</li><li>It must have a GetFitness method, which returns a float corresponding to the individual’s fitness, the higher the better. For roulette wheel selection, fitness scores must be positive. (If your individuals don’t always produce positive fitness scores, the GA can clamp or scale them, see GeneticAlgorithm::SetFitnessFix for details).</li></ul>
<p>
There are a number of other features required by the GA for evolvable individuals, so to make things as easy as possible, an abstract base class called Evolver is supplied. If you inherit from this class and provide suitable GetGenotype, SetGenotype and GetFitness methods, the other details will be filled in automatically.<p>
But wait! You don’t even need to inherit your own Evolver! An Animat class with a built in feed-forward network and GA compatibility is already provided, called EvoFFNAnimat. EvoFFNAnimat returns the neural net’s configuration vector as its genotype, it initialises the net with one input per sensor and one output per control (i.e. the right and left wheels in the basic Animat) and there is also an automated Control method.<p>
The code for the evolving feed-forward net mouse looks like this:<p>
<div class="fragment"><pre><span class="keyword">class </span>EvoMouse : <span class="keyword">public</span> EvoFFNAnimat
{
<span class="keyword">public</span>:
    EvoMouse(): cheesesFound(0)
    {
        This.Add(<span class="stringliteral">"angle"</span>, NearestAngleSensor&lt;Cheese&gt;());
        This.InitRandom = <span class="keyword">true</span>;
        This.InitFFN(4);
    }

    <span class="keyword">virtual</span> <span class="keywordtype">void</span> OnCollision(WorldObject* obj)
    {
        Cheese* cheese;

        <span class="keywordflow">if</span> (<a class="code" href="group__utilities.html#a17">IsKindOf</a>(obj,cheese)) {
            cheesesFound++;
            cheese-&gt;Eaten();
        }

        This.EvoFFNAnimat::OnCollision(obj);
    }

    <span class="keyword">virtual</span> <span class="keywordtype">float</span> GetFitness()<span class="keyword">const</span>
    {
        <span class="keywordflow">return</span> cheesesFound &gt; 0 ? static_cast&lt;float&gt;(cheesesFound) / static_cast&lt;float&gt;(powerUsed) : 0;
    }

    <span class="keyword">virtual</span> string ToString()<span class="keyword">const</span>
    {
        ostringstream out;
        out &lt;&lt; <span class="stringliteral">" Power used: "</span> &lt;&lt; powerUsed;
        <span class="keywordflow">return</span> out.str();
    }

<span class="keyword">private</span>:
    <span class="keywordtype">int</span> cheesesFound;   <span class="comment">// The number of cheeses collected for this run.</span>
};
</pre></div><p>
The constructor sets up the sensor and initRandom as before, but now also initialises cheesesFound to 0 and calls InitFFN to set up a feed-forward network with two hidden nodes. The number of inputs is one, since there is only one sensor and the number of outputs is two, one for each wheel. This 1-2-2 setup matches the hand-configured network so there is good reason to believe that the GA will be able to find a suitable network.<p>
OnCollision is exactly as before except that each cheese eaten increments cheesesFound by one, and EvoFFNAnimat::OnCollision is now called at the end.<p>
Finally, GetFitness returns the number of cheeses found, divided by powerUsed which is the total activation of all the controls for the duration of the assessment. This penalises mice that latch onto the unrealistic tactic of going as fast as possible in one direction, picking up more cheese simply due to the greater area covered.<p>
We also need to set up the simulation. This time, instead of a Group, the mice will go into a Population. This is a similar container to Group but also has an associated GA which is used on the population at the end of each assessment.<p>
<div class="fragment"><pre><span class="keyword">class </span>MouseSimulation : <span class="keyword">public</span> Simulation
{
    Population&lt;EvoMouse&gt;        theMice;
    GeneticAlgorithm&lt;EvoMouse&gt;  theGA;
    Group&lt;Cheese&gt;               theCheeses;

<span class="keyword">public</span>:
    MouseSimulation():
    theGA(0.7f, 0.05f),
    theMice(30, theGA),
    theCheeses(50)
    {
        This.theGA.SetSelection(GA_RANK);
        This.theGA.SetParameter(GA_RANK_SPRESSURE, 2.0);

        This.Add(<span class="stringliteral">"Mice"</span>,        theMice);
        This.Add(<span class="stringliteral">"Cheeses"</span>,     theCheeses);
    }
};
</pre></div><p>
The Population of 'evomice' is configured with a reference to a GA which works on EvoMouse objects, this GA will therefore be used at the end of each generation.<p>
Rather than using roulette wheel selection, rank selection has been specified with a selection pressure of two. This means that at the end of the generations the individuals' chances of reproducing depend on how they rank in the overall population. Selection pressure ranges between one and two, one means that all individuals have an equal chance of going on to the next generation (not very useful!) whereas two means that in a population of twelve, the sixth individual has half as much chance of reproducing as the best, the third has three quarters the chance of the best, the ninth has one quarter the chance of the best and so on.<p>
For information on the other options and selection methods available, see the GeneticAlgorithm documentation.<p>
Compile and run the simulation same as usual. This time the animats start off wandering about with no idea about cheese or its uses. At the end of a certain period (the time limit defaults to 1000 time steps) the animats will be taken out of the world and put through the GA. Their offspring then appear as the next generation. To make this process go faster, go to the Simulation menu and click on High Speed. The display will stop updating and the simulation environment will go at the highest speed your machine is capable of. After a few more generations, click cancel and see if your mice are doing anything useful. You should expect to see good results for this particular simulation after about 200 generations.<h2><a name="tutorial3_2"></a>
Coevolutionary Simulations</h2>
Now we'll try creating something more complex, a coevolutionary simulation where two populations are evolving and the fitness of each is dependent in some way on the fitness of the other. In this case, we'll evolve predators and prey. The <code>Predator</code> class will be similar to <code>Mouse</code>, in that it has to seek out prey and receives a point for every <code>Prey</code> object it munches on. <code>Prey</code> will be penalised each time they get munched. To make things interesting, we'll give predators two long-range, forward facing proximity sensors, a little like the eyes of a hawk or cat, and the prey will have short-range, sideways-facing proximity sensors like fish and rodents - if it makes sense in nature, it should make sense here.<p>
Here is the code for both the <code>Predator</code> and <code>Prey</code> classes.<p>
<div class="fragment"><pre><span class="comment">// Forward declaration for Prey</span>
<span class="keyword">class </span>Predator;

<span class="keyword">class </span>Prey : <span class="keyword">public</span> EvoFFNAnimat
{
<span class="keyword">public</span>:
    Prey():timesEaten(1)
    {
        This.Add(<span class="stringliteral">"right"</span>, ProximitySensor&lt;Predator&gt;(PI/1.05, 100.0, -PI/2));
        This.Add(<span class="stringliteral">"left"</span>, ProximitySensor&lt;Predator&gt;(PI/1.05, 100.0, PI/2));

        This.InitFFN(4);
        This.InitRandom = <span class="keyword">true</span>;
        This.MinSpeed = 0;
        This.MaxSpeed = 100;
    }

    <span class="keywordtype">void</span> Eaten()
    {
        This.timesEaten++;
        This.Location = myWorld-&gt;RandomLocation();
    }

    <span class="keywordtype">float</span> GetFitness()<span class="keyword">const</span>
    {
        <span class="keywordflow">return</span> 1.0f / static_cast&lt;float&gt;(This.timesEaten);
    }

<span class="keyword">private</span>:
    <span class="keywordtype">int</span> timesEaten;
};

<span class="keyword">class </span>Predator : <span class="keyword">public</span> EvoFFNAnimat
{
<span class="keyword">public</span>:
    Predator():preyEaten(0)
    {
        This.Add(<span class="stringliteral">"left"</span>, ProximitySensor&lt;Prey&gt;(PI/5, 200.0, -PI/20));
        This.Add(<span class="stringliteral">"right"</span>, ProximitySensor&lt;Prey&gt;(PI/5, 200.0, PI/20));

        This.InitFFN(4);
        This.InitRandom = <span class="keyword">true</span>;

        This.MinSpeed = 0;
        This.MaxSpeed = 100;
        This.Radius = 10.0;
    }

    <span class="keywordtype">void</span> OnCollision(WorldObject* obj)
    {
        Prey* ptr;

        <span class="keywordflow">if</span> (<a class="code" href="group__utilities.html#a17">IsKindOf</a>(obj,ptr)) {
            This.preyEaten++;
            ptr-&gt;Eaten();
        }

        This.FFNAnimat::OnCollision(obj);
    }

    <span class="keywordtype">float</span> GetFitness()<span class="keyword">const</span> { <span class="keywordflow">return</span> preyEaten; }

<span class="keyword">private</span>:
    <span class="keywordtype">int</span> preyEaten;
};
</pre></div><p>
Note that there is a forward declaration of <code>Predator</code> above the <code>Prey</code> class, which simply states that there is a class called 'Predator'. This is to get round the problem of classes which refer to each other - one must be defined after the other, and both contain methods which use pointers to the other, so one is bound to find itself referring to a type which has not yet been defined. The forward declaration simply lets the compiler know that the type <code>Predator</code> does exist and so there's no need to get upset when <code>Prey</code> starts talking about <code>Predator</code> objects which aren't yet defined. By the time <code>Predator</code> is defined, the compiler knows all about <code>Prey</code>, so it's safe for <code>Predator</code> to manipulate <code>Prey</code> objects and call member functions.<p>
The only other unusual feature worth mentioning in the code above is the fitness function for <code>Prey</code>:  are more fit the fewer times they are eaten, so it would make sense to subtract one from the <code>Prey's</code> fitness each time it is eaten, however the standard GA using roulette wheel selection is unable to work with negative scores. Two solutions are available:<ul>
<li>Set up the GA to adjust the scores using <code>SetFitnessFix</code>, which can be set to one of three options:<ul>
<li><code>GA_IGNORE</code> which is the default setting, no change is made to fitness scores.</li><li><code>GA_CLAMP</code> which sets any scores below zero to zero.</li><li><code>GA_FIX</code> which linearly scales the scores up so that the lowest score becomes zero.</li></ul>
</li><li>Ensure that GetFitness returns a positive value, in this case by returning the inverse of the number of times the individual has been eaten, so higher numbers become lower but remain positive.</li></ul>
<p>
Setting up a GA to do coevolution is very easy, all you need is two GAs. They don't need to know anything about each other, and the fitness functions of the two types of individuals are entirely unrelated. <code>ChaseSimulation</code> is therefore set up just like previous simulations, but with two populations (and no groups).<p>
I've chosen population sizes of 30 for speed but feel free to experiment with larger numbers depending on the speed of your computer and how much time you have. One thing we don't want is a simulation with 60 individuals vying for space in our environment - this would reduce the effectiveness of the simulation because the chances of randomly bumping into another individual, regardless of whether that individual is effective at chasing or evading (depending on whether it is predator or prey), are increased the more crowded the simulation becomes. One answer is to simply increase the arena size using World::SetWidth and World::SetHeight, but then they'd be too small to see.<p>
Instead, I've opted for a more complex kind of simulation where rather than simulating every individual at once, a selection of each Population go into the arena and are assessed, their scores are then stored and a new selection go in. The selections are made depending on the <code>Population</code> object's team size, which is set using SetTeamSize. The default is for the team to be the whole population, but team sizes as low as one can be used, making individual assessments possible.<p>
<div class="fragment"><pre><span class="keyword">class </span>ChaseSimulation : <span class="keyword">public</span> Simulation
{
    GeneticAlgorithm&lt;Predator&gt; gaPred;
    GeneticAlgorithm&lt;Prey&gt; gaPrey;
    Population&lt;Predator&gt; popPred;
    Population&lt;Prey&gt; popPrey;

<span class="keyword">public</span>:
    ChaseSimulation():
    gaPred(0.7f, 0.1f), gaPrey(0.7f, 0.1f), 
    popPred(30,gaPred), popPrey(30,gaPrey)
    {
        This.gaPred.SetSelection(GA_RANK);
        This.gaPred.SetParameter(GA_RANK_SPRESSURE, 2.0);
        
        This.gaPrey.SetSelection(GA_RANK);
        This.gaPrey.SetParameter(GA_RANK_SPRESSURE, 2.0);

        This.popPred.SetTeamSize(5);
        This.popPrey.SetTeamSize(10);
        This.SetAssessments(30);

        This.Add(<span class="stringliteral">"Predators"</span>, popPred);
        This.Add(<span class="stringliteral">"Prey"</span>, popPrey);
    }
};
</pre></div><p>
In this simulation, 30 assessments are being made for each generation, so each <code>Predator</code> will have had 5 assessments and each <code>Prey</code> will have had 10 assessments, and also every <code>Prey</code> will have been preyed on by every <code>Predator</code>.<p>
If you set this simulation going in the usual way and leave it for a few hundred generations you will start to see some quite convincing predator/prey behaviour.<h2><a name="tutorial3_3"></a>
More things to try...</h2>
<ul>
<li>Replace the EvoFFNAnimat used in the predator/prey simulation with EvoDNNAnimat and see if the dynamical network-based solution is any 'cleverer'.</li><li>Give the predators an additional DensitySensor, a beam sensor which counts the number of individuals in its range. More successful predators should be able to use this sensor to concentrate on areas where there are more than one prey nearby. Giving the same kind of sensor to prey will give the prey chance to avoid running into large groups of predators.</li><li>Add sensors allowing predators to sense other predators and prey to sense other prey. Do the prey consequently avoid each other, or huddle together? Do the predators work together or look for their own territory? (Hint: if you find that adding all these sensors slows things down too much, change some of them into nearest angle sensors which are just as effective and much faster for the simulation environment to process.)</li><li>Introduce a third coevolving class which can eat predators but is eaten by prey (yes, I know it's silly but it might be funny to watch). </li></ul>
<hr size="1"><address style="align: right;"><small>Generated on Sun Feb 1 21:26:36 2004 for BEAST - Bioinspired Evolutionary Agent Simulation Toolkit by
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border=0 > 
</a>1.3.2 </small></address>
</body>
</html>
